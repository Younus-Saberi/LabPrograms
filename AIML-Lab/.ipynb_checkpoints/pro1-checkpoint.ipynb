{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2052c1d-2847-46d6-adea-ee732388352a",
   "metadata": {},
   "source": [
    "# Program 1 Source Code ðŸ‘‡\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d2fb57d-a71d-405a-b71b-0faf1ef8b654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph-1\n",
      "Path\n",
      "A -> B -> D\n",
      "Cost\n",
      "0 -> 1 -> 6\n"
     ]
    }
   ],
   "source": [
    "from heuristicsearch.a_star_search import AStar\n",
    "\n",
    "print(\"Graph-1\")\n",
    "\n",
    "heuristic = {'A':1,'B':1,'C':11,'D':1}\n",
    "adjance_list = {'A':[('B',1),('C',3),('D',7),],'B':[('D',5 )],'C':[('D',12)]}\n",
    "\n",
    "graph=AStar(adjance_list,heuristic)\n",
    "graph.apply_a_star(start='A',stop='D')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deeb8580-f7b2-4100-9f3b-55753a9d90fd",
   "metadata": {},
   "source": [
    "# Program 2 Source Code ðŸ‘‡\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ac1577d-5ad0-48c3-90ca-571a17c8311a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph-1\n",
      "PROCESSING NODE : A\n",
      "-----------------------------------------------------------------------------------------\n",
      "11 ['D']\n",
      "\n",
      "PROCESSING NODE : D\n",
      "-----------------------------------------------------------------------------------------\n",
      "6 ['E', 'F']\n",
      "\n",
      "PROCESSING NODE : A\n",
      "-----------------------------------------------------------------------------------------\n",
      "7 ['D']\n",
      "\n",
      "PROCESSING NODE : E\n",
      "-----------------------------------------------------------------------------------------\n",
      "0 []\n",
      "\n",
      "PROCESSING NODE : D\n",
      "-----------------------------------------------------------------------------------------\n",
      "2 ['E', 'F']\n",
      "\n",
      "PROCESSING NODE : A\n",
      "-----------------------------------------------------------------------------------------\n",
      "3 ['D']\n",
      "\n",
      "PROCESSING NODE : F\n",
      "-----------------------------------------------------------------------------------------\n",
      "0 []\n",
      "\n",
      "PROCESSING NODE : D\n",
      "-----------------------------------------------------------------------------------------\n",
      "2 ['E', 'F']\n",
      "\n",
      "PROCESSING NODE : A\n",
      "-----------------------------------------------------------------------------------------\n",
      "3 ['D']\n",
      "\n",
      "FOR THE SOLUTION, TRAVERSE THE GRAPH FROM THE START NODE: A\n",
      "------------------------------------------------------------\n",
      "{'E': [], 'F': [], 'D': ['E', 'F'], 'A': ['D']}\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from heuristicsearch.ao_star import AOStar\n",
    "print(\"Graph-1\")\n",
    "heuristic={'A':1,'B':6,'C':12,'D':10,'E':4,'G':5,'H':7}\n",
    "adjancency_list = {'A':[[('B',1),('C',1)],[('D',1)]],\n",
    "                   'B':[[('G',1)],[('H',1)]],\n",
    "                   'C':[[('J',1)]],\n",
    "                   'D':[[('E',1),('F',1)]],\n",
    "                   'G':[[('I',1)]]\n",
    "                  }\n",
    "graph=AOStar(adjancency_list, heuristic, 'A')\n",
    "graph.applyAOStar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3adbca7-d00a-40d9-b552-8da65dce052b",
   "metadata": {},
   "source": [
    "# Program 3 Source CodeðŸ‘‡\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "74a3d429-5889-4a1a-b1c9-33fea01bf7bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Steps for candidate elimination algorithm 1\n",
      "['Sunny', 'Warm', '?', 'Strong', 'Warm', 'Same']\n",
      "[['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?']]\n",
      "\n",
      " Steps for candidate elimination algorithm 2\n",
      "['Sunny', 'Warm', '?', 'Strong', 'Warm', 'Same']\n",
      "[['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?']]\n",
      "\n",
      " Steps for candidate elimination algorithm 3\n",
      "['Sunny', 'Warm', '?', 'Strong', 'Warm', 'Same']\n",
      "[['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?']]\n",
      "\n",
      " Steps for candidate elimination algorithm 4\n",
      "['?', 'Warm', '?', 'Strong', '?', '?']\n",
      "[['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?']]\n",
      "\n",
      " Final Specific Hypothesis:\n",
      " ['?', 'Warm', '?', 'Strong', '?', '?']\n",
      "\n",
      " Final General Hypothesis:\n",
      " []\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Copy the CSV File Format as given below\n",
    "\n",
    "Sunny,Warm,Normal,Strong,Warm,Same,Yes\n",
    "Sunny,Warm,High,Strong,Warm,Same,Yes\n",
    "Rainy,Cold,High,Strong,Warm,Change,No \n",
    "Rainy,Warm,High,Strong,Cool,Change,Yes\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "import csv\n",
    "\n",
    "with open('pro3.csv') as f:\n",
    "    csv_file=csv.reader(f)\n",
    "    data=list(csv_file)\n",
    "\n",
    "    s=data[1][:-1]\n",
    "    g=[['?' for i in range(len(s))] for j in range(len(s))] \n",
    "\n",
    "    for i in data:\n",
    "        if i[-1]==\"Yes\":\n",
    "            for j in range(len(s)):\n",
    "                if i[j]!=s[j]:\n",
    "                    s[j]='?'\n",
    "                    g[j][j]='?'\n",
    "        elif i[-1]==\"No\":\n",
    "            for j in range(len(s)):\n",
    "                if i[j]!=s[j]:\n",
    "                    g[j][j]=s[j]\n",
    "                else:\n",
    "                    g[j][j]=\"?\"\n",
    "        print(\"\\n Steps for candidate elimination algorithm\",data.index(i)+1)\n",
    "        print(s)\n",
    "        print(g)\n",
    "\n",
    "    gh=[]\n",
    "\n",
    "    for i in g:\n",
    "        for j in i:\n",
    "            if j!=\"?\":\n",
    "                gh.append(i)\n",
    "                break\n",
    "\n",
    "    print(\"\\n Final Specific Hypothesis:\\n\",s)\n",
    "    print(\"\\n Final General Hypothesis:\\n\", gh)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba1bc87-6032-47ba-a9d2-f6396da28418",
   "metadata": {},
   "source": [
    "# Program 4 Source CodeðŸ‘‡\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "20246fe6-4b68-4f84-8921-e6005d843b99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "X= [[0,0],[1,1]]\n",
    "Y= [0,1]\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(X,Y)\n",
    "clf.predict([[2.,2.]])\n",
    "clf.predict_proba([[2.,2.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "12908f39-d659-45f8-b9e7-c373025bc813",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(0.5, 0.9166666666666666, 'x[3] <= 0.8\\ngini = 0.667\\nsamples = 150\\nvalue = [50, 50, 50]'),\n",
       " Text(0.4230769230769231, 0.75, 'gini = 0.0\\nsamples = 50\\nvalue = [50, 0, 0]'),\n",
       " Text(0.5769230769230769, 0.75, 'x[3] <= 1.75\\ngini = 0.5\\nsamples = 100\\nvalue = [0, 50, 50]'),\n",
       " Text(0.3076923076923077, 0.5833333333333334, 'x[2] <= 4.95\\ngini = 0.168\\nsamples = 54\\nvalue = [0, 49, 5]'),\n",
       " Text(0.15384615384615385, 0.4166666666666667, 'x[3] <= 1.65\\ngini = 0.041\\nsamples = 48\\nvalue = [0, 47, 1]'),\n",
       " Text(0.07692307692307693, 0.25, 'gini = 0.0\\nsamples = 47\\nvalue = [0, 47, 0]'),\n",
       " Text(0.23076923076923078, 0.25, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(0.46153846153846156, 0.4166666666666667, 'x[3] <= 1.55\\ngini = 0.444\\nsamples = 6\\nvalue = [0, 2, 4]'),\n",
       " Text(0.38461538461538464, 0.25, 'gini = 0.0\\nsamples = 3\\nvalue = [0, 0, 3]'),\n",
       " Text(0.5384615384615384, 0.25, 'x[2] <= 5.45\\ngini = 0.444\\nsamples = 3\\nvalue = [0, 2, 1]'),\n",
       " Text(0.46153846153846156, 0.08333333333333333, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 2, 0]'),\n",
       " Text(0.6153846153846154, 0.08333333333333333, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(0.8461538461538461, 0.5833333333333334, 'x[2] <= 4.85\\ngini = 0.043\\nsamples = 46\\nvalue = [0, 1, 45]'),\n",
       " Text(0.7692307692307693, 0.4166666666666667, 'x[1] <= 3.1\\ngini = 0.444\\nsamples = 3\\nvalue = [0, 1, 2]'),\n",
       " Text(0.6923076923076923, 0.25, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 0, 2]'),\n",
       " Text(0.8461538461538461, 0.25, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1, 0]'),\n",
       " Text(0.9230769230769231, 0.4166666666666667, 'gini = 0.0\\nsamples = 43\\nvalue = [0, 0, 43]')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn import tree\n",
    "iris= load_iris()\n",
    "X,y = iris.data,iris.target\n",
    "clf=tree.DecisionTreeClassifier()\n",
    "clf=clf.fit(X,y)\n",
    "tree.plot_tree(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65094142-a355-4481-9fe8-36f106cf0a45",
   "metadata": {},
   "source": [
    "# Program 5 Source CodeðŸ‘‡\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e41c50e2-6634-47d8-8df6-d8660230de6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3. 9.]\n",
      "Epoch: 0\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.72676846]\n",
      " [0.66586932]\n",
      " [0.71990522]]\n",
      "Loss: \n",
      " 0.03465245983850545\n",
      "\n",
      "\n",
      "Epoch: 1\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.72897259]\n",
      " [0.66815457]\n",
      " [0.72191969]]\n",
      "Loss: \n",
      " 0.03384904338048457\n",
      "\n",
      "\n",
      "Epoch: 2\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.7311321 ]\n",
      " [0.67039748]\n",
      " [0.72389591]]\n",
      "Loss: \n",
      " 0.03307025604711877\n",
      "\n",
      "\n",
      "Epoch: 3\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.7332482 ]\n",
      " [0.67259908]\n",
      " [0.72583484]]\n",
      "Loss: \n",
      " 0.0323151802830122\n",
      "\n",
      "\n",
      "Epoch: 4\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.73532204]\n",
      " [0.67476037]\n",
      " [0.72773743]]\n",
      "Loss: \n",
      " 0.03158293723435112\n",
      "\n",
      "\n",
      "Epoch: 5\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.73735475]\n",
      " [0.67688234]\n",
      " [0.72960458]]\n",
      "Loss: \n",
      " 0.030872685024070288\n",
      "\n",
      "\n",
      "Epoch: 6\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.73934741]\n",
      " [0.67896595]\n",
      " [0.73143719]]\n",
      "Loss: \n",
      " 0.030183617100401443\n",
      "\n",
      "\n",
      "Epoch: 7\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.7413011 ]\n",
      " [0.68101211]\n",
      " [0.7332361 ]]\n",
      "Loss: \n",
      " 0.029514960656614266\n",
      "\n",
      "\n",
      "Epoch: 8\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.74321682]\n",
      " [0.68302174]\n",
      " [0.73500216]]\n",
      "Loss: \n",
      " 0.028865975119681687\n",
      "\n",
      "\n",
      "Epoch: 9\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.74509558]\n",
      " [0.68499572]\n",
      " [0.73673618]]\n",
      "Loss: \n",
      " 0.028235950705547283\n",
      "\n",
      "\n",
      "Epoch: 10\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.74693835]\n",
      " [0.68693489]\n",
      " [0.73843895]]\n",
      "Loss: \n",
      " 0.027624207038643666\n",
      "\n",
      "\n",
      "Epoch: 11\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.74874605]\n",
      " [0.68884009]\n",
      " [0.74011123]]\n",
      "Loss: \n",
      " 0.02703009183330118\n",
      "\n",
      "\n",
      "Epoch: 12\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.75051959]\n",
      " [0.69071213]\n",
      " [0.74175376]]\n",
      "Loss: \n",
      " 0.026452979634691582\n",
      "\n",
      "\n",
      "Epoch: 13\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.75225986]\n",
      " [0.69255179]\n",
      " [0.74336728]]\n",
      "Loss: \n",
      " 0.02589227061697223\n",
      "\n",
      "\n",
      "Epoch: 14\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.7539677 ]\n",
      " [0.69435985]\n",
      " [0.74495248]]\n",
      "Loss: \n",
      " 0.025347389436328\n",
      "\n",
      "\n",
      "Epoch: 15\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.75564394]\n",
      " [0.69613704]\n",
      " [0.74651005]]\n",
      "Loss: \n",
      " 0.024817784136648573\n",
      "\n",
      "\n",
      "Epoch: 16\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.75728938]\n",
      " [0.69788408]\n",
      " [0.74804064]]\n",
      "Loss: \n",
      " 0.02430292510562754\n",
      "\n",
      "\n",
      "Epoch: 17\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.75890481]\n",
      " [0.69960169]\n",
      " [0.74954491]]\n",
      "Loss: \n",
      " 0.023802304079124186\n",
      "\n",
      "\n",
      "Epoch: 18\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.76049097]\n",
      " [0.70129054]\n",
      " [0.75102347]]\n",
      "Loss: \n",
      " 0.023315433191688495\n",
      "\n",
      "\n",
      "Epoch: 19\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.7620486 ]\n",
      " [0.7029513 ]\n",
      " [0.75247694]]\n",
      "Loss: \n",
      " 0.022841844071211648\n",
      "\n",
      "\n",
      "Epoch: 20\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.7635784 ]\n",
      " [0.70458461]\n",
      " [0.75390591]]\n",
      "Loss: \n",
      " 0.022381086975730807\n",
      "\n",
      "\n",
      "Epoch: 21\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.76508107]\n",
      " [0.70619112]\n",
      " [0.75531094]]\n",
      "Loss: \n",
      " 0.02193272997048323\n",
      "\n",
      "\n",
      "Epoch: 22\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.76655727]\n",
      " [0.70777142]\n",
      " [0.75669261]]\n",
      "Loss: \n",
      " 0.021496358143372928\n",
      "\n",
      "\n",
      "Epoch: 23\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.76800765]\n",
      " [0.70932611]\n",
      " [0.75805144]]\n",
      "Loss: \n",
      " 0.02107157285708167\n",
      "\n",
      "\n",
      "Epoch: 24\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.76943283]\n",
      " [0.71085578]\n",
      " [0.75938797]]\n",
      "Loss: \n",
      " 0.020657991036124455\n",
      "\n",
      "\n",
      "Epoch: 25\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.77083344]\n",
      " [0.71236098]\n",
      " [0.76070271]]\n",
      "Loss: \n",
      " 0.02025524448721695\n",
      "\n",
      "\n",
      "Epoch: 26\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.77221005]\n",
      " [0.71384227]\n",
      " [0.76199615]]\n",
      "Loss: \n",
      " 0.01986297925138986\n",
      "\n",
      "\n",
      "Epoch: 27\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.77356325]\n",
      " [0.71530017]\n",
      " [0.76326878]]\n",
      "Loss: \n",
      " 0.019480854986350365\n",
      "\n",
      "\n",
      "Epoch: 28\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.77489359]\n",
      " [0.71673521]\n",
      " [0.76452107]]\n",
      "Loss: \n",
      " 0.019108544377655322\n",
      "\n",
      "\n",
      "Epoch: 29\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.77620161]\n",
      " [0.71814789]\n",
      " [0.76575348]]\n",
      "Loss: \n",
      " 0.01874573257732354\n",
      "\n",
      "\n",
      "Epoch: 30\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.77748784]\n",
      " [0.71953869]\n",
      " [0.76696645]]\n",
      "Loss: \n",
      " 0.018392116668575573\n",
      "\n",
      "\n",
      "Epoch: 31\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.77875278]\n",
      " [0.72090811]\n",
      " [0.76816041]]\n",
      "Loss: \n",
      " 0.018047405155448105\n",
      "\n",
      "\n",
      "Epoch: 32\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.77999695]\n",
      " [0.7222566 ]\n",
      " [0.76933579]]\n",
      "Loss: \n",
      " 0.0177113174760877\n",
      "\n",
      "\n",
      "Epoch: 33\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.78122081]\n",
      " [0.72358461]\n",
      " [0.77049299]]\n",
      "Loss: \n",
      " 0.017383583538584046\n",
      "\n",
      "\n",
      "Epoch: 34\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.78242483]\n",
      " [0.72489258]\n",
      " [0.77163241]]\n",
      "Loss: \n",
      " 0.017063943278254844\n",
      "\n",
      "\n",
      "Epoch: 35\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.78360946]\n",
      " [0.72618095]\n",
      " [0.77275443]]\n",
      "Loss: \n",
      " 0.016752146235347567\n",
      "\n",
      "\n",
      "Epoch: 36\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.78477516]\n",
      " [0.72745013]\n",
      " [0.77385944]]\n",
      "Loss: \n",
      " 0.016447951152170844\n",
      "\n",
      "\n",
      "Epoch: 37\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.78592234]\n",
      " [0.72870053]\n",
      " [0.77494781]]\n",
      "Loss: \n",
      " 0.016151125588716213\n",
      "\n",
      "\n",
      "Epoch: 38\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.78705143]\n",
      " [0.72993254]\n",
      " [0.77601987]]\n",
      "Loss: \n",
      " 0.015861445555876204\n",
      "\n",
      "\n",
      "Epoch: 39\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.78816282]\n",
      " [0.73114654]\n",
      " [0.777076  ]]\n",
      "Loss: \n",
      " 0.015578695165407644\n",
      "\n",
      "\n",
      "Epoch: 40\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.78925692]\n",
      " [0.73234292]\n",
      " [0.77811651]]\n",
      "Loss: \n",
      " 0.015302666295831047\n",
      "\n",
      "\n",
      "Epoch: 41\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.7903341 ]\n",
      " [0.73352204]\n",
      " [0.77914174]]\n",
      "Loss: \n",
      " 0.015033158273495545\n",
      "\n",
      "\n",
      "Epoch: 42\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.79139473]\n",
      " [0.73468424]\n",
      " [0.78015202]]\n",
      "Loss: \n",
      " 0.014769977568077975\n",
      "\n",
      "\n",
      "Epoch: 43\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.79243919]\n",
      " [0.73582989]\n",
      " [0.78114764]]\n",
      "Loss: \n",
      " 0.014512937501819347\n",
      "\n",
      "\n",
      "Epoch: 44\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.79346781]\n",
      " [0.73695932]\n",
      " [0.78212892]]\n",
      "Loss: \n",
      " 0.014261857971837209\n",
      "\n",
      "\n",
      "Epoch: 45\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.79448095]\n",
      " [0.73807285]\n",
      " [0.78309615]]\n",
      "Loss: \n",
      " 0.014016565184884935\n",
      "\n",
      "\n",
      "Epoch: 46\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.79547893]\n",
      " [0.73917081]\n",
      " [0.78404962]]\n",
      "Loss: \n",
      " 0.01377689140395969\n",
      "\n",
      "\n",
      "Epoch: 47\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.79646207]\n",
      " [0.7402535 ]\n",
      " [0.78498961]]\n",
      "Loss: \n",
      " 0.013542674706191428\n",
      "\n",
      "\n",
      "Epoch: 48\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.7974307 ]\n",
      " [0.74132124]\n",
      " [0.7859164 ]]\n",
      "Loss: \n",
      " 0.01331375875147247\n",
      "\n",
      "\n",
      "Epoch: 49\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.79838513]\n",
      " [0.74237432]\n",
      " [0.78683023]]\n",
      "Loss: \n",
      " 0.013089992561314932\n",
      "\n",
      "\n",
      "Epoch: 50\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.79932563]\n",
      " [0.74341304]\n",
      " [0.78773139]]\n",
      "Loss: \n",
      " 0.012871230307448092\n",
      "\n",
      "\n",
      "Epoch: 51\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.80025252]\n",
      " [0.74443766]\n",
      " [0.78862012]]\n",
      "Loss: \n",
      " 0.012657331109692962\n",
      "\n",
      "\n",
      "Epoch: 52\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.80116607]\n",
      " [0.74544847]\n",
      " [0.78949666]]\n",
      "Loss: \n",
      " 0.012448158842673106\n",
      "\n",
      "\n",
      "Epoch: 53\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.80206656]\n",
      " [0.74644573]\n",
      " [0.79036127]]\n",
      "Loss: \n",
      " 0.012243581950944138\n",
      "\n",
      "\n",
      "Epoch: 54\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.80295425]\n",
      " [0.74742971]\n",
      " [0.79121416]]\n",
      "Loss: \n",
      " 0.012043473272143909\n",
      "\n",
      "\n",
      "Epoch: 55\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8038294 ]\n",
      " [0.74840067]\n",
      " [0.79205557]]\n",
      "Loss: \n",
      " 0.011847709867786035\n",
      "\n",
      "\n",
      "Epoch: 56\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.80469228]\n",
      " [0.74935884]\n",
      " [0.79288572]]\n",
      "Loss: \n",
      " 0.011656172861337502\n",
      "\n",
      "\n",
      "Epoch: 57\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.80554312]\n",
      " [0.75030448]\n",
      " [0.79370484]]\n",
      "Loss: \n",
      " 0.011468747283239435\n",
      "\n",
      "\n",
      "Epoch: 58\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.80638218]\n",
      " [0.75123782]\n",
      " [0.79451312]]\n",
      "Loss: \n",
      " 0.011285321922546913\n",
      "\n",
      "\n",
      "Epoch: 59\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.80720967]\n",
      " [0.75215909]\n",
      " [0.79531078]]\n",
      "Loss: \n",
      " 0.011105789184879249\n",
      "\n",
      "\n",
      "Epoch: 60\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.80802584]\n",
      " [0.75306852]\n",
      " [0.79609802]]\n",
      "Loss: \n",
      " 0.010930044956388668\n",
      "\n",
      "\n",
      "Epoch: 61\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.80883091]\n",
      " [0.75396632]\n",
      " [0.79687504]]\n",
      "Loss: \n",
      " 0.010757988473467752\n",
      "\n",
      "\n",
      "Epoch: 62\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.80962509]\n",
      " [0.75485272]\n",
      " [0.79764202]]\n",
      "Loss: \n",
      " 0.010589522197932124\n",
      "\n",
      "\n",
      "Epoch: 63\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8104086 ]\n",
      " [0.75572793]\n",
      " [0.79839915]]\n",
      "Loss: \n",
      " 0.010424551697426012\n",
      "\n",
      "\n",
      "Epoch: 64\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.81118164]\n",
      " [0.75659213]\n",
      " [0.79914663]]\n",
      "Loss: \n",
      " 0.010262985530811302\n",
      "\n",
      "\n",
      "Epoch: 65\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.81194442]\n",
      " [0.75744555]\n",
      " [0.79988462]]\n",
      "Loss: \n",
      " 0.010104735138313035\n",
      "\n",
      "\n",
      "Epoch: 66\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.81269713]\n",
      " [0.75828837]\n",
      " [0.8006133 ]]\n",
      "Loss: \n",
      " 0.009949714736204167\n",
      "\n",
      "\n",
      "Epoch: 67\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.81343996]\n",
      " [0.75912079]\n",
      " [0.80133284]]\n",
      "Loss: \n",
      " 0.009797841215824324\n",
      "\n",
      "\n",
      "Epoch: 68\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.81417311]\n",
      " [0.75994298]\n",
      " [0.8020434 ]]\n",
      "Loss: \n",
      " 0.009649034046736137\n",
      "\n",
      "\n",
      "Epoch: 69\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.81489674]\n",
      " [0.76075514]\n",
      " [0.80274515]]\n",
      "Loss: \n",
      " 0.009503215183833196\n",
      "\n",
      "\n",
      "Epoch: 70\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.81561105]\n",
      " [0.76155743]\n",
      " [0.80343825]]\n",
      "Loss: \n",
      " 0.009360308978222006\n",
      "\n",
      "\n",
      "Epoch: 71\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.81631621]\n",
      " [0.76235005]\n",
      " [0.80412285]]\n",
      "Loss: \n",
      " 0.009220242091709156\n",
      "\n",
      "\n",
      "Epoch: 72\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.81701238]\n",
      " [0.76313314]\n",
      " [0.80479911]]\n",
      "Loss: \n",
      " 0.009082943414733327\n",
      "\n",
      "\n",
      "Epoch: 73\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.81769973]\n",
      " [0.76390689]\n",
      " [0.80546716]]\n",
      "Loss: \n",
      " 0.008948343987588848\n",
      "\n",
      "\n",
      "Epoch: 74\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.81837843]\n",
      " [0.76467145]\n",
      " [0.80612715]]\n",
      "Loss: \n",
      " 0.008816376924795404\n",
      "\n",
      "\n",
      "Epoch: 75\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.81904863]\n",
      " [0.76542698]\n",
      " [0.80677923]]\n",
      "Loss: \n",
      " 0.008686977342475288\n",
      "\n",
      "\n",
      "Epoch: 76\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.81971048]\n",
      " [0.76617363]\n",
      " [0.80742354]]\n",
      "Loss: \n",
      " 0.008560082288605872\n",
      "\n",
      "\n",
      "Epoch: 77\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.82036414]\n",
      " [0.76691157]\n",
      " [0.8080602 ]]\n",
      "Loss: \n",
      " 0.008435630676021915\n",
      "\n",
      "\n",
      "Epoch: 78\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.82100975]\n",
      " [0.76764093]\n",
      " [0.80868935]]\n",
      "Loss: \n",
      " 0.008313563218047555\n",
      "\n",
      "\n",
      "Epoch: 79\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.82164746]\n",
      " [0.76836186]\n",
      " [0.80931112]]\n",
      "Loss: \n",
      " 0.008193822366644005\n",
      "\n",
      "\n",
      "Epoch: 80\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8222774 ]\n",
      " [0.76907451]\n",
      " [0.80992563]]\n",
      "Loss: \n",
      " 0.00807635225296414\n",
      "\n",
      "\n",
      "Epoch: 81\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.82289972]\n",
      " [0.769779  ]\n",
      " [0.81053301]]\n",
      "Loss: \n",
      " 0.007961098630210226\n",
      "\n",
      "\n",
      "Epoch: 82\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.82351454]\n",
      " [0.77047549]\n",
      " [0.81113337]]\n",
      "Loss: \n",
      " 0.007848008818695983\n",
      "\n",
      "\n",
      "Epoch: 83\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.82412201]\n",
      " [0.77116409]\n",
      " [0.81172685]]\n",
      "Loss: \n",
      " 0.0077370316530188015\n",
      "\n",
      "\n",
      "Epoch: 84\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.82472224]\n",
      " [0.77184494]\n",
      " [0.81231354]]\n",
      "Loss: \n",
      " 0.007628117431252256\n",
      "\n",
      "\n",
      "Epoch: 85\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.82531536]\n",
      " [0.77251817]\n",
      " [0.81289356]]\n",
      "Loss: \n",
      " 0.007521217866073027\n",
      "\n",
      "\n",
      "Epoch: 86\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8259015 ]\n",
      " [0.77318391]\n",
      " [0.81346702]]\n",
      "Loss: \n",
      " 0.007416286037740912\n",
      "\n",
      "\n",
      "Epoch: 87\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.82648077]\n",
      " [0.77384226]\n",
      " [0.81403404]]\n",
      "Loss: \n",
      " 0.007313276348853512\n",
      "\n",
      "\n",
      "Epoch: 88\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.82705329]\n",
      " [0.77449336]\n",
      " [0.81459471]]\n",
      "Loss: \n",
      " 0.007212144480801389\n",
      "\n",
      "\n",
      "Epoch: 89\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.82761917]\n",
      " [0.77513732]\n",
      " [0.81514915]]\n",
      "Loss: \n",
      " 0.00711284735185277\n",
      "\n",
      "\n",
      "Epoch: 90\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.82817853]\n",
      " [0.77577425]\n",
      " [0.81569744]]\n",
      "Loss: \n",
      " 0.007015343076799878\n",
      "\n",
      "\n",
      "Epoch: 91\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.82873148]\n",
      " [0.77640426]\n",
      " [0.81623969]]\n",
      "Loss: \n",
      " 0.006919590928102293\n",
      "\n",
      "\n",
      "Epoch: 92\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.82927812]\n",
      " [0.77702747]\n",
      " [0.816776  ]]\n",
      "Loss: \n",
      " 0.006825551298465471\n",
      "\n",
      "\n",
      "Epoch: 93\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.82981855]\n",
      " [0.77764399]\n",
      " [0.81730646]]\n",
      "Loss: \n",
      " 0.00673318566479567\n",
      "\n",
      "\n",
      "Epoch: 94\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.83035289]\n",
      " [0.7782539 ]\n",
      " [0.81783116]]\n",
      "Loss: \n",
      " 0.006642456553474535\n",
      "\n",
      "\n",
      "Epoch: 95\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.83088122]\n",
      " [0.77885733]\n",
      " [0.8183502 ]]\n",
      "Loss: \n",
      " 0.006553327506899992\n",
      "\n",
      "\n",
      "Epoch: 96\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.83140365]\n",
      " [0.77945437]\n",
      " [0.81886366]]\n",
      "Loss: \n",
      " 0.006465763051241712\n",
      "\n",
      "\n",
      "Epoch: 97\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.83192028]\n",
      " [0.78004512]\n",
      " [0.81937164]]\n",
      "Loss: \n",
      " 0.006379728665362125\n",
      "\n",
      "\n",
      "Epoch: 98\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.83243119]\n",
      " [0.78062967]\n",
      " [0.81987421]]\n",
      "Loss: \n",
      " 0.006295190750856046\n",
      "\n",
      "\n",
      "Epoch: 99\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.83293648]\n",
      " [0.78120813]\n",
      " [0.82037146]]\n",
      "Loss: \n",
      " 0.006212116603163957\n",
      "\n",
      "\n",
      "Epoch: 100\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.83343624]\n",
      " [0.78178057]\n",
      " [0.82086347]]\n",
      "Loss: \n",
      " 0.006130474383716109\n",
      "\n",
      "\n",
      "Epoch: 101\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.83393056]\n",
      " [0.7823471 ]\n",
      " [0.82135033]]\n",
      "Loss: \n",
      " 0.006050233093066359\n",
      "\n",
      "\n",
      "Epoch: 102\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.83441952]\n",
      " [0.78290781]\n",
      " [0.8218321 ]]\n",
      "Loss: \n",
      " 0.005971362544976544\n",
      "\n",
      "\n",
      "Epoch: 103\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8349032 ]\n",
      " [0.78346277]\n",
      " [0.82230888]]\n",
      "Loss: \n",
      " 0.005893833341413712\n",
      "\n",
      "\n",
      "Epoch: 104\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8353817 ]\n",
      " [0.78401209]\n",
      " [0.82278073]]\n",
      "Loss: \n",
      " 0.005817616848424634\n",
      "\n",
      "\n",
      "Epoch: 105\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.83585509]\n",
      " [0.78455583]\n",
      " [0.82324773]]\n",
      "Loss: \n",
      " 0.005742685172852722\n",
      "\n",
      "\n",
      "Epoch: 106\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.83632345]\n",
      " [0.78509408]\n",
      " [0.82370994]]\n",
      "Loss: \n",
      " 0.005669011139865028\n",
      "\n",
      "\n",
      "Epoch: 107\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.83678685]\n",
      " [0.78562693]\n",
      " [0.82416745]]\n",
      "Loss: \n",
      " 0.005596568271257383\n",
      "\n",
      "\n",
      "Epoch: 108\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.83724538]\n",
      " [0.78615446]\n",
      " [0.82462033]]\n",
      "Loss: \n",
      " 0.005525330764507899\n",
      "\n",
      "\n",
      "Epoch: 109\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.83769912]\n",
      " [0.78667673]\n",
      " [0.82506863]]\n",
      "Loss: \n",
      " 0.005455273472549736\n",
      "\n",
      "\n",
      "Epoch: 110\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.83814812]\n",
      " [0.78719383]\n",
      " [0.82551243]]\n",
      "Loss: \n",
      " 0.005386371884235513\n",
      "\n",
      "\n",
      "Epoch: 111\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.83859246]\n",
      " [0.78770583]\n",
      " [0.82595179]]\n",
      "Loss: \n",
      " 0.005318602105467227\n",
      "\n",
      "\n",
      "Epoch: 112\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.83903223]\n",
      " [0.78821281]\n",
      " [0.82638679]]\n",
      "Loss: \n",
      " 0.005251940840965888\n",
      "\n",
      "\n",
      "Epoch: 113\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.83946747]\n",
      " [0.78871483]\n",
      " [0.82681747]]\n",
      "Loss: \n",
      " 0.00518636537665688\n",
      "\n",
      "\n",
      "Epoch: 114\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.83989826]\n",
      " [0.78921197]\n",
      " [0.82724391]]\n",
      "Loss: \n",
      " 0.0051218535626476455\n",
      "\n",
      "\n",
      "Epoch: 115\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.84032467]\n",
      " [0.7897043 ]\n",
      " [0.82766616]]\n",
      "Loss: \n",
      " 0.005058383796775434\n",
      "\n",
      "\n",
      "Epoch: 116\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.84074677]\n",
      " [0.79019188]\n",
      " [0.82808428]]\n",
      "Loss: \n",
      " 0.004995935008703801\n",
      "\n",
      "\n",
      "Epoch: 117\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8411646 ]\n",
      " [0.79067478]\n",
      " [0.82849834]]\n",
      "Loss: \n",
      " 0.004934486644547175\n",
      "\n",
      "\n",
      "Epoch: 118\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.84157825]\n",
      " [0.79115307]\n",
      " [0.82890839]]\n",
      "Loss: \n",
      " 0.004874018652004064\n",
      "\n",
      "\n",
      "Epoch: 119\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.84198776]\n",
      " [0.79162681]\n",
      " [0.82931448]]\n",
      "Loss: \n",
      " 0.004814511465979895\n",
      "\n",
      "\n",
      "Epoch: 120\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8423932 ]\n",
      " [0.79209607]\n",
      " [0.82971668]]\n",
      "Loss: \n",
      " 0.004755945994681455\n",
      "\n",
      "\n",
      "Epoch: 121\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.84279463]\n",
      " [0.7925609 ]\n",
      " [0.83011503]]\n",
      "Loss: \n",
      " 0.004698303606165652\n",
      "\n",
      "\n",
      "Epoch: 122\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8431921 ]\n",
      " [0.79302137]\n",
      " [0.8305096 ]]\n",
      "Loss: \n",
      " 0.004641566115325849\n",
      "\n",
      "\n",
      "Epoch: 123\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.84358568]\n",
      " [0.79347753]\n",
      " [0.83090043]]\n",
      "Loss: \n",
      " 0.004585715771299821\n",
      "\n",
      "\n",
      "Epoch: 124\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.84397541]\n",
      " [0.79392945]\n",
      " [0.83128757]]\n",
      "Loss: \n",
      " 0.004530735245284215\n",
      "\n",
      "\n",
      "Epoch: 125\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.84436136]\n",
      " [0.79437718]\n",
      " [0.83167107]]\n",
      "Loss: \n",
      " 0.004476607618740472\n",
      "\n",
      "\n",
      "Epoch: 126\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.84474357]\n",
      " [0.79482078]\n",
      " [0.83205099]]\n",
      "Loss: \n",
      " 0.004423316371978286\n",
      "\n",
      "\n",
      "Epoch: 127\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8451221 ]\n",
      " [0.7952603 ]\n",
      " [0.83242738]]\n",
      "Loss: \n",
      " 0.004370845373103085\n",
      "\n",
      "\n",
      "Epoch: 128\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.84549699]\n",
      " [0.7956958 ]\n",
      " [0.83280027]]\n",
      "Loss: \n",
      " 0.00431917886731428\n",
      "\n",
      "\n",
      "Epoch: 129\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.84586831]\n",
      " [0.79612734]\n",
      " [0.83316972]]\n",
      "Loss: \n",
      " 0.004268301466542202\n",
      "\n",
      "\n",
      "Epoch: 130\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8462361 ]\n",
      " [0.79655496]\n",
      " [0.83353578]]\n",
      "Loss: \n",
      " 0.004218198139411066\n",
      "\n",
      "\n",
      "Epoch: 131\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8466004 ]\n",
      " [0.79697872]\n",
      " [0.83389848]]\n",
      "Loss: \n",
      " 0.004168854201517162\n",
      "\n",
      "\n",
      "Epoch: 132\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.84696128]\n",
      " [0.79739866]\n",
      " [0.83425788]]\n",
      "Loss: \n",
      " 0.004120255306010498\n",
      "\n",
      "\n",
      "Epoch: 133\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.84731876]\n",
      " [0.79781485]\n",
      " [0.83461402]]\n",
      "Loss: \n",
      " 0.0040723874344697165\n",
      "\n",
      "\n",
      "Epoch: 134\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.84767291]\n",
      " [0.79822731]\n",
      " [0.83496694]]\n",
      "Loss: \n",
      " 0.004025236888059855\n",
      "\n",
      "\n",
      "Epoch: 135\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.84802376]\n",
      " [0.79863612]\n",
      " [0.83531668]]\n",
      "Loss: \n",
      " 0.00397879027896305\n",
      "\n",
      "\n",
      "Epoch: 136\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.84837136]\n",
      " [0.7990413 ]\n",
      " [0.83566329]]\n",
      "Loss: \n",
      " 0.003933034522072751\n",
      "\n",
      "\n",
      "Epoch: 137\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.84871575]\n",
      " [0.79944292]\n",
      " [0.8360068 ]]\n",
      "Loss: \n",
      " 0.0038879568269424443\n",
      "\n",
      "\n",
      "Epoch: 138\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.84905698]\n",
      " [0.79984101]\n",
      " [0.83634726]]\n",
      "Loss: \n",
      " 0.003843544689979951\n",
      "\n",
      "\n",
      "Epoch: 139\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.84939508]\n",
      " [0.80023561]\n",
      " [0.8366847 ]]\n",
      "Loss: \n",
      " 0.003799785886878977\n",
      "\n",
      "\n",
      "Epoch: 140\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.84973011]\n",
      " [0.80062678]\n",
      " [0.83701916]]\n",
      "Loss: \n",
      " 0.003756668465279821\n",
      "\n",
      "\n",
      "Epoch: 141\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.85006209]\n",
      " [0.80101456]\n",
      " [0.83735069]]\n",
      "Loss: \n",
      " 0.0037141807376513125\n",
      "\n",
      "\n",
      "Epoch: 142\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.85039108]\n",
      " [0.80139899]\n",
      " [0.83767932]]\n",
      "Loss: \n",
      " 0.0036723112743867066\n",
      "\n",
      "\n",
      "Epoch: 143\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.85071711]\n",
      " [0.80178011]\n",
      " [0.83800508]]\n",
      "Loss: \n",
      " 0.003631048897106031\n",
      "\n",
      "\n",
      "Epoch: 144\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.85104021]\n",
      " [0.80215796]\n",
      " [0.83832802]]\n",
      "Loss: \n",
      " 0.0035903826721581343\n",
      "\n",
      "\n",
      "Epoch: 145\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.85136043]\n",
      " [0.80253259]\n",
      " [0.83864816]]\n",
      "Loss: \n",
      " 0.0035503019043156806\n",
      "\n",
      "\n",
      "Epoch: 146\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8516778 ]\n",
      " [0.80290403]\n",
      " [0.83896554]]\n",
      "Loss: \n",
      " 0.0035107961306566036\n",
      "\n",
      "\n",
      "Epoch: 147\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.85199237]\n",
      " [0.80327232]\n",
      " [0.83928021]]\n",
      "Loss: \n",
      " 0.0034718551146258494\n",
      "\n",
      "\n",
      "Epoch: 148\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.85230416]\n",
      " [0.80363751]\n",
      " [0.83959218]]\n",
      "Loss: \n",
      " 0.0034334688402714642\n",
      "\n",
      "\n",
      "Epoch: 149\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.85261321]\n",
      " [0.80399962]\n",
      " [0.8399015 ]]\n",
      "Loss: \n",
      " 0.0033956275066492018\n",
      "\n",
      "\n",
      "Epoch: 150\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.85291955]\n",
      " [0.8043587 ]\n",
      " [0.84020819]]\n",
      "Loss: \n",
      " 0.003358321522390095\n",
      "\n",
      "\n",
      "Epoch: 151\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.85322323]\n",
      " [0.80471479]\n",
      " [0.8405123 ]]\n",
      "Loss: \n",
      " 0.0033215415004257003\n",
      "\n",
      "\n",
      "Epoch: 152\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.85352428]\n",
      " [0.80506791]\n",
      " [0.84081384]]\n",
      "Loss: \n",
      " 0.0032852782528658975\n",
      "\n",
      "\n",
      "Epoch: 153\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.85382272]\n",
      " [0.80541811]\n",
      " [0.84111286]]\n",
      "Loss: \n",
      " 0.0032495227860241172\n",
      "\n",
      "\n",
      "Epoch: 154\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.85411859]\n",
      " [0.80576542]\n",
      " [0.84140938]]\n",
      "Loss: \n",
      " 0.0032142662955854085\n",
      "\n",
      "\n",
      "Epoch: 155\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.85441192]\n",
      " [0.80610988]\n",
      " [0.84170343]]\n",
      "Loss: \n",
      " 0.0031795001619125615\n",
      "\n",
      "\n",
      "Epoch: 156\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.85470274]\n",
      " [0.80645151]\n",
      " [0.84199504]]\n",
      "Loss: \n",
      " 0.0031452159454859537\n",
      "\n",
      "\n",
      "Epoch: 157\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.85499109]\n",
      " [0.80679036]\n",
      " [0.84228425]]\n",
      "Loss: \n",
      " 0.003111405382472819\n",
      "\n",
      "\n",
      "Epoch: 158\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.855277  ]\n",
      " [0.80712646]\n",
      " [0.84257108]]\n",
      "Loss: \n",
      " 0.0030780603804217203\n",
      "\n",
      "\n",
      "Epoch: 159\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.85556049]\n",
      " [0.80745983]\n",
      " [0.84285555]]\n",
      "Loss: \n",
      " 0.003045173014078289\n",
      "\n",
      "\n",
      "Epoch: 160\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.85584159]\n",
      " [0.80779051]\n",
      " [0.84313771]]\n",
      "Loss: \n",
      " 0.0030127355213184076\n",
      "\n",
      "\n",
      "Epoch: 161\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.85612034]\n",
      " [0.80811854]\n",
      " [0.84341756]]\n",
      "Loss: \n",
      " 0.0029807402991951174\n",
      "\n",
      "\n",
      "Epoch: 162\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.85639676]\n",
      " [0.80844393]\n",
      " [0.84369515]]\n",
      "Loss: \n",
      " 0.0029491799000955898\n",
      "\n",
      "\n",
      "Epoch: 163\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.85667088]\n",
      " [0.80876673]\n",
      " [0.84397049]]\n",
      "Loss: \n",
      " 0.0029180470280047673\n",
      "\n",
      "\n",
      "Epoch: 164\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.85694273]\n",
      " [0.80908696]\n",
      " [0.84424362]]\n",
      "Loss: \n",
      " 0.0028873345348723774\n",
      "\n",
      "\n",
      "Epoch: 165\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.85721233]\n",
      " [0.80940465]\n",
      " [0.84451456]]\n",
      "Loss: \n",
      " 0.0028570354170800003\n",
      "\n",
      "\n",
      "Epoch: 166\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.85747971]\n",
      " [0.80971983]\n",
      " [0.84478333]]\n",
      "Loss: \n",
      " 0.00282714281200514\n",
      "\n",
      "\n",
      "Epoch: 167\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8577449 ]\n",
      " [0.81003254]\n",
      " [0.84504997]]\n",
      "Loss: \n",
      " 0.002797649994679298\n",
      "\n",
      "\n",
      "Epoch: 168\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.85800793]\n",
      " [0.81034279]\n",
      " [0.84531448]]\n",
      "Loss: \n",
      " 0.0027685503745370904\n",
      "\n",
      "\n",
      "Epoch: 169\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.85826881]\n",
      " [0.81065061]\n",
      " [0.84557691]]\n",
      "Loss: \n",
      " 0.0027398374922537453\n",
      "\n",
      "\n",
      "Epoch: 170\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.85852758]\n",
      " [0.81095604]\n",
      " [0.84583727]]\n",
      "Loss: \n",
      " 0.0027115050166680835\n",
      "\n",
      "\n",
      "Epoch: 171\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.85878426]\n",
      " [0.8112591 ]\n",
      " [0.84609558]]\n",
      "Loss: \n",
      " 0.0026835467417885115\n",
      "\n",
      "\n",
      "Epoch: 172\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.85903887]\n",
      " [0.81155981]\n",
      " [0.84635187]]\n",
      "Loss: \n",
      " 0.0026559565838795043\n",
      "\n",
      "\n",
      "Epoch: 173\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.85929144]\n",
      " [0.81185821]\n",
      " [0.84660617]]\n",
      "Loss: \n",
      " 0.0026287285786259947\n",
      "\n",
      "\n",
      "Epoch: 174\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.85954199]\n",
      " [0.81215432]\n",
      " [0.84685848]]\n",
      "Loss: \n",
      " 0.0026018568783735345\n",
      "\n",
      "\n",
      "Epoch: 175\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.85979055]\n",
      " [0.81244815]\n",
      " [0.84710885]]\n",
      "Loss: \n",
      " 0.0025753357494417268\n",
      "\n",
      "\n",
      "Epoch: 176\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86003713]\n",
      " [0.81273975]\n",
      " [0.84735728]]\n",
      "Loss: \n",
      " 0.0025491595695088655\n",
      "\n",
      "\n",
      "Epoch: 177\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86028176]\n",
      " [0.81302913]\n",
      " [0.8476038 ]]\n",
      "Loss: \n",
      " 0.0025233228250656913\n",
      "\n",
      "\n",
      "Epoch: 178\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86052446]\n",
      " [0.81331632]\n",
      " [0.84784843]]\n",
      "Loss: \n",
      " 0.0024978201089359844\n",
      "\n",
      "\n",
      "Epoch: 179\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86076526]\n",
      " [0.81360133]\n",
      " [0.8480912 ]]\n",
      "Loss: \n",
      " 0.002472646117862286\n",
      "\n",
      "\n",
      "Epoch: 180\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86100417]\n",
      " [0.81388421]\n",
      " [0.84833211]]\n",
      "Loss: \n",
      " 0.002447795650154658\n",
      "\n",
      "\n",
      "Epoch: 181\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86124122]\n",
      " [0.81416496]\n",
      " [0.8485712 ]]\n",
      "Loss: \n",
      " 0.0024232636034006035\n",
      "\n",
      "\n",
      "Epoch: 182\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86147643]\n",
      " [0.81444361]\n",
      " [0.84880848]]\n",
      "Loss: \n",
      " 0.0023990449722345072\n",
      "\n",
      "\n",
      "Epoch: 183\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86170981]\n",
      " [0.81472018]\n",
      " [0.84904397]]\n",
      "Loss: \n",
      " 0.002375134846164604\n",
      "\n",
      "\n",
      "Epoch: 184\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8619414 ]\n",
      " [0.8149947 ]\n",
      " [0.84927769]]\n",
      "Loss: \n",
      " 0.0023515284074561017\n",
      "\n",
      "\n",
      "Epoch: 185\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8621712 ]\n",
      " [0.81526718]\n",
      " [0.84950966]]\n",
      "Loss: \n",
      " 0.0023282209290685493\n",
      "\n",
      "\n",
      "Epoch: 186\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86239924]\n",
      " [0.81553766]\n",
      " [0.8497399 ]]\n",
      "Loss: \n",
      " 0.002305207772646011\n",
      "\n",
      "\n",
      "Epoch: 187\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86262553]\n",
      " [0.81580615]\n",
      " [0.84996843]]\n",
      "Loss: \n",
      " 0.0022824843865585356\n",
      "\n",
      "\n",
      "Epoch: 188\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8628501 ]\n",
      " [0.81607266]\n",
      " [0.85019526]]\n",
      "Loss: \n",
      " 0.0022600463039933955\n",
      "\n",
      "\n",
      "Epoch: 189\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86307297]\n",
      " [0.81633723]\n",
      " [0.85042042]]\n",
      "Loss: \n",
      " 0.002237889141094648\n",
      "\n",
      "\n",
      "Epoch: 190\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86329415]\n",
      " [0.81659987]\n",
      " [0.85064391]]\n",
      "Loss: \n",
      " 0.002216008595149704\n",
      "\n",
      "\n",
      "Epoch: 191\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86351367]\n",
      " [0.8168606 ]\n",
      " [0.85086577]]\n",
      "Loss: \n",
      " 0.0021944004428214813\n",
      "\n",
      "\n",
      "Epoch: 192\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86373153]\n",
      " [0.81711945]\n",
      " [0.851086  ]]\n",
      "Loss: \n",
      " 0.0021730605384250035\n",
      "\n",
      "\n",
      "Epoch: 193\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86394776]\n",
      " [0.81737643]\n",
      " [0.85130463]]\n",
      "Loss: \n",
      " 0.0021519848122469013\n",
      "\n",
      "\n",
      "Epoch: 194\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86416238]\n",
      " [0.81763155]\n",
      " [0.85152166]]\n",
      "Loss: \n",
      " 0.002131169268906905\n",
      "\n",
      "\n",
      "Epoch: 195\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8643754 ]\n",
      " [0.81788485]\n",
      " [0.85173712]]\n",
      "Loss: \n",
      " 0.0021106099857600095\n",
      "\n",
      "\n",
      "Epoch: 196\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86458684]\n",
      " [0.81813634]\n",
      " [0.85195103]]\n",
      "Loss: \n",
      " 0.002090303111338116\n",
      "\n",
      "\n",
      "Epoch: 197\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86479671]\n",
      " [0.81838603]\n",
      " [0.85216339]]\n",
      "Loss: \n",
      " 0.0020702448638301686\n",
      "\n",
      "\n",
      "Epoch: 198\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86500504]\n",
      " [0.81863395]\n",
      " [0.85237422]]\n",
      "Loss: \n",
      " 0.002050431529599634\n",
      "\n",
      "\n",
      "Epoch: 199\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86521184]\n",
      " [0.81888011]\n",
      " [0.85258355]]\n",
      "Loss: \n",
      " 0.0020308594617383033\n",
      "\n",
      "\n",
      "Epoch: 200\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86541712]\n",
      " [0.81912454]\n",
      " [0.85279138]]\n",
      "Loss: \n",
      " 0.0020115250786554013\n",
      "\n",
      "\n",
      "Epoch: 201\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8656209 ]\n",
      " [0.81936724]\n",
      " [0.85299774]]\n",
      "Loss: \n",
      " 0.0019924248627011198\n",
      "\n",
      "\n",
      "Epoch: 202\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86582321]\n",
      " [0.81960824]\n",
      " [0.85320263]]\n",
      "Loss: \n",
      " 0.0019735553588234095\n",
      "\n",
      "\n",
      "Epoch: 203\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86602404]\n",
      " [0.81984755]\n",
      " [0.85340606]]\n",
      "Loss: \n",
      " 0.001954913173257391\n",
      "\n",
      "\n",
      "Epoch: 204\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86622342]\n",
      " [0.8200852 ]\n",
      " [0.85360807]]\n",
      "Loss: \n",
      " 0.0019364949722462832\n",
      "\n",
      "\n",
      "Epoch: 205\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86642136]\n",
      " [0.82032118]\n",
      " [0.85380865]]\n",
      "Loss: \n",
      " 0.0019182974807931304\n",
      "\n",
      "\n",
      "Epoch: 206\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86661788]\n",
      " [0.82055554]\n",
      " [0.85400783]]\n",
      "Loss: \n",
      " 0.0019003174814423626\n",
      "\n",
      "\n",
      "Epoch: 207\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86681299]\n",
      " [0.82078827]\n",
      " [0.85420562]]\n",
      "Loss: \n",
      " 0.0018825518130904636\n",
      "\n",
      "\n",
      "Epoch: 208\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86700671]\n",
      " [0.82101939]\n",
      " [0.85440203]]\n",
      "Loss: \n",
      " 0.0018649973698249833\n",
      "\n",
      "\n",
      "Epoch: 209\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86719905]\n",
      " [0.82124893]\n",
      " [0.85459707]]\n",
      "Loss: \n",
      " 0.001847651099791062\n",
      "\n",
      "\n",
      "Epoch: 210\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86739002]\n",
      " [0.82147689]\n",
      " [0.85479076]]\n",
      "Loss: \n",
      " 0.0018305100040847597\n",
      "\n",
      "\n",
      "Epoch: 211\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86757964]\n",
      " [0.8217033 ]\n",
      " [0.85498312]]\n",
      "Loss: \n",
      " 0.0018135711356725053\n",
      "\n",
      "\n",
      "Epoch: 212\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86776792]\n",
      " [0.82192816]\n",
      " [0.85517415]]\n",
      "Loss: \n",
      " 0.0017968315983358778\n",
      "\n",
      "\n",
      "Epoch: 213\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86795488]\n",
      " [0.8221515 ]\n",
      " [0.85536387]]\n",
      "Loss: \n",
      " 0.0017802885456411571\n",
      "\n",
      "\n",
      "Epoch: 214\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86814053]\n",
      " [0.82237332]\n",
      " [0.85555228]]\n",
      "Loss: \n",
      " 0.0017639391799329416\n",
      "\n",
      "\n",
      "Epoch: 215\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86832487]\n",
      " [0.82259364]\n",
      " [0.85573942]]\n",
      "Loss: \n",
      " 0.0017477807513511497\n",
      "\n",
      "\n",
      "Epoch: 216\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86850793]\n",
      " [0.82281247]\n",
      " [0.85592528]]\n",
      "Loss: \n",
      " 0.0017318105568708527\n",
      "\n",
      "\n",
      "Epoch: 217\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86868972]\n",
      " [0.82302984]\n",
      " [0.85610987]]\n",
      "Loss: \n",
      " 0.0017160259393643868\n",
      "\n",
      "\n",
      "Epoch: 218\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86887025]\n",
      " [0.82324575]\n",
      " [0.85629322]]\n",
      "Loss: \n",
      " 0.0017004242866849569\n",
      "\n",
      "\n",
      "Epoch: 219\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86904953]\n",
      " [0.82346022]\n",
      " [0.85647533]]\n",
      "Loss: \n",
      " 0.0016850030307714325\n",
      "\n",
      "\n",
      "Epoch: 220\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86922758]\n",
      " [0.82367326]\n",
      " [0.85665622]]\n",
      "Loss: \n",
      " 0.0016697596467736223\n",
      "\n",
      "\n",
      "Epoch: 221\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8694044 ]\n",
      " [0.82388488]\n",
      " [0.85683589]]\n",
      "Loss: \n",
      " 0.0016546916521974944\n",
      "\n",
      "\n",
      "Epoch: 222\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86958001]\n",
      " [0.8240951 ]\n",
      " [0.85701436]]\n",
      "Loss: \n",
      " 0.0016397966060699553\n",
      "\n",
      "\n",
      "Epoch: 223\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86975442]\n",
      " [0.82430393]\n",
      " [0.85719164]]\n",
      "Loss: \n",
      " 0.0016250721081224892\n",
      "\n",
      "\n",
      "Epoch: 224\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86992764]\n",
      " [0.82451139]\n",
      " [0.85736773]]\n",
      "Loss: \n",
      " 0.0016105157979934114\n",
      "\n",
      "\n",
      "Epoch: 225\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87009969]\n",
      " [0.82471748]\n",
      " [0.85754266]]\n",
      "Loss: \n",
      " 0.0015961253544479826\n",
      "\n",
      "\n",
      "Epoch: 226\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87027057]\n",
      " [0.82492223]\n",
      " [0.85771643]]\n",
      "Loss: \n",
      " 0.0015818984946161946\n",
      "\n",
      "\n",
      "Epoch: 227\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87044029]\n",
      " [0.82512563]\n",
      " [0.85788906]]\n",
      "Loss: \n",
      " 0.0015678329732475953\n",
      "\n",
      "\n",
      "Epoch: 228\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87060887]\n",
      " [0.82532771]\n",
      " [0.85806055]]\n",
      "Loss: \n",
      " 0.0015539265819827918\n",
      "\n",
      "\n",
      "Epoch: 229\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87077632]\n",
      " [0.82552847]\n",
      " [0.85823091]]\n",
      "Loss: \n",
      " 0.0015401771486412256\n",
      "\n",
      "\n",
      "Epoch: 230\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87094265]\n",
      " [0.82572794]\n",
      " [0.85840016]]\n",
      "Loss: \n",
      " 0.0015265825365247114\n",
      "\n",
      "\n",
      "Epoch: 231\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87110787]\n",
      " [0.82592611]\n",
      " [0.8585683 ]]\n",
      "Loss: \n",
      " 0.0015131406437365307\n",
      "\n",
      "\n",
      "Epoch: 232\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87127199]\n",
      " [0.82612301]\n",
      " [0.85873535]]\n",
      "Loss: \n",
      " 0.001499849402515468\n",
      "\n",
      "\n",
      "Epoch: 233\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87143501]\n",
      " [0.82631864]\n",
      " [0.85890131]]\n",
      "Loss: \n",
      " 0.0014867067785845718\n",
      "\n",
      "\n",
      "Epoch: 234\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87159696]\n",
      " [0.82651302]\n",
      " [0.8590662 ]]\n",
      "Loss: \n",
      " 0.0014737107705142206\n",
      "\n",
      "\n",
      "Epoch: 235\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87175784]\n",
      " [0.82670615]\n",
      " [0.85923003]]\n",
      "Loss: \n",
      " 0.0014608594090991477\n",
      "\n",
      "\n",
      "Epoch: 236\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87191765]\n",
      " [0.82689805]\n",
      " [0.85939279]]\n",
      "Loss: \n",
      " 0.0014481507567490495\n",
      "\n",
      "\n",
      "Epoch: 237\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87207642]\n",
      " [0.82708873]\n",
      " [0.85955452]]\n",
      "Loss: \n",
      " 0.0014355829068924597\n",
      "\n",
      "\n",
      "Epoch: 238\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87223415]\n",
      " [0.8272782 ]\n",
      " [0.8597152 ]]\n",
      "Loss: \n",
      " 0.0014231539833936208\n",
      "\n",
      "\n",
      "Epoch: 239\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87239084]\n",
      " [0.82746646]\n",
      " [0.85987486]]\n",
      "Loss: \n",
      " 0.0014108621399819274\n",
      "\n",
      "\n",
      "Epoch: 240\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87254652]\n",
      " [0.82765355]\n",
      " [0.86003351]]\n",
      "Loss: \n",
      " 0.001398705559693715\n",
      "\n",
      "\n",
      "Epoch: 241\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87270118]\n",
      " [0.82783945]\n",
      " [0.86019114]]\n",
      "Loss: \n",
      " 0.0013866824543260464\n",
      "\n",
      "\n",
      "Epoch: 242\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87285484]\n",
      " [0.82802418]\n",
      " [0.86034777]]\n",
      "Loss: \n",
      " 0.001374791063902199\n",
      "\n",
      "\n",
      "Epoch: 243\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87300751]\n",
      " [0.82820776]\n",
      " [0.86050342]]\n",
      "Loss: \n",
      " 0.0013630296561486746\n",
      "\n",
      "\n",
      "Epoch: 244\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8731592 ]\n",
      " [0.82839019]\n",
      " [0.86065808]]\n",
      "Loss: \n",
      " 0.0013513965259832755\n",
      "\n",
      "\n",
      "Epoch: 245\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8733099 ]\n",
      " [0.82857148]\n",
      " [0.86081176]]\n",
      "Loss: \n",
      " 0.0013398899950141322\n",
      "\n",
      "\n",
      "Epoch: 246\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87345964]\n",
      " [0.82875165]\n",
      " [0.86096449]]\n",
      "Loss: \n",
      " 0.001328508411049321\n",
      "\n",
      "\n",
      "Epoch: 247\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87360843]\n",
      " [0.82893069]\n",
      " [0.86111626]]\n",
      "Loss: \n",
      " 0.0013172501476168723\n",
      "\n",
      "\n",
      "Epoch: 248\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87375626]\n",
      " [0.82910863]\n",
      " [0.86126708]]\n",
      "Loss: \n",
      " 0.0013061136034949357\n",
      "\n",
      "\n",
      "Epoch: 249\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87390316]\n",
      " [0.82928547]\n",
      " [0.86141696]]\n",
      "Loss: \n",
      " 0.001295097202251767\n",
      "\n",
      "\n",
      "Epoch: 250\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87404912]\n",
      " [0.82946123]\n",
      " [0.8615659 ]]\n",
      "Loss: \n",
      " 0.0012841993917954162\n",
      "\n",
      "\n",
      "Epoch: 251\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87419415]\n",
      " [0.8296359 ]\n",
      " [0.86171393]]\n",
      "Loss: \n",
      " 0.0012734186439328193\n",
      "\n",
      "\n",
      "Epoch: 252\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87433827]\n",
      " [0.8298095 ]\n",
      " [0.86186104]]\n",
      "Loss: \n",
      " 0.0012627534539380624\n",
      "\n",
      "\n",
      "Epoch: 253\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87448149]\n",
      " [0.82998205]\n",
      " [0.86200724]]\n",
      "Loss: \n",
      " 0.001252202340129642\n",
      "\n",
      "\n",
      "Epoch: 254\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8746238 ]\n",
      " [0.83015354]\n",
      " [0.86215255]]\n",
      "Loss: \n",
      " 0.0012417638434565313\n",
      "\n",
      "\n",
      "Epoch: 255\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87476522]\n",
      " [0.83032398]\n",
      " [0.86229696]]\n",
      "Loss: \n",
      " 0.0012314365270927532\n",
      "\n",
      "\n",
      "Epoch: 256\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87490576]\n",
      " [0.8304934 ]\n",
      " [0.86244049]]\n",
      "Loss: \n",
      " 0.001221218976040325\n",
      "\n",
      "\n",
      "Epoch: 257\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87504542]\n",
      " [0.83066178]\n",
      " [0.86258314]]\n",
      "Loss: \n",
      " 0.0012111097967403834\n",
      "\n",
      "\n",
      "Epoch: 258\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87518421]\n",
      " [0.83082915]\n",
      " [0.86272492]]\n",
      "Loss: \n",
      " 0.0012011076166923223\n",
      "\n",
      "\n",
      "Epoch: 259\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87532215]\n",
      " [0.83099552]\n",
      " [0.86286584]]\n",
      "Loss: \n",
      " 0.001191211084080629\n",
      "\n",
      "\n",
      "Epoch: 260\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87545922]\n",
      " [0.83116088]\n",
      " [0.86300591]]\n",
      "Loss: \n",
      " 0.0011814188674094102\n",
      "\n",
      "\n",
      "Epoch: 261\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87559546]\n",
      " [0.83132525]\n",
      " [0.86314513]]\n",
      "Loss: \n",
      " 0.001171729655144333\n",
      "\n",
      "\n",
      "Epoch: 262\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87573085]\n",
      " [0.83148864]\n",
      " [0.86328351]]\n",
      "Loss: \n",
      " 0.0011621421553618084\n",
      "\n",
      "\n",
      "Epoch: 263\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87586541]\n",
      " [0.83165106]\n",
      " [0.86342105]]\n",
      "Loss: \n",
      " 0.0011526550954052974\n",
      "\n",
      "\n",
      "Epoch: 264\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87599915]\n",
      " [0.8318125 ]\n",
      " [0.86355777]]\n",
      "Loss: \n",
      " 0.0011432672215485613\n",
      "\n",
      "\n",
      "Epoch: 265\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87613206]\n",
      " [0.83197299]\n",
      " [0.86369367]]\n",
      "Loss: \n",
      " 0.001133977298665622\n",
      "\n",
      "\n",
      "Epoch: 266\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87626417]\n",
      " [0.83213253]\n",
      " [0.86382876]]\n",
      "Loss: \n",
      " 0.0011247841099074252\n",
      "\n",
      "\n",
      "Epoch: 267\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87639548]\n",
      " [0.83229112]\n",
      " [0.86396305]]\n",
      "Loss: \n",
      " 0.0011156864563849603\n",
      "\n",
      "\n",
      "Epoch: 268\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87652598]\n",
      " [0.83244878]\n",
      " [0.86409653]]\n",
      "Loss: \n",
      " 0.0011066831568586118\n",
      "\n",
      "\n",
      "Epoch: 269\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8766557 ]\n",
      " [0.83260551]\n",
      " [0.86422922]]\n",
      "Loss: \n",
      " 0.0010977730474338683\n",
      "\n",
      "\n",
      "Epoch: 270\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87678464]\n",
      " [0.83276132]\n",
      " [0.86436113]]\n",
      "Loss: \n",
      " 0.0010889549812628835\n",
      "\n",
      "\n",
      "Epoch: 271\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87691279]\n",
      " [0.83291622]\n",
      " [0.86449226]]\n",
      "Loss: \n",
      " 0.0010802278282520895\n",
      "\n",
      "\n",
      "Epoch: 272\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87704018]\n",
      " [0.83307021]\n",
      " [0.86462261]]\n",
      "Loss: \n",
      " 0.0010715904747754942\n",
      "\n",
      "\n",
      "Epoch: 273\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8771668 ]\n",
      " [0.83322331]\n",
      " [0.8647522 ]]\n",
      "Loss: \n",
      " 0.0010630418233936833\n",
      "\n",
      "\n",
      "Epoch: 274\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87729267]\n",
      " [0.83337551]\n",
      " [0.86488103]]\n",
      "Loss: \n",
      " 0.0010545807925782917\n",
      "\n",
      "\n",
      "Epoch: 275\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87741778]\n",
      " [0.83352683]\n",
      " [0.8650091 ]]\n",
      "Loss: \n",
      " 0.0010462063164419215\n",
      "\n",
      "\n",
      "Epoch: 276\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87754215]\n",
      " [0.83367728]\n",
      " [0.86513642]]\n",
      "Loss: \n",
      " 0.0010379173444733034\n",
      "\n",
      "\n",
      "Epoch: 277\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87766578]\n",
      " [0.83382685]\n",
      " [0.86526301]]\n",
      "Loss: \n",
      " 0.001029712841277611\n",
      "\n",
      "\n",
      "Epoch: 278\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87778868]\n",
      " [0.83397557]\n",
      " [0.86538885]]\n",
      "Loss: \n",
      " 0.0010215917863218545\n",
      "\n",
      "\n",
      "Epoch: 279\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87791085]\n",
      " [0.83412342]\n",
      " [0.86551397]]\n",
      "Loss: \n",
      " 0.0010135531736851998\n",
      "\n",
      "\n",
      "Epoch: 280\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8780323 ]\n",
      " [0.83427043]\n",
      " [0.86563836]]\n",
      "Loss: \n",
      " 0.001005596011814098\n",
      "\n",
      "\n",
      "Epoch: 281\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87815303]\n",
      " [0.8344166 ]\n",
      " [0.86576204]]\n",
      "Loss: \n",
      " 0.000997719323282128\n",
      "\n",
      "\n",
      "Epoch: 282\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87827306]\n",
      " [0.83456193]\n",
      " [0.865885  ]]\n",
      "Loss: \n",
      " 0.000989922144554519\n",
      "\n",
      "\n",
      "Epoch: 283\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87839238]\n",
      " [0.83470643]\n",
      " [0.86600725]]\n",
      "Loss: \n",
      " 0.0009822035257571196\n",
      "\n",
      "\n",
      "Epoch: 284\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.878511  ]\n",
      " [0.83485011]\n",
      " [0.86612881]]\n",
      "Loss: \n",
      " 0.0009745625304498111\n",
      "\n",
      "\n",
      "Epoch: 285\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87862894]\n",
      " [0.83499297]\n",
      " [0.86624967]]\n",
      "Loss: \n",
      " 0.0009669982354042628\n",
      "\n",
      "\n",
      "Epoch: 286\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87874618]\n",
      " [0.83513503]\n",
      " [0.86636983]]\n",
      "Loss: \n",
      " 0.00095950973038591\n",
      "\n",
      "\n",
      "Epoch: 287\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87886275]\n",
      " [0.83527628]\n",
      " [0.86648931]]\n",
      "Loss: \n",
      " 0.0009520961179400444\n",
      "\n",
      "\n",
      "Epoch: 288\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87897864]\n",
      " [0.83541673]\n",
      " [0.86660812]]\n",
      "Loss: \n",
      " 0.0009447565131820023\n",
      "\n",
      "\n",
      "Epoch: 289\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87909386]\n",
      " [0.8355564 ]\n",
      " [0.86672624]]\n",
      "Loss: \n",
      " 0.0009374900435912678\n",
      "\n",
      "\n",
      "Epoch: 290\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87920841]\n",
      " [0.83569528]\n",
      " [0.8668437 ]]\n",
      "Loss: \n",
      " 0.00093029584880948\n",
      "\n",
      "\n",
      "Epoch: 291\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87932231]\n",
      " [0.83583338]\n",
      " [0.8669605 ]]\n",
      "Loss: \n",
      " 0.0009231730804422708\n",
      "\n",
      "\n",
      "Epoch: 292\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87943555]\n",
      " [0.8359707 ]\n",
      " [0.86707663]]\n",
      "Loss: \n",
      " 0.0009161209018647234\n",
      "\n",
      "\n",
      "Epoch: 293\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87954814]\n",
      " [0.83610726]\n",
      " [0.86719212]]\n",
      "Loss: \n",
      " 0.0009091384880305694\n",
      "\n",
      "\n",
      "Epoch: 294\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87966009]\n",
      " [0.83624306]\n",
      " [0.86730695]]\n",
      "Loss: \n",
      " 0.0009022250252848854\n",
      "\n",
      "\n",
      "Epoch: 295\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8797714 ]\n",
      " [0.83637811]\n",
      " [0.86742114]]\n",
      "Loss: \n",
      " 0.0008953797111802843\n",
      "\n",
      "\n",
      "Epoch: 296\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87988207]\n",
      " [0.8365124 ]\n",
      " [0.86753469]]\n",
      "Loss: \n",
      " 0.0008886017542965558\n",
      "\n",
      "\n",
      "Epoch: 297\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87999212]\n",
      " [0.83664595]\n",
      " [0.86764761]]\n",
      "Loss: \n",
      " 0.0008818903740635532\n",
      "\n",
      "\n",
      "Epoch: 298\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88010154]\n",
      " [0.83677877]\n",
      " [0.8677599 ]]\n",
      "Loss: \n",
      " 0.0008752448005874776\n",
      "\n",
      "\n",
      "Epoch: 299\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88021035]\n",
      " [0.83691085]\n",
      " [0.86787157]]\n",
      "Loss: \n",
      " 0.0008686642744802541\n",
      "\n",
      "\n",
      "Epoch: 300\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88031854]\n",
      " [0.8370422 ]\n",
      " [0.86798262]]\n",
      "Loss: \n",
      " 0.0008621480466920994\n",
      "\n",
      "\n",
      "Epoch: 301\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88042612]\n",
      " [0.83717284]\n",
      " [0.86809305]]\n",
      "Loss: \n",
      " 0.0008556953783471401\n",
      "\n",
      "\n",
      "Epoch: 302\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88053309]\n",
      " [0.83730276]\n",
      " [0.86820287]]\n",
      "Loss: \n",
      " 0.0008493055405820392\n",
      "\n",
      "\n",
      "Epoch: 303\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88063947]\n",
      " [0.83743196]\n",
      " [0.86831209]]\n",
      "Loss: \n",
      " 0.0008429778143875712\n",
      "\n",
      "\n",
      "Epoch: 304\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88074525]\n",
      " [0.83756046]\n",
      " [0.8684207 ]]\n",
      "Loss: \n",
      " 0.0008367114904530578\n",
      "\n",
      "\n",
      "Epoch: 305\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88085044]\n",
      " [0.83768826]\n",
      " [0.86852872]]\n",
      "Loss: \n",
      " 0.000830505869013681\n",
      "\n",
      "\n",
      "Epoch: 306\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88095504]\n",
      " [0.83781537]\n",
      " [0.86863615]]\n",
      "Loss: \n",
      " 0.0008243602597004734\n",
      "\n",
      "\n",
      "Epoch: 307\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88105906]\n",
      " [0.83794179]\n",
      " [0.86874299]]\n",
      "Loss: \n",
      " 0.0008182739813931123\n",
      "\n",
      "\n",
      "Epoch: 308\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8811625 ]\n",
      " [0.83806752]\n",
      " [0.86884925]]\n",
      "Loss: \n",
      " 0.0008122463620752973\n",
      "\n",
      "\n",
      "Epoch: 309\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88126537]\n",
      " [0.83819257]\n",
      " [0.86895493]]\n",
      "Loss: \n",
      " 0.0008062767386927619\n",
      "\n",
      "\n",
      "Epoch: 310\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88136768]\n",
      " [0.83831695]\n",
      " [0.86906003]]\n",
      "Loss: \n",
      " 0.0008003644570138145\n",
      "\n",
      "\n",
      "Epoch: 311\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88146941]\n",
      " [0.83844066]\n",
      " [0.86916457]]\n",
      "Loss: \n",
      " 0.0007945088714923846\n",
      "\n",
      "\n",
      "Epoch: 312\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88157059]\n",
      " [0.8385637 ]\n",
      " [0.86926853]]\n",
      "Loss: \n",
      " 0.0007887093451334996\n",
      "\n",
      "\n",
      "Epoch: 313\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88167121]\n",
      " [0.83868609]\n",
      " [0.86937194]]\n",
      "Loss: \n",
      " 0.0007829652493611948\n",
      "\n",
      "\n",
      "Epoch: 314\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88177128]\n",
      " [0.83880782]\n",
      " [0.86947479]]\n",
      "Loss: \n",
      " 0.0007772759638886859\n",
      "\n",
      "\n",
      "Epoch: 315\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8818708 ]\n",
      " [0.83892889]\n",
      " [0.86957709]]\n",
      "Loss: \n",
      " 0.0007716408765909465\n",
      "\n",
      "\n",
      "Epoch: 316\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88196978]\n",
      " [0.83904933]\n",
      " [0.86967883]]\n",
      "Loss: \n",
      " 0.0007660593833794645\n",
      "\n",
      "\n",
      "Epoch: 317\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88206822]\n",
      " [0.83916912]\n",
      " [0.86978003]]\n",
      "Loss: \n",
      " 0.0007605308880792217\n",
      "\n",
      "\n",
      "Epoch: 318\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88216612]\n",
      " [0.83928827]\n",
      " [0.86988069]]\n",
      "Loss: \n",
      " 0.0007550548023078571\n",
      "\n",
      "\n",
      "Epoch: 319\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88226349]\n",
      " [0.8394068 ]\n",
      " [0.86998082]]\n",
      "Loss: \n",
      " 0.0007496305453569378\n",
      "\n",
      "\n",
      "Epoch: 320\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88236034]\n",
      " [0.8395247 ]\n",
      " [0.8700804 ]]\n",
      "Loss: \n",
      " 0.0007442575440752947\n",
      "\n",
      "\n",
      "Epoch: 321\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88245666]\n",
      " [0.83964197]\n",
      " [0.87017946]]\n",
      "Loss: \n",
      " 0.000738935232754419\n",
      "\n",
      "\n",
      "Epoch: 322\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88255246]\n",
      " [0.83975863]\n",
      " [0.870278  ]]\n",
      "Loss: \n",
      " 0.000733663053015858\n",
      "\n",
      "\n",
      "Epoch: 323\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88264774]\n",
      " [0.83987467]\n",
      " [0.87037601]]\n",
      "Loss: \n",
      " 0.0007284404537005335\n",
      "\n",
      "\n",
      "Epoch: 324\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88274251]\n",
      " [0.8399901 ]\n",
      " [0.8704735 ]]\n",
      "Loss: \n",
      " 0.0007232668907600241\n",
      "\n",
      "\n",
      "Epoch: 325\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88283678]\n",
      " [0.84010493]\n",
      " [0.87057048]]\n",
      "Loss: \n",
      " 0.000718141827149684\n",
      "\n",
      "\n",
      "Epoch: 326\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88293054]\n",
      " [0.84021915]\n",
      " [0.87066694]]\n",
      "Loss: \n",
      " 0.0007130647327236676\n",
      "\n",
      "\n",
      "Epoch: 327\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88302379]\n",
      " [0.84033278]\n",
      " [0.8707629 ]]\n",
      "Loss: \n",
      " 0.0007080350841316907\n",
      "\n",
      "\n",
      "Epoch: 328\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88311655]\n",
      " [0.84044582]\n",
      " [0.87085836]]\n",
      "Loss: \n",
      " 0.0007030523647176116\n",
      "\n",
      "\n",
      "Epoch: 329\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88320882]\n",
      " [0.84055827]\n",
      " [0.87095331]]\n",
      "Loss: \n",
      " 0.0006981160644197393\n",
      "\n",
      "\n",
      "Epoch: 330\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88330059]\n",
      " [0.84067014]\n",
      " [0.87104777]]\n",
      "Loss: \n",
      " 0.0006932256796728715\n",
      "\n",
      "\n",
      "Epoch: 331\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88339188]\n",
      " [0.84078142]\n",
      " [0.87114173]]\n",
      "Loss: \n",
      " 0.0006883807133119245\n",
      "\n",
      "\n",
      "Epoch: 332\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88348269]\n",
      " [0.84089213]\n",
      " [0.87123521]]\n",
      "Loss: \n",
      " 0.0006835806744773217\n",
      "\n",
      "\n",
      "Epoch: 333\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88357301]\n",
      " [0.84100227]\n",
      " [0.8713282 ]]\n",
      "Loss: \n",
      " 0.0006788250785218843\n",
      "\n",
      "\n",
      "Epoch: 334\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88366286]\n",
      " [0.84111184]\n",
      " [0.8714207 ]]\n",
      "Loss: \n",
      " 0.0006741134469193544\n",
      "\n",
      "\n",
      "Epoch: 335\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88375224]\n",
      " [0.84122084]\n",
      " [0.87151273]]\n",
      "Loss: \n",
      " 0.0006694453071744814\n",
      "\n",
      "\n",
      "Epoch: 336\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88384115]\n",
      " [0.84132929]\n",
      " [0.87160428]]\n",
      "Loss: \n",
      " 0.0006648201927345498\n",
      "\n",
      "\n",
      "Epoch: 337\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88392959]\n",
      " [0.84143718]\n",
      " [0.87169536]]\n",
      "Loss: \n",
      " 0.0006602376429024724\n",
      "\n",
      "\n",
      "Epoch: 338\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88401756]\n",
      " [0.84154451]\n",
      " [0.87178597]]\n",
      "Loss: \n",
      " 0.0006556972027513181\n",
      "\n",
      "\n",
      "Epoch: 339\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88410508]\n",
      " [0.8416513 ]\n",
      " [0.87187611]]\n",
      "Loss: \n",
      " 0.0006511984230402535\n",
      "\n",
      "\n",
      "Epoch: 340\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88419214]\n",
      " [0.84175754]\n",
      " [0.87196579]]\n",
      "Loss: \n",
      " 0.0006467408601319219\n",
      "\n",
      "\n",
      "Epoch: 341\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88427875]\n",
      " [0.84186325]\n",
      " [0.87205501]]\n",
      "Loss: \n",
      " 0.0006423240759111676\n",
      "\n",
      "\n",
      "Epoch: 342\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88436491]\n",
      " [0.84196841]\n",
      " [0.87214377]]\n",
      "Loss: \n",
      " 0.0006379476377051499\n",
      "\n",
      "\n",
      "Epoch: 343\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88445062]\n",
      " [0.84207304]\n",
      " [0.87223208]]\n",
      "Loss: \n",
      " 0.0006336111182047441\n",
      "\n",
      "\n",
      "Epoch: 344\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88453589]\n",
      " [0.84217714]\n",
      " [0.87231994]]\n",
      "Loss: \n",
      " 0.0006293140953872754\n",
      "\n",
      "\n",
      "Epoch: 345\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88462071]\n",
      " [0.84228071]\n",
      " [0.87240735]]\n",
      "Loss: \n",
      " 0.0006250561524405201\n",
      "\n",
      "\n",
      "Epoch: 346\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8847051 ]\n",
      " [0.84238377]\n",
      " [0.87249432]]\n",
      "Loss: \n",
      " 0.0006208368776879496\n",
      "\n",
      "\n",
      "Epoch: 347\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88478905]\n",
      " [0.8424863 ]\n",
      " [0.87258084]]\n",
      "Loss: \n",
      " 0.0006166558645152442\n",
      "\n",
      "\n",
      "Epoch: 348\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88487258]\n",
      " [0.84258831]\n",
      " [0.87266693]]\n",
      "Loss: \n",
      " 0.0006125127112979447\n",
      "\n",
      "\n",
      "Epoch: 349\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88495567]\n",
      " [0.84268981]\n",
      " [0.87275258]]\n",
      "Loss: \n",
      " 0.000608407021330358\n",
      "\n",
      "\n",
      "Epoch: 350\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88503834]\n",
      " [0.84279081]\n",
      " [0.8728378 ]]\n",
      "Loss: \n",
      " 0.0006043384027556007\n",
      "\n",
      "\n",
      "Epoch: 351\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88512058]\n",
      " [0.8428913 ]\n",
      " [0.87292259]]\n",
      "Loss: \n",
      " 0.0006003064684967713\n",
      "\n",
      "\n",
      "Epoch: 352\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88520241]\n",
      " [0.84299128]\n",
      " [0.87300696]]\n",
      "Loss: \n",
      " 0.0005963108361892424\n",
      "\n",
      "\n",
      "Epoch: 353\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88528382]\n",
      " [0.84309077]\n",
      " [0.8730909 ]]\n",
      "Loss: \n",
      " 0.0005923511281141002\n",
      "\n",
      "\n",
      "Epoch: 354\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88536481]\n",
      " [0.84318976]\n",
      " [0.87317442]]\n",
      "Loss: \n",
      " 0.0005884269711325846\n",
      "\n",
      "\n",
      "Epoch: 355\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88544539]\n",
      " [0.84328826]\n",
      " [0.87325752]]\n",
      "Loss: \n",
      " 0.0005845379966216603\n",
      "\n",
      "\n",
      "Epoch: 356\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88552557]\n",
      " [0.84338627]\n",
      " [0.8733402 ]]\n",
      "Loss: \n",
      " 0.0005806838404105922\n",
      "\n",
      "\n",
      "Epoch: 357\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88560534]\n",
      " [0.84348379]\n",
      " [0.87342248]]\n",
      "Loss: \n",
      " 0.0005768641427185518\n",
      "\n",
      "\n",
      "Epoch: 358\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8856847 ]\n",
      " [0.84358083]\n",
      " [0.87350434]]\n",
      "Loss: \n",
      " 0.00057307854809321\n",
      "\n",
      "\n",
      "Epoch: 359\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88576367]\n",
      " [0.84367739]\n",
      " [0.8735858 ]]\n",
      "Loss: \n",
      " 0.0005693267053503643\n",
      "\n",
      "\n",
      "Epoch: 360\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88584223]\n",
      " [0.84377348]\n",
      " [0.87366685]]\n",
      "Loss: \n",
      " 0.0005656082675144588\n",
      "\n",
      "\n",
      "Epoch: 361\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88592041]\n",
      " [0.84386909]\n",
      " [0.8737475 ]]\n",
      "Loss: \n",
      " 0.000561922891760109\n",
      "\n",
      "\n",
      "Epoch: 362\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88599819]\n",
      " [0.84396423]\n",
      " [0.87382775]]\n",
      "Loss: \n",
      " 0.000558270239354553\n",
      "\n",
      "\n",
      "Epoch: 363\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88607558]\n",
      " [0.84405891]\n",
      " [0.87390761]]\n",
      "Loss: \n",
      " 0.0005546499756009951\n",
      "\n",
      "\n",
      "Epoch: 364\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88615258]\n",
      " [0.84415312]\n",
      " [0.87398707]]\n",
      "Loss: \n",
      " 0.000551061769782848\n",
      "\n",
      "\n",
      "Epoch: 365\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8862292 ]\n",
      " [0.84424687]\n",
      " [0.87406614]]\n",
      "Loss: \n",
      " 0.0005475052951089005\n",
      "\n",
      "\n",
      "Epoch: 366\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88630544]\n",
      " [0.84434016]\n",
      " [0.87414482]]\n",
      "Loss: \n",
      " 0.0005439802286592984\n",
      "\n",
      "\n",
      "Epoch: 367\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8863813 ]\n",
      " [0.84443299]\n",
      " [0.87422312]]\n",
      "Loss: \n",
      " 0.0005404862513324016\n",
      "\n",
      "\n",
      "Epoch: 368\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88645678]\n",
      " [0.84452538]\n",
      " [0.87430103]]\n",
      "Loss: \n",
      " 0.0005370230477925019\n",
      "\n",
      "\n",
      "Epoch: 369\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88653189]\n",
      " [0.84461731]\n",
      " [0.87437856]]\n",
      "Loss: \n",
      " 0.0005335903064182848\n",
      "\n",
      "\n",
      "Epoch: 370\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88660662]\n",
      " [0.8447088 ]\n",
      " [0.87445571]]\n",
      "Loss: \n",
      " 0.0005301877192522042\n",
      "\n",
      "\n",
      "Epoch: 371\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88668099]\n",
      " [0.84479985]\n",
      " [0.87453249]]\n",
      "Loss: \n",
      " 0.000526814981950559\n",
      "\n",
      "\n",
      "Epoch: 372\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88675499]\n",
      " [0.84489045]\n",
      " [0.87460889]]\n",
      "Loss: \n",
      " 0.0005234717937343988\n",
      "\n",
      "\n",
      "Epoch: 373\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88682862]\n",
      " [0.84498062]\n",
      " [0.87468492]]\n",
      "Loss: \n",
      " 0.0005201578573411847\n",
      "\n",
      "\n",
      "Epoch: 374\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8869019 ]\n",
      " [0.84507035]\n",
      " [0.87476059]]\n",
      "Loss: \n",
      " 0.0005168728789771724\n",
      "\n",
      "\n",
      "Epoch: 375\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88697481]\n",
      " [0.84515965]\n",
      " [0.87483588]]\n",
      "Loss: \n",
      " 0.000513616568270583\n",
      "\n",
      "\n",
      "Epoch: 376\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88704736]\n",
      " [0.84524852]\n",
      " [0.87491081]]\n",
      "Loss: \n",
      " 0.0005103886382254479\n",
      "\n",
      "\n",
      "Epoch: 377\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88711956]\n",
      " [0.84533697]\n",
      " [0.87498538]]\n",
      "Loss: \n",
      " 0.000507188805176226\n",
      "\n",
      "\n",
      "Epoch: 378\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88719141]\n",
      " [0.84542499]\n",
      " [0.87505959]]\n",
      "Loss: \n",
      " 0.0005040167887430535\n",
      "\n",
      "\n",
      "Epoch: 379\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88726291]\n",
      " [0.84551258]\n",
      " [0.87513344]]\n",
      "Loss: \n",
      " 0.0005008723117877265\n",
      "\n",
      "\n",
      "Epoch: 380\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88733406]\n",
      " [0.84559976]\n",
      " [0.87520694]]\n",
      "Loss: \n",
      " 0.000497755100370345\n",
      "\n",
      "\n",
      "Epoch: 381\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88740486]\n",
      " [0.84568653]\n",
      " [0.87528009]]\n",
      "Loss: \n",
      " 0.0004946648837066229\n",
      "\n",
      "\n",
      "Epoch: 382\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88747532]\n",
      " [0.84577288]\n",
      " [0.87535288]]\n",
      "Loss: \n",
      " 0.0004916013941258537\n",
      "\n",
      "\n",
      "Epoch: 383\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88754543]\n",
      " [0.84585881]\n",
      " [0.87542533]]\n",
      "Loss: \n",
      " 0.0004885643670295175\n",
      "\n",
      "\n",
      "Epoch: 384\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88761521]\n",
      " [0.84594434]\n",
      " [0.87549743]]\n",
      "Loss: \n",
      " 0.00048555354085050225\n",
      "\n",
      "\n",
      "Epoch: 385\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88768465]\n",
      " [0.84602947]\n",
      " [0.87556918]]\n",
      "Loss: \n",
      " 0.0004825686570129688\n",
      "\n",
      "\n",
      "Epoch: 386\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88775376]\n",
      " [0.84611419]\n",
      " [0.87564059]]\n",
      "Loss: \n",
      " 0.00047960945989280356\n",
      "\n",
      "\n",
      "Epoch: 387\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88782253]\n",
      " [0.84619851]\n",
      " [0.87571167]]\n",
      "Loss: \n",
      " 0.0004766756967786851\n",
      "\n",
      "\n",
      "Epoch: 388\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88789097]\n",
      " [0.84628243]\n",
      " [0.87578241]]\n",
      "Loss: \n",
      " 0.0004737671178337353\n",
      "\n",
      "\n",
      "Epoch: 389\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88795908]\n",
      " [0.84636596]\n",
      " [0.87585281]]\n",
      "Loss: \n",
      " 0.00047088347605774646\n",
      "\n",
      "\n",
      "Epoch: 390\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88802687]\n",
      " [0.84644909]\n",
      " [0.87592287]]\n",
      "Loss: \n",
      " 0.0004680245272499585\n",
      "\n",
      "\n",
      "Epoch: 391\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88809433]\n",
      " [0.84653183]\n",
      " [0.87599261]]\n",
      "Loss: \n",
      " 0.00046519002997244264\n",
      "\n",
      "\n",
      "Epoch: 392\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88816147]\n",
      " [0.84661419]\n",
      " [0.87606202]]\n",
      "Loss: \n",
      " 0.00046237974551397343\n",
      "\n",
      "\n",
      "Epoch: 393\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88822829]\n",
      " [0.84669615]\n",
      " [0.8761311 ]]\n",
      "Loss: \n",
      " 0.00045959343785448325\n",
      "\n",
      "\n",
      "Epoch: 394\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88829479]\n",
      " [0.84677774]\n",
      " [0.87619985]]\n",
      "Loss: \n",
      " 0.0004568308736300572\n",
      "\n",
      "\n",
      "Epoch: 395\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88836097]\n",
      " [0.84685894]\n",
      " [0.87626828]]\n",
      "Loss: \n",
      " 0.00045409182209837896\n",
      "\n",
      "\n",
      "Epoch: 396\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88842684]\n",
      " [0.84693976]\n",
      " [0.87633639]]\n",
      "Loss: \n",
      " 0.0004513760551047843\n",
      "\n",
      "\n",
      "Epoch: 397\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8884924 ]\n",
      " [0.84702021]\n",
      " [0.87640419]]\n",
      "Loss: \n",
      " 0.0004486833470487514\n",
      "\n",
      "\n",
      "Epoch: 398\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88855765]\n",
      " [0.84710028]\n",
      " [0.87647166]]\n",
      "Loss: \n",
      " 0.00044601347485089855\n",
      "\n",
      "\n",
      "Epoch: 399\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88862258]\n",
      " [0.84717998]\n",
      " [0.87653882]]\n",
      "Loss: \n",
      " 0.00044336621792050927\n",
      "\n",
      "\n",
      "Epoch: 400\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88868721]\n",
      " [0.84725931]\n",
      " [0.87660566]]\n",
      "Loss: \n",
      " 0.00044074135812347394\n",
      "\n",
      "\n",
      "Epoch: 401\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88875154]\n",
      " [0.84733827]\n",
      " [0.8766722 ]]\n",
      "Loss: \n",
      " 0.00043813867975075793\n",
      "\n",
      "\n",
      "Epoch: 402\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88881556]\n",
      " [0.84741687]\n",
      " [0.87673842]]\n",
      "Loss: \n",
      " 0.00043555796948729496\n",
      "\n",
      "\n",
      "Epoch: 403\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88887928]\n",
      " [0.8474951 ]\n",
      " [0.87680434]]\n",
      "Loss: \n",
      " 0.0004329990163813774\n",
      "\n",
      "\n",
      "Epoch: 404\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88894271]\n",
      " [0.84757297]\n",
      " [0.87686995]]\n",
      "Loss: \n",
      " 0.00043046161181444024\n",
      "\n",
      "\n",
      "Epoch: 405\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88900583]\n",
      " [0.84765048]\n",
      " [0.87693525]]\n",
      "Loss: \n",
      " 0.00042794554947132494\n",
      "\n",
      "\n",
      "Epoch: 406\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88906866]\n",
      " [0.84772764]\n",
      " [0.87700026]]\n",
      "Loss: \n",
      " 0.00042545062531098134\n",
      "\n",
      "\n",
      "Epoch: 407\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8891312 ]\n",
      " [0.84780444]\n",
      " [0.87706496]]\n",
      "Loss: \n",
      " 0.0004229766375375566\n",
      "\n",
      "\n",
      "Epoch: 408\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88919344]\n",
      " [0.84788089]\n",
      " [0.87712937]]\n",
      "Loss: \n",
      " 0.0004205233865719547\n",
      "\n",
      "\n",
      "Epoch: 409\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8892554 ]\n",
      " [0.84795698]\n",
      " [0.87719348]]\n",
      "Loss: \n",
      " 0.0004180906750237774\n",
      "\n",
      "\n",
      "Epoch: 410\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88931706]\n",
      " [0.84803273]\n",
      " [0.87725729]]\n",
      "Loss: \n",
      " 0.000415678307663645\n",
      "\n",
      "\n",
      "Epoch: 411\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88937844]\n",
      " [0.84810814]\n",
      " [0.87732081]]\n",
      "Loss: \n",
      " 0.0004132860913960042\n",
      "\n",
      "\n",
      "Epoch: 412\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88943953]\n",
      " [0.8481832 ]\n",
      " [0.87738404]]\n",
      "Loss: \n",
      " 0.00041091383523222404\n",
      "\n",
      "\n",
      "Epoch: 413\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88950034]\n",
      " [0.84825791]\n",
      " [0.87744698]]\n",
      "Loss: \n",
      " 0.00040856135026414407\n",
      "\n",
      "\n",
      "Epoch: 414\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88956087]\n",
      " [0.84833229]\n",
      " [0.87750963]]\n",
      "Loss: \n",
      " 0.0004062284496379881\n",
      "\n",
      "\n",
      "Epoch: 415\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88962112]\n",
      " [0.84840633]\n",
      " [0.87757199]]\n",
      "Loss: \n",
      " 0.0004039149485286449\n",
      "\n",
      "\n",
      "Epoch: 416\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88968109]\n",
      " [0.84848003]\n",
      " [0.87763407]]\n",
      "Loss: \n",
      " 0.00040162066411431524\n",
      "\n",
      "\n",
      "Epoch: 417\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88974079]\n",
      " [0.84855339]\n",
      " [0.87769587]]\n",
      "Loss: \n",
      " 0.00039934541555154034\n",
      "\n",
      "\n",
      "Epoch: 418\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88980021]\n",
      " [0.84862643]\n",
      " [0.87775739]]\n",
      "Loss: \n",
      " 0.00039708902395055415\n",
      "\n",
      "\n",
      "Epoch: 419\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88985936]\n",
      " [0.84869913]\n",
      " [0.87781862]]\n",
      "Loss: \n",
      " 0.00039485131235101196\n",
      "\n",
      "\n",
      "Epoch: 420\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88991823]\n",
      " [0.84877151]\n",
      " [0.87787958]]\n",
      "Loss: \n",
      " 0.0003926321056980505\n",
      "\n",
      "\n",
      "Epoch: 421\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88997684]\n",
      " [0.84884356]\n",
      " [0.87794027]]\n",
      "Loss: \n",
      " 0.00039043123081871565\n",
      "\n",
      "\n",
      "Epoch: 422\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89003517]\n",
      " [0.84891528]\n",
      " [0.87800067]]\n",
      "Loss: \n",
      " 0.0003882485163986523\n",
      "\n",
      "\n",
      "Epoch: 423\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89009324]\n",
      " [0.84898669]\n",
      " [0.87806081]]\n",
      "Loss: \n",
      " 0.00038608379295921924\n",
      "\n",
      "\n",
      "Epoch: 424\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89015105]\n",
      " [0.84905777]\n",
      " [0.87812067]]\n",
      "Loss: \n",
      " 0.00038393689283484407\n",
      "\n",
      "\n",
      "Epoch: 425\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89020859]\n",
      " [0.84912853]\n",
      " [0.87818026]]\n",
      "Loss: \n",
      " 0.00038180765015076527\n",
      "\n",
      "\n",
      "Epoch: 426\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89026587]\n",
      " [0.84919898]\n",
      " [0.87823959]]\n",
      "Loss: \n",
      " 0.0003796959008010035\n",
      "\n",
      "\n",
      "Epoch: 427\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89032289]\n",
      " [0.84926911]\n",
      " [0.87829865]]\n",
      "Loss: \n",
      " 0.0003776014824267338\n",
      "\n",
      "\n",
      "Epoch: 428\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89037965]\n",
      " [0.84933892]\n",
      " [0.87835744]]\n",
      "Loss: \n",
      " 0.00037552423439490227\n",
      "\n",
      "\n",
      "Epoch: 429\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89043616]\n",
      " [0.84940843]\n",
      " [0.87841597]]\n",
      "Loss: \n",
      " 0.00037346399777713873\n",
      "\n",
      "\n",
      "Epoch: 430\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89049241]\n",
      " [0.84947762]\n",
      " [0.87847424]]\n",
      "Loss: \n",
      " 0.00037142061532901676\n",
      "\n",
      "\n",
      "Epoch: 431\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8905484 ]\n",
      " [0.84954651]\n",
      " [0.87853224]]\n",
      "Loss: \n",
      " 0.00036939393146952925\n",
      "\n",
      "\n",
      "Epoch: 432\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89060414]\n",
      " [0.84961509]\n",
      " [0.87858999]]\n",
      "Loss: \n",
      " 0.000367383792260903\n",
      "\n",
      "\n",
      "Epoch: 433\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89065963]\n",
      " [0.84968336]\n",
      " [0.87864748]]\n",
      "Loss: \n",
      " 0.0003653900453886607\n",
      "\n",
      "\n",
      "Epoch: 434\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89071487]\n",
      " [0.84975134]\n",
      " [0.87870471]]\n",
      "Loss: \n",
      " 0.0003634125401420143\n",
      "\n",
      "\n",
      "Epoch: 435\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89076986]\n",
      " [0.84981901]\n",
      " [0.87876169]]\n",
      "Loss: \n",
      " 0.00036145112739442736\n",
      "\n",
      "\n",
      "Epoch: 436\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8908246 ]\n",
      " [0.84988638]\n",
      " [0.87881842]]\n",
      "Loss: \n",
      " 0.00035950565958456034\n",
      "\n",
      "\n",
      "Epoch: 437\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8908791 ]\n",
      " [0.84995345]\n",
      " [0.87887489]]\n",
      "Loss: \n",
      " 0.00035757599069738394\n",
      "\n",
      "\n",
      "Epoch: 438\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89093336]\n",
      " [0.85002023]\n",
      " [0.87893111]]\n",
      "Loss: \n",
      " 0.0003556619762456249\n",
      "\n",
      "\n",
      "Epoch: 439\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89098737]\n",
      " [0.85008671]\n",
      " [0.87898709]]\n",
      "Loss: \n",
      " 0.0003537634732514057\n",
      "\n",
      "\n",
      "Epoch: 440\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89104114]\n",
      " [0.8501529 ]\n",
      " [0.87904281]]\n",
      "Loss: \n",
      " 0.00035188034022818254\n",
      "\n",
      "\n",
      "Epoch: 441\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89109467]\n",
      " [0.8502188 ]\n",
      " [0.87909829]]\n",
      "Loss: \n",
      " 0.00035001243716289103\n",
      "\n",
      "\n",
      "Epoch: 442\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89114796]\n",
      " [0.85028441]\n",
      " [0.87915353]]\n",
      "Loss: \n",
      " 0.00034815962549837836\n",
      "\n",
      "\n",
      "Epoch: 443\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89120101]\n",
      " [0.85034973]\n",
      " [0.87920852]]\n",
      "Loss: \n",
      " 0.0003463217681160382\n",
      "\n",
      "\n",
      "Epoch: 444\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89125383]\n",
      " [0.85041477]\n",
      " [0.87926327]]\n",
      "Loss: \n",
      " 0.00034449872931867977\n",
      "\n",
      "\n",
      "Epoch: 445\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89130642]\n",
      " [0.85047952]\n",
      " [0.87931778]]\n",
      "Loss: \n",
      " 0.000342690374813683\n",
      "\n",
      "\n",
      "Epoch: 446\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89135877]\n",
      " [0.85054399]\n",
      " [0.87937205]]\n",
      "Loss: \n",
      " 0.00034089657169629803\n",
      "\n",
      "\n",
      "Epoch: 447\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89141089]\n",
      " [0.85060817]\n",
      " [0.87942608]]\n",
      "Loss: \n",
      " 0.00033911718843324714\n",
      "\n",
      "\n",
      "Epoch: 448\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89146277]\n",
      " [0.85067208]\n",
      " [0.87947988]]\n",
      "Loss: \n",
      " 0.000337352094846501\n",
      "\n",
      "\n",
      "Epoch: 449\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89151443]\n",
      " [0.85073571]\n",
      " [0.87953344]]\n",
      "Loss: \n",
      " 0.00033560116209729353\n",
      "\n",
      "\n",
      "Epoch: 450\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89156587]\n",
      " [0.85079906]\n",
      " [0.87958676]]\n",
      "Loss: \n",
      " 0.0003338642626703424\n",
      "\n",
      "\n",
      "Epoch: 451\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89161707]\n",
      " [0.85086213]\n",
      " [0.87963986]]\n",
      "Loss: \n",
      " 0.00033214127035829027\n",
      "\n",
      "\n",
      "Epoch: 452\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89166805]\n",
      " [0.85092494]\n",
      " [0.87969272]]\n",
      "Loss: \n",
      " 0.0003304320602463536\n",
      "\n",
      "\n",
      "Epoch: 453\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89171881]\n",
      " [0.85098747]\n",
      " [0.87974535]]\n",
      "Loss: \n",
      " 0.0003287365086971495\n",
      "\n",
      "\n",
      "Epoch: 454\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89176934]\n",
      " [0.85104972]\n",
      " [0.87979776]]\n",
      "Loss: \n",
      " 0.00032705449333577877\n",
      "\n",
      "\n",
      "Epoch: 455\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89181965]\n",
      " [0.85111171]\n",
      " [0.87984993]]\n",
      "Loss: \n",
      " 0.0003253858930350645\n",
      "\n",
      "\n",
      "Epoch: 456\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89186974]\n",
      " [0.85117344]\n",
      " [0.87990188]]\n",
      "Loss: \n",
      " 0.00032373058790098494\n",
      "\n",
      "\n",
      "Epoch: 457\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89191961]\n",
      " [0.85123489]\n",
      " [0.87995361]]\n",
      "Loss: \n",
      " 0.0003220884592583587\n",
      "\n",
      "\n",
      "Epoch: 458\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89196927]\n",
      " [0.85129608]\n",
      " [0.88000511]]\n",
      "Loss: \n",
      " 0.00032045938963661235\n",
      "\n",
      "\n",
      "Epoch: 459\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8920187 ]\n",
      " [0.85135701]\n",
      " [0.88005638]]\n",
      "Loss: \n",
      " 0.00031884326275585876\n",
      "\n",
      "\n",
      "Epoch: 460\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89206792]\n",
      " [0.85141767]\n",
      " [0.88010744]]\n",
      "Loss: \n",
      " 0.00031723996351307307\n",
      "\n",
      "\n",
      "Epoch: 461\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89211693]\n",
      " [0.85147808]\n",
      " [0.88015828]]\n",
      "Loss: \n",
      " 0.00031564937796847367\n",
      "\n",
      "\n",
      "Epoch: 462\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89216573]\n",
      " [0.85153822]\n",
      " [0.8802089 ]]\n",
      "Loss: \n",
      " 0.0003140713933321012\n",
      "\n",
      "\n",
      "Epoch: 463\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89221431]\n",
      " [0.85159811]\n",
      " [0.8802593 ]]\n",
      "Loss: \n",
      " 0.0003125058979505579\n",
      "\n",
      "\n",
      "Epoch: 464\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89226268]\n",
      " [0.85165774]\n",
      " [0.88030948]]\n",
      "Loss: \n",
      " 0.00031095278129391306\n",
      "\n",
      "\n",
      "Epoch: 465\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89231084]\n",
      " [0.85171712]\n",
      " [0.88035945]]\n",
      "Loss: \n",
      " 0.0003094119339428018\n",
      "\n",
      "\n",
      "Epoch: 466\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8923588 ]\n",
      " [0.85177624]\n",
      " [0.8804092 ]]\n",
      "Loss: \n",
      " 0.0003078832475756879\n",
      "\n",
      "\n",
      "Epoch: 467\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89240655]\n",
      " [0.85183511]\n",
      " [0.88045874]]\n",
      "Loss: \n",
      " 0.0003063666149562638\n",
      "\n",
      "\n",
      "Epoch: 468\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89245409]\n",
      " [0.85189373]\n",
      " [0.88050807]]\n",
      "Loss: \n",
      " 0.00030486192992105175\n",
      "\n",
      "\n",
      "Epoch: 469\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89250142]\n",
      " [0.8519521 ]\n",
      " [0.88055719]]\n",
      "Loss: \n",
      " 0.0003033690873671449\n",
      "\n",
      "\n",
      "Epoch: 470\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89254855]\n",
      " [0.85201022]\n",
      " [0.8806061 ]]\n",
      "Loss: \n",
      " 0.0003018879832401325\n",
      "\n",
      "\n",
      "Epoch: 471\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89259548]\n",
      " [0.85206809]\n",
      " [0.8806548 ]]\n",
      "Loss: \n",
      " 0.00030041851452214066\n",
      "\n",
      "\n",
      "Epoch: 472\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89264221]\n",
      " [0.85212572]\n",
      " [0.88070329]]\n",
      "Loss: \n",
      " 0.0002989605792200586\n",
      "\n",
      "\n",
      "Epoch: 473\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89268874]\n",
      " [0.85218311]\n",
      " [0.88075157]]\n",
      "Loss: \n",
      " 0.0002975140763539214\n",
      "\n",
      "\n",
      "Epoch: 474\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89273507]\n",
      " [0.85224025]\n",
      " [0.88079965]]\n",
      "Loss: \n",
      " 0.0002960789059454144\n",
      "\n",
      "\n",
      "Epoch: 475\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8927812 ]\n",
      " [0.85229715]\n",
      " [0.88084753]]\n",
      "Loss: \n",
      " 0.0002946549690065507\n",
      "\n",
      "\n",
      "Epoch: 476\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89282713]\n",
      " [0.85235381]\n",
      " [0.88089521]]\n",
      "Loss: \n",
      " 0.0002932421675284819\n",
      "\n",
      "\n",
      "Epoch: 477\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89287286]\n",
      " [0.85241023]\n",
      " [0.88094268]]\n",
      "Loss: \n",
      " 0.00029184040447047043\n",
      "\n",
      "\n",
      "Epoch: 478\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89291841]\n",
      " [0.85246641]\n",
      " [0.88098995]]\n",
      "Loss: \n",
      " 0.00029044958374895897\n",
      "\n",
      "\n",
      "Epoch: 479\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89296375]\n",
      " [0.85252236]\n",
      " [0.88103702]]\n",
      "Loss: \n",
      " 0.0002890696102268429\n",
      "\n",
      "\n",
      "Epoch: 480\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89300891]\n",
      " [0.85257807]\n",
      " [0.88108389]]\n",
      "Loss: \n",
      " 0.000287700389702828\n",
      "\n",
      "\n",
      "Epoch: 481\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89305387]\n",
      " [0.85263354]\n",
      " [0.88113057]]\n",
      "Loss: \n",
      " 0.00028634182890094464\n",
      "\n",
      "\n",
      "Epoch: 482\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89309864]\n",
      " [0.85268879]\n",
      " [0.88117705]]\n",
      "Loss: \n",
      " 0.0002849938354602049\n",
      "\n",
      "\n",
      "Epoch: 483\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89314322]\n",
      " [0.8527438 ]\n",
      " [0.88122333]]\n",
      "Loss: \n",
      " 0.000283656317924366\n",
      "\n",
      "\n",
      "Epoch: 484\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89318761]\n",
      " [0.85279858]\n",
      " [0.88126942]]\n",
      "Loss: \n",
      " 0.0002823291857318376\n",
      "\n",
      "\n",
      "Epoch: 485\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89323182]\n",
      " [0.85285313]\n",
      " [0.88131532]]\n",
      "Loss: \n",
      " 0.00028101234920573445\n",
      "\n",
      "\n",
      "Epoch: 486\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89327583]\n",
      " [0.85290746]\n",
      " [0.88136102]]\n",
      "Loss: \n",
      " 0.00027970571954401643\n",
      "\n",
      "\n",
      "Epoch: 487\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89331967]\n",
      " [0.85296156]\n",
      " [0.88140653]]\n",
      "Loss: \n",
      " 0.00027840920880979316\n",
      "\n",
      "\n",
      "Epoch: 488\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89336331]\n",
      " [0.85301543]\n",
      " [0.88145185]]\n",
      "Loss: \n",
      " 0.00027712272992171474\n",
      "\n",
      "\n",
      "Epoch: 489\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89340678]\n",
      " [0.85306907]\n",
      " [0.88149698]]\n",
      "Loss: \n",
      " 0.00027584619664450927\n",
      "\n",
      "\n",
      "Epoch: 490\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89345006]\n",
      " [0.8531225 ]\n",
      " [0.88154193]]\n",
      "Loss: \n",
      " 0.000274579523579631\n",
      "\n",
      "\n",
      "Epoch: 491\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89349315]\n",
      " [0.8531757 ]\n",
      " [0.88158668]]\n",
      "Loss: \n",
      " 0.000273322626156034\n",
      "\n",
      "\n",
      "Epoch: 492\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89353607]\n",
      " [0.85322868]\n",
      " [0.88163125]]\n",
      "Loss: \n",
      " 0.0002720754206210234\n",
      "\n",
      "\n",
      "Epoch: 493\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89357881]\n",
      " [0.85328144]\n",
      " [0.88167564]]\n",
      "Loss: \n",
      " 0.00027083782403129037\n",
      "\n",
      "\n",
      "Epoch: 494\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89362136]\n",
      " [0.85333399]\n",
      " [0.88171984]]\n",
      "Loss: \n",
      " 0.00026960975424398836\n",
      "\n",
      "\n",
      "Epoch: 495\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89366374]\n",
      " [0.85338631]\n",
      " [0.88176385]]\n",
      "Loss: \n",
      " 0.00026839112990796973\n",
      "\n",
      "\n",
      "Epoch: 496\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89370595]\n",
      " [0.85343842]\n",
      " [0.88180768]]\n",
      "Loss: \n",
      " 0.0002671818704551059\n",
      "\n",
      "\n",
      "Epoch: 497\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89374797]\n",
      " [0.85349031]\n",
      " [0.88185134]]\n",
      "Loss: \n",
      " 0.00026598189609172387\n",
      "\n",
      "\n",
      "Epoch: 498\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89378982]\n",
      " [0.85354199]\n",
      " [0.88189481]]\n",
      "Loss: \n",
      " 0.0002647911277901489\n",
      "\n",
      "\n",
      "Epoch: 499\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8938315 ]\n",
      " [0.85359346]\n",
      " [0.8819381 ]]\n",
      "Loss: \n",
      " 0.0002636094872803464\n",
      "\n",
      "\n",
      "Epoch: 500\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.893873  ]\n",
      " [0.85364471]\n",
      " [0.88198121]]\n",
      "Loss: \n",
      " 0.00026243689704168226\n",
      "\n",
      "\n",
      "Epoch: 501\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89391433]\n",
      " [0.85369575]\n",
      " [0.88202414]]\n",
      "Loss: \n",
      " 0.00026127328029476864\n",
      "\n",
      "\n",
      "Epoch: 502\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89395549]\n",
      " [0.85374659]\n",
      " [0.8820669 ]]\n",
      "Loss: \n",
      " 0.00026011856099341426\n",
      "\n",
      "\n",
      "Epoch: 503\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89399648]\n",
      " [0.85379721]\n",
      " [0.88210948]]\n",
      "Loss: \n",
      " 0.0002589726638166792\n",
      "\n",
      "\n",
      "Epoch: 504\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8940373 ]\n",
      " [0.85384763]\n",
      " [0.88215189]]\n",
      "Loss: \n",
      " 0.000257835514161025\n",
      "\n",
      "\n",
      "Epoch: 505\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89407794]\n",
      " [0.85389784]\n",
      " [0.88219412]]\n",
      "Loss: \n",
      " 0.00025670703813255024\n",
      "\n",
      "\n",
      "Epoch: 506\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89411843]\n",
      " [0.85394784]\n",
      " [0.88223618]]\n",
      "Loss: \n",
      " 0.0002555871625393546\n",
      "\n",
      "\n",
      "Epoch: 507\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89415874]\n",
      " [0.85399764]\n",
      " [0.88227806]]\n",
      "Loss: \n",
      " 0.00025447581488394796\n",
      "\n",
      "\n",
      "Epoch: 508\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89419889]\n",
      " [0.85404724]\n",
      " [0.88231978]]\n",
      "Loss: \n",
      " 0.00025337292335578655\n",
      "\n",
      "\n",
      "Epoch: 509\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89423887]\n",
      " [0.85409663]\n",
      " [0.88236132]]\n",
      "Loss: \n",
      " 0.000252278416823895\n",
      "\n",
      "\n",
      "Epoch: 510\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89427868]\n",
      " [0.85414582]\n",
      " [0.88240269]]\n",
      "Loss: \n",
      " 0.00025119222482957473\n",
      "\n",
      "\n",
      "Epoch: 511\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89431834]\n",
      " [0.85419481]\n",
      " [0.8824439 ]]\n",
      "Loss: \n",
      " 0.00025011427757919087\n",
      "\n",
      "\n",
      "Epoch: 512\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89435782]\n",
      " [0.8542436 ]\n",
      " [0.88248493]]\n",
      "Loss: \n",
      " 0.0002490445059370653\n",
      "\n",
      "\n",
      "Epoch: 513\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89439715]\n",
      " [0.8542922 ]\n",
      " [0.8825258 ]]\n",
      "Loss: \n",
      " 0.00024798284141844517\n",
      "\n",
      "\n",
      "Epoch: 514\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89443632]\n",
      " [0.85434059]\n",
      " [0.8825665 ]]\n",
      "Loss: \n",
      " 0.00024692921618254805\n",
      "\n",
      "\n",
      "Epoch: 515\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89447532]\n",
      " [0.85438879]\n",
      " [0.88260704]]\n",
      "Loss: \n",
      " 0.00024588356302571873\n",
      "\n",
      "\n",
      "Epoch: 516\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89451417]\n",
      " [0.8544368 ]\n",
      " [0.88264741]]\n",
      "Loss: \n",
      " 0.00024484581537464973\n",
      "\n",
      "\n",
      "Epoch: 517\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89455285]\n",
      " [0.8544846 ]\n",
      " [0.88268762]]\n",
      "Loss: \n",
      " 0.000243815907279658\n",
      "\n",
      "\n",
      "Epoch: 518\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89459138]\n",
      " [0.85453222]\n",
      " [0.88272766]]\n",
      "Loss: \n",
      " 0.00024279377340810648\n",
      "\n",
      "\n",
      "Epoch: 519\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89462975]\n",
      " [0.85457964]\n",
      " [0.88276754]]\n",
      "Loss: \n",
      " 0.0002417793490378479\n",
      "\n",
      "\n",
      "Epoch: 520\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89466797]\n",
      " [0.85462687]\n",
      " [0.88280726]]\n",
      "Loss: \n",
      " 0.00024077257005076014\n",
      "\n",
      "\n",
      "Epoch: 521\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89470603]\n",
      " [0.85467392]\n",
      " [0.88284682]]\n",
      "Loss: \n",
      " 0.00023977337292638894\n",
      "\n",
      "\n",
      "Epoch: 522\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89474393]\n",
      " [0.85472077]\n",
      " [0.88288622]]\n",
      "Loss: \n",
      " 0.00023878169473562152\n",
      "\n",
      "\n",
      "Epoch: 523\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89478168]\n",
      " [0.85476743]\n",
      " [0.88292546]]\n",
      "Loss: \n",
      " 0.00023779747313447093\n",
      "\n",
      "\n",
      "Epoch: 524\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89481928]\n",
      " [0.8548139 ]\n",
      " [0.88296455]]\n",
      "Loss: \n",
      " 0.00023682064635791053\n",
      "\n",
      "\n",
      "Epoch: 525\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89485672]\n",
      " [0.85486019]\n",
      " [0.88300347]]\n",
      "Loss: \n",
      " 0.00023585115321381265\n",
      "\n",
      "\n",
      "Epoch: 526\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89489402]\n",
      " [0.85490629]\n",
      " [0.88304224]]\n",
      "Loss: \n",
      " 0.00023488893307690715\n",
      "\n",
      "\n",
      "Epoch: 527\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89493116]\n",
      " [0.85495221]\n",
      " [0.88308085]]\n",
      "Loss: \n",
      " 0.00023393392588287877\n",
      "\n",
      "\n",
      "Epoch: 528\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89496815]\n",
      " [0.85499794]\n",
      " [0.88311931]]\n",
      "Loss: \n",
      " 0.0002329860721224735\n",
      "\n",
      "\n",
      "Epoch: 529\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89500499]\n",
      " [0.85504349]\n",
      " [0.88315761]]\n",
      "Loss: \n",
      " 0.00023204531283571776\n",
      "\n",
      "\n",
      "Epoch: 530\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89504168]\n",
      " [0.85508885]\n",
      " [0.88319576]]\n",
      "Loss: \n",
      " 0.000231111589606177\n",
      "\n",
      "\n",
      "Epoch: 531\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89507823]\n",
      " [0.85513404]\n",
      " [0.88323375]]\n",
      "Loss: \n",
      " 0.00023018484455529867\n",
      "\n",
      "\n",
      "Epoch: 532\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89511462]\n",
      " [0.85517904]\n",
      " [0.88327159]]\n",
      "Loss: \n",
      " 0.00022926502033681698\n",
      "\n",
      "\n",
      "Epoch: 533\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89515087]\n",
      " [0.85522387]\n",
      " [0.88330929]]\n",
      "Loss: \n",
      " 0.00022835206013122725\n",
      "\n",
      "\n",
      "Epoch: 534\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89518698]\n",
      " [0.85526851]\n",
      " [0.88334683]]\n",
      "Loss: \n",
      " 0.00022744590764031412\n",
      "\n",
      "\n",
      "Epoch: 535\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89522294]\n",
      " [0.85531298]\n",
      " [0.88338422]]\n",
      "Loss: \n",
      " 0.0002265465070817565\n",
      "\n",
      "\n",
      "Epoch: 536\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89525875]\n",
      " [0.85535727]\n",
      " [0.88342146]]\n",
      "Loss: \n",
      " 0.00022565380318378543\n",
      "\n",
      "\n",
      "Epoch: 537\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89529442]\n",
      " [0.85540139]\n",
      " [0.88345855]]\n",
      "Loss: \n",
      " 0.00022476774117991352\n",
      "\n",
      "\n",
      "Epoch: 538\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89532995]\n",
      " [0.85544533]\n",
      " [0.8834955 ]]\n",
      "Loss: \n",
      " 0.0002238882668037278\n",
      "\n",
      "\n",
      "Epoch: 539\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89536534]\n",
      " [0.85548909]\n",
      " [0.8835323 ]]\n",
      "Loss: \n",
      " 0.0002230153262837253\n",
      "\n",
      "\n",
      "Epoch: 540\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89540058]\n",
      " [0.85553268]\n",
      " [0.88356895]]\n",
      "Loss: \n",
      " 0.00022214886633822295\n",
      "\n",
      "\n",
      "Epoch: 541\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89543569]\n",
      " [0.8555761 ]\n",
      " [0.88360546]]\n",
      "Loss: \n",
      " 0.00022128883417033623\n",
      "\n",
      "\n",
      "Epoch: 542\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89547065]\n",
      " [0.85561935]\n",
      " [0.88364182]]\n",
      "Loss: \n",
      " 0.00022043517746298623\n",
      "\n",
      "\n",
      "Epoch: 543\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89550548]\n",
      " [0.85566242]\n",
      " [0.88367804]]\n",
      "Loss: \n",
      " 0.00021958784437399958\n",
      "\n",
      "\n",
      "Epoch: 544\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89554016]\n",
      " [0.85570533]\n",
      " [0.88371411]]\n",
      "Loss: \n",
      " 0.0002187467835312396\n",
      "\n",
      "\n",
      "Epoch: 545\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89557471]\n",
      " [0.85574806]\n",
      " [0.88375004]]\n",
      "Loss: \n",
      " 0.00021791194402780243\n",
      "\n",
      "\n",
      "Epoch: 546\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89560912]\n",
      " [0.85579063]\n",
      " [0.88378583]]\n",
      "Loss: \n",
      " 0.00021708327541726755\n",
      "\n",
      "\n",
      "Epoch: 547\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89564339]\n",
      " [0.85583303]\n",
      " [0.88382148]]\n",
      "Loss: \n",
      " 0.0002162607277090143\n",
      "\n",
      "\n",
      "Epoch: 548\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89567753]\n",
      " [0.85587526]\n",
      " [0.88385699]]\n",
      "Loss: \n",
      " 0.00021544425136356022\n",
      "\n",
      "\n",
      "Epoch: 549\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89571153]\n",
      " [0.85591732]\n",
      " [0.88389235]]\n",
      "Loss: \n",
      " 0.00021463379728800462\n",
      "\n",
      "\n",
      "Epoch: 550\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8957454 ]\n",
      " [0.85595922]\n",
      " [0.88392758]]\n",
      "Loss: \n",
      " 0.00021382931683146895\n",
      "\n",
      "\n",
      "Epoch: 551\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89577913]\n",
      " [0.85600096]\n",
      " [0.88396267]]\n",
      "Loss: \n",
      " 0.0002130307617806287\n",
      "\n",
      "\n",
      "Epoch: 552\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89581273]\n",
      " [0.85604253]\n",
      " [0.88399762]]\n",
      "Loss: \n",
      " 0.0002122380843552758\n",
      "\n",
      "\n",
      "Epoch: 553\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89584619]\n",
      " [0.85608393]\n",
      " [0.88403243]]\n",
      "Loss: \n",
      " 0.0002114512372039415\n",
      "\n",
      "\n",
      "Epoch: 554\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89587953]\n",
      " [0.85612518]\n",
      " [0.88406711]]\n",
      "Loss: \n",
      " 0.0002106701733995694\n",
      "\n",
      "\n",
      "Epoch: 555\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89591273]\n",
      " [0.85616626]\n",
      " [0.88410165]]\n",
      "Loss: \n",
      " 0.0002098948464352284\n",
      "\n",
      "\n",
      "Epoch: 556\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8959458 ]\n",
      " [0.85620719]\n",
      " [0.88413606]]\n",
      "Loss: \n",
      " 0.00020912521021989336\n",
      "\n",
      "\n",
      "Epoch: 557\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89597875]\n",
      " [0.85624795]\n",
      " [0.88417033]]\n",
      "Loss: \n",
      " 0.000208361219074236\n",
      "\n",
      "\n",
      "Epoch: 558\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89601156]\n",
      " [0.85628855]\n",
      " [0.88420446]]\n",
      "Loss: \n",
      " 0.00020760282772652042\n",
      "\n",
      "\n",
      "Epoch: 559\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89604424]\n",
      " [0.856329  ]\n",
      " [0.88423847]]\n",
      "Loss: \n",
      " 0.00020684999130848915\n",
      "\n",
      "\n",
      "Epoch: 560\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89607679]\n",
      " [0.85636928]\n",
      " [0.88427234]]\n",
      "Loss: \n",
      " 0.0002061026653513325\n",
      "\n",
      "\n",
      "Epoch: 561\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89610922]\n",
      " [0.85640941]\n",
      " [0.88430607]]\n",
      "Loss: \n",
      " 0.0002053608057816837\n",
      "\n",
      "\n",
      "Epoch: 562\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89614152]\n",
      " [0.85644939]\n",
      " [0.88433968]]\n",
      "Loss: \n",
      " 0.0002046243689176724\n",
      "\n",
      "\n",
      "Epoch: 563\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89617369]\n",
      " [0.85648921]\n",
      " [0.88437316]]\n",
      "Loss: \n",
      " 0.00020389331146501483\n",
      "\n",
      "\n",
      "Epoch: 564\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89620574]\n",
      " [0.85652887]\n",
      " [0.8844065 ]]\n",
      "Loss: \n",
      " 0.0002031675905131436\n",
      "\n",
      "\n",
      "Epoch: 565\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89623766]\n",
      " [0.85656838]\n",
      " [0.88443971]]\n",
      "Loss: \n",
      " 0.00020244716353140375\n",
      "\n",
      "\n",
      "Epoch: 566\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89626946]\n",
      " [0.85660773]\n",
      " [0.8844728 ]]\n",
      "Loss: \n",
      " 0.00020173198836525043\n",
      "\n",
      "\n",
      "Epoch: 567\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89630113]\n",
      " [0.85664694]\n",
      " [0.88450576]]\n",
      "Loss: \n",
      " 0.0002010220232325352\n",
      "\n",
      "\n",
      "Epoch: 568\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89633268]\n",
      " [0.85668599]\n",
      " [0.88453859]]\n",
      "Loss: \n",
      " 0.00020031722671980112\n",
      "\n",
      "\n",
      "Epoch: 569\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89636411]\n",
      " [0.85672489]\n",
      " [0.88457129]]\n",
      "Loss: \n",
      " 0.00019961755777863822\n",
      "\n",
      "\n",
      "Epoch: 570\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89639541]\n",
      " [0.85676364]\n",
      " [0.88460386]]\n",
      "Loss: \n",
      " 0.00019892297572206372\n",
      "\n",
      "\n",
      "Epoch: 571\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89642659]\n",
      " [0.85680224]\n",
      " [0.88463631]]\n",
      "Loss: \n",
      " 0.0001982334402209513\n",
      "\n",
      "\n",
      "Epoch: 572\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89645765]\n",
      " [0.85684069]\n",
      " [0.88466864]]\n",
      "Loss: \n",
      " 0.00019754891130050712\n",
      "\n",
      "\n",
      "Epoch: 573\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89648859]\n",
      " [0.85687899]\n",
      " [0.88470084]]\n",
      "Loss: \n",
      " 0.0001968693493367751\n",
      "\n",
      "\n",
      "Epoch: 574\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89651941]\n",
      " [0.85691714]\n",
      " [0.88473291]]\n",
      "Loss: \n",
      " 0.00019619471505317196\n",
      "\n",
      "\n",
      "Epoch: 575\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89655012]\n",
      " [0.85695515]\n",
      " [0.88476486]]\n",
      "Loss: \n",
      " 0.0001955249695170868\n",
      "\n",
      "\n",
      "Epoch: 576\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8965807 ]\n",
      " [0.85699301]\n",
      " [0.88479669]]\n",
      "Loss: \n",
      " 0.00019486007413649882\n",
      "\n",
      "\n",
      "Epoch: 577\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89661116]\n",
      " [0.85703072]\n",
      " [0.88482839]]\n",
      "Loss: \n",
      " 0.00019419999065663294\n",
      "\n",
      "\n",
      "Epoch: 578\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89664151]\n",
      " [0.85706829]\n",
      " [0.88485997]]\n",
      "Loss: \n",
      " 0.00019354468115666138\n",
      "\n",
      "\n",
      "Epoch: 579\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89667173]\n",
      " [0.85710572]\n",
      " [0.88489144]]\n",
      "Loss: \n",
      " 0.00019289410804643214\n",
      "\n",
      "\n",
      "Epoch: 580\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89670184]\n",
      " [0.857143  ]\n",
      " [0.88492278]]\n",
      "Loss: \n",
      " 0.00019224823406324706\n",
      "\n",
      "\n",
      "Epoch: 581\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89673184]\n",
      " [0.85718014]\n",
      " [0.88495399]]\n",
      "Loss: \n",
      " 0.00019160702226865184\n",
      "\n",
      "\n",
      "Epoch: 582\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89676172]\n",
      " [0.85721714]\n",
      " [0.88498509]]\n",
      "Loss: \n",
      " 0.00019097043604529226\n",
      "\n",
      "\n",
      "Epoch: 583\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89679148]\n",
      " [0.85725399]\n",
      " [0.88501607]]\n",
      "Loss: \n",
      " 0.00019033843909376693\n",
      "\n",
      "\n",
      "Epoch: 584\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89682113]\n",
      " [0.8572907 ]\n",
      " [0.88504694]]\n",
      "Loss: \n",
      " 0.00018971099542956449\n",
      "\n",
      "\n",
      "Epoch: 585\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89685067]\n",
      " [0.85732728]\n",
      " [0.88507768]]\n",
      "Loss: \n",
      " 0.0001890880693799815\n",
      "\n",
      "\n",
      "Epoch: 586\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89688009]\n",
      " [0.85736371]\n",
      " [0.88510831]]\n",
      "Loss: \n",
      " 0.00018846962558110607\n",
      "\n",
      "\n",
      "Epoch: 587\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8969094 ]\n",
      " [0.8574    ]\n",
      " [0.88513882]]\n",
      "Loss: \n",
      " 0.00018785562897483108\n",
      "\n",
      "\n",
      "Epoch: 588\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8969386 ]\n",
      " [0.85743616]\n",
      " [0.88516921]]\n",
      "Loss: \n",
      " 0.00018724604480588596\n",
      "\n",
      "\n",
      "Epoch: 589\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89696768]\n",
      " [0.85747218]\n",
      " [0.88519948]]\n",
      "Loss: \n",
      " 0.00018664083861892427\n",
      "\n",
      "\n",
      "Epoch: 590\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89699666]\n",
      " [0.85750806]\n",
      " [0.88522964]]\n",
      "Loss: \n",
      " 0.00018603997625561306\n",
      "\n",
      "\n",
      "Epoch: 591\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89702552]\n",
      " [0.8575438 ]\n",
      " [0.88525969]]\n",
      "Loss: \n",
      " 0.00018544342385177752\n",
      "\n",
      "\n",
      "Epoch: 592\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89705427]\n",
      " [0.85757941]\n",
      " [0.88528962]]\n",
      "Loss: \n",
      " 0.00018485114783456816\n",
      "\n",
      "\n",
      "Epoch: 593\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89708291]\n",
      " [0.85761488]\n",
      " [0.88531944]]\n",
      "Loss: \n",
      " 0.00018426311491966032\n",
      "\n",
      "\n",
      "Epoch: 594\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89711145]\n",
      " [0.85765021]\n",
      " [0.88534914]]\n",
      "Loss: \n",
      " 0.00018367929210847908\n",
      "\n",
      "\n",
      "Epoch: 595\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89713987]\n",
      " [0.85768542]\n",
      " [0.88537873]]\n",
      "Loss: \n",
      " 0.00018309964668545873\n",
      "\n",
      "\n",
      "Epoch: 596\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89716819]\n",
      " [0.85772049]\n",
      " [0.88540821]]\n",
      "Loss: \n",
      " 0.00018252414621533022\n",
      "\n",
      "\n",
      "Epoch: 597\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89719639]\n",
      " [0.85775542]\n",
      " [0.88543758]]\n",
      "Loss: \n",
      " 0.00018195275854044238\n",
      "\n",
      "\n",
      "Epoch: 598\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89722449]\n",
      " [0.85779023]\n",
      " [0.88546684]]\n",
      "Loss: \n",
      " 0.00018138545177810605\n",
      "\n",
      "\n",
      "Epoch: 599\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89725249]\n",
      " [0.8578249 ]\n",
      " [0.88549598]]\n",
      "Loss: \n",
      " 0.00018082219431795604\n",
      "\n",
      "\n",
      "Epoch: 600\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89728037]\n",
      " [0.85785944]\n",
      " [0.88552501]]\n",
      "Loss: \n",
      " 0.0001802629548193806\n",
      "\n",
      "\n",
      "Epoch: 601\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89730816]\n",
      " [0.85789385]\n",
      " [0.88555394]]\n",
      "Loss: \n",
      " 0.00017970770220892543\n",
      "\n",
      "\n",
      "Epoch: 602\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89733583]\n",
      " [0.85792813]\n",
      " [0.88558275]]\n",
      "Loss: \n",
      " 0.00017915640567776493\n",
      "\n",
      "\n",
      "Epoch: 603\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8973634 ]\n",
      " [0.85796228]\n",
      " [0.88561146]]\n",
      "Loss: \n",
      " 0.00017860903467918914\n",
      "\n",
      "\n",
      "Epoch: 604\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89739087]\n",
      " [0.8579963 ]\n",
      " [0.88564006]]\n",
      "Loss: \n",
      " 0.00017806555892609606\n",
      "\n",
      "\n",
      "Epoch: 605\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89741823]\n",
      " [0.8580302 ]\n",
      " [0.88566855]]\n",
      "Loss: \n",
      " 0.0001775259483885662\n",
      "\n",
      "\n",
      "Epoch: 606\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89744549]\n",
      " [0.85806396]\n",
      " [0.88569693]]\n",
      "Loss: \n",
      " 0.00017699017329138412\n",
      "\n",
      "\n",
      "Epoch: 607\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89747265]\n",
      " [0.8580976 ]\n",
      " [0.88572521]]\n",
      "Loss: \n",
      " 0.00017645820411166347\n",
      "\n",
      "\n",
      "Epoch: 608\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8974997 ]\n",
      " [0.85813111]\n",
      " [0.88575338]]\n",
      "Loss: \n",
      " 0.0001759300115764486\n",
      "\n",
      "\n",
      "Epoch: 609\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89752665]\n",
      " [0.8581645 ]\n",
      " [0.88578144]]\n",
      "Loss: \n",
      " 0.0001754055666603484\n",
      "\n",
      "\n",
      "Epoch: 610\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8975535 ]\n",
      " [0.85819776]\n",
      " [0.8858094 ]]\n",
      "Loss: \n",
      " 0.00017488484058322034\n",
      "\n",
      "\n",
      "Epoch: 611\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89758025]\n",
      " [0.8582309 ]\n",
      " [0.88583725]]\n",
      "Loss: \n",
      " 0.00017436780480784302\n",
      "\n",
      "\n",
      "Epoch: 612\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8976069 ]\n",
      " [0.85826391]\n",
      " [0.885865  ]]\n",
      "Loss: \n",
      " 0.00017385443103764888\n",
      "\n",
      "\n",
      "Epoch: 613\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89763344]\n",
      " [0.8582968 ]\n",
      " [0.88589264]]\n",
      "Loss: \n",
      " 0.00017334469121444798\n",
      "\n",
      "\n",
      "Epoch: 614\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89765989]\n",
      " [0.85832956]\n",
      " [0.88592018]]\n",
      "Loss: \n",
      " 0.00017283855751619359\n",
      "\n",
      "\n",
      "Epoch: 615\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89768624]\n",
      " [0.8583622 ]\n",
      " [0.88594762]]\n",
      "Loss: \n",
      " 0.0001723360023547868\n",
      "\n",
      "\n",
      "Epoch: 616\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89771249]\n",
      " [0.85839472]\n",
      " [0.88597496]]\n",
      "Loss: \n",
      " 0.000171836998373861\n",
      "\n",
      "\n",
      "Epoch: 617\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89773864]\n",
      " [0.85842712]\n",
      " [0.88600219]]\n",
      "Loss: \n",
      " 0.0001713415184466262\n",
      "\n",
      "\n",
      "Epoch: 618\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89776469]\n",
      " [0.8584594 ]\n",
      " [0.88602932]]\n",
      "Loss: \n",
      " 0.00017084953567372664\n",
      "\n",
      "\n",
      "Epoch: 619\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89779065]\n",
      " [0.85849156]\n",
      " [0.88605635]]\n",
      "Loss: \n",
      " 0.00017036102338111546\n",
      "\n",
      "\n",
      "Epoch: 620\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89781651]\n",
      " [0.85852359]\n",
      " [0.88608328]]\n",
      "Loss: \n",
      " 0.00016987595511796011\n",
      "\n",
      "\n",
      "Epoch: 621\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89784227]\n",
      " [0.85855551]\n",
      " [0.88611011]]\n",
      "Loss: \n",
      " 0.00016939430465455417\n",
      "\n",
      "\n",
      "Epoch: 622\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89786793]\n",
      " [0.85858731]\n",
      " [0.88613683]]\n",
      "Loss: \n",
      " 0.00016891604598026462\n",
      "\n",
      "\n",
      "Epoch: 623\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8978935 ]\n",
      " [0.85861899]\n",
      " [0.88616346]]\n",
      "Loss: \n",
      " 0.00016844115330150896\n",
      "\n",
      "\n",
      "Epoch: 624\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89791898]\n",
      " [0.85865055]\n",
      " [0.88618999]]\n",
      "Loss: \n",
      " 0.0001679696010397196\n",
      "\n",
      "\n",
      "Epoch: 625\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89794435]\n",
      " [0.858682  ]\n",
      " [0.88621642]]\n",
      "Loss: \n",
      " 0.00016750136382936943\n",
      "\n",
      "\n",
      "Epoch: 626\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89796964]\n",
      " [0.85871332]\n",
      " [0.88624276]]\n",
      "Loss: \n",
      " 0.00016703641651599188\n",
      "\n",
      "\n",
      "Epoch: 627\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89799483]\n",
      " [0.85874453]\n",
      " [0.88626899]]\n",
      "Loss: \n",
      " 0.00016657473415423147\n",
      "\n",
      "\n",
      "Epoch: 628\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89801992]\n",
      " [0.85877563]\n",
      " [0.88629513]]\n",
      "Loss: \n",
      " 0.00016611629200590799\n",
      "\n",
      "\n",
      "Epoch: 629\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89804493]\n",
      " [0.85880661]\n",
      " [0.88632117]]\n",
      "Loss: \n",
      " 0.0001656610655381117\n",
      "\n",
      "\n",
      "Epoch: 630\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89806984]\n",
      " [0.85883748]\n",
      " [0.88634711]]\n",
      "Loss: \n",
      " 0.00016520903042130383\n",
      "\n",
      "\n",
      "Epoch: 631\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89809465]\n",
      " [0.85886823]\n",
      " [0.88637296]]\n",
      "Loss: \n",
      " 0.00016476016252744757\n",
      "\n",
      "\n",
      "Epoch: 632\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89811938]\n",
      " [0.85889886]\n",
      " [0.88639871]]\n",
      "Loss: \n",
      " 0.00016431443792816195\n",
      "\n",
      "\n",
      "Epoch: 633\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89814401]\n",
      " [0.85892939]\n",
      " [0.88642437]]\n",
      "Loss: \n",
      " 0.0001638718328928749\n",
      "\n",
      "\n",
      "Epoch: 634\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89816856]\n",
      " [0.8589598 ]\n",
      " [0.88644993]]\n",
      "Loss: \n",
      " 0.0001634323238870146\n",
      "\n",
      "\n",
      "Epoch: 635\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89819301]\n",
      " [0.8589901 ]\n",
      " [0.8864754 ]]\n",
      "Loss: \n",
      " 0.0001629958875702126\n",
      "\n",
      "\n",
      "Epoch: 636\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89821737]\n",
      " [0.85902028]\n",
      " [0.88650077]]\n",
      "Loss: \n",
      " 0.00016256250079452975\n",
      "\n",
      "\n",
      "Epoch: 637\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89824164]\n",
      " [0.85905036]\n",
      " [0.88652605]]\n",
      "Loss: \n",
      " 0.00016213214060269195\n",
      "\n",
      "\n",
      "Epoch: 638\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89826582]\n",
      " [0.85908032]\n",
      " [0.88655124]]\n",
      "Loss: \n",
      " 0.00016170478422634305\n",
      "\n",
      "\n",
      "Epoch: 639\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89828991]\n",
      " [0.85911018]\n",
      " [0.88657633]]\n",
      "Loss: \n",
      " 0.00016128040908432647\n",
      "\n",
      "\n",
      "Epoch: 640\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89831391]\n",
      " [0.85913992]\n",
      " [0.88660134]]\n",
      "Loss: \n",
      " 0.00016085899278098228\n",
      "\n",
      "\n",
      "Epoch: 641\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89833783]\n",
      " [0.85916956]\n",
      " [0.88662625]]\n",
      "Loss: \n",
      " 0.0001604405131044478\n",
      "\n",
      "\n",
      "Epoch: 642\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89836165]\n",
      " [0.85919908]\n",
      " [0.88665106]]\n",
      "Loss: \n",
      " 0.00016002494802499787\n",
      "\n",
      "\n",
      "Epoch: 643\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89838539]\n",
      " [0.8592285 ]\n",
      " [0.88667579]]\n",
      "Loss: \n",
      " 0.0001596122756933776\n",
      "\n",
      "\n",
      "Epoch: 644\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89840904]\n",
      " [0.85925781]\n",
      " [0.88670043]]\n",
      "Loss: \n",
      " 0.00015920247443917325\n",
      "\n",
      "\n",
      "Epoch: 645\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89843261]\n",
      " [0.85928701]\n",
      " [0.88672497]]\n",
      "Loss: \n",
      " 0.00015879552276917936\n",
      "\n",
      "\n",
      "Epoch: 646\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89845609]\n",
      " [0.8593161 ]\n",
      " [0.88674943]]\n",
      "Loss: \n",
      " 0.00015839139936581185\n",
      "\n",
      "\n",
      "Epoch: 647\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89847948]\n",
      " [0.85934509]\n",
      " [0.88677379]]\n",
      "Loss: \n",
      " 0.0001579900830855028\n",
      "\n",
      "\n",
      "Epoch: 648\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89850278]\n",
      " [0.85937397]\n",
      " [0.88679807]]\n",
      "Loss: \n",
      " 0.0001575915529571303\n",
      "\n",
      "\n",
      "Epoch: 649\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.898526  ]\n",
      " [0.85940275]\n",
      " [0.88682226]]\n",
      "Loss: \n",
      " 0.00015719578818046285\n",
      "\n",
      "\n",
      "Epoch: 650\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89854914]\n",
      " [0.85943142]\n",
      " [0.88684636]]\n",
      "Loss: \n",
      " 0.00015680276812462418\n",
      "\n",
      "\n",
      "Epoch: 651\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89857219]\n",
      " [0.85945998]\n",
      " [0.88687037]]\n",
      "Loss: \n",
      " 0.00015641247232655962\n",
      "\n",
      "\n",
      "Epoch: 652\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89859515]\n",
      " [0.85948844]\n",
      " [0.88689429]]\n",
      "Loss: \n",
      " 0.00015602488048952102\n",
      "\n",
      "\n",
      "Epoch: 653\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89861803]\n",
      " [0.8595168 ]\n",
      " [0.88691813]]\n",
      "Loss: \n",
      " 0.00015563997248159214\n",
      "\n",
      "\n",
      "Epoch: 654\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89864083]\n",
      " [0.85954505]\n",
      " [0.88694188]]\n",
      "Loss: \n",
      " 0.00015525772833417995\n",
      "\n",
      "\n",
      "Epoch: 655\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89866355]\n",
      " [0.8595732 ]\n",
      " [0.88696554]]\n",
      "Loss: \n",
      " 0.0001548781282405691\n",
      "\n",
      "\n",
      "Epoch: 656\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89868618]\n",
      " [0.85960125]\n",
      " [0.88698911]]\n",
      "Loss: \n",
      " 0.00015450115255445952\n",
      "\n",
      "\n",
      "Epoch: 657\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89870873]\n",
      " [0.85962919]\n",
      " [0.88701261]]\n",
      "Loss: \n",
      " 0.00015412678178854686\n",
      "\n",
      "\n",
      "Epoch: 658\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89873119]\n",
      " [0.85965704]\n",
      " [0.88703601]]\n",
      "Loss: \n",
      " 0.00015375499661307666\n",
      "\n",
      "\n",
      "Epoch: 659\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89875358]\n",
      " [0.85968478]\n",
      " [0.88705933]]\n",
      "Loss: \n",
      " 0.00015338577785445565\n",
      "\n",
      "\n",
      "Epoch: 660\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89877588]\n",
      " [0.85971242]\n",
      " [0.88708256]]\n",
      "Loss: \n",
      " 0.0001530191064938422\n",
      "\n",
      "\n",
      "Epoch: 661\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8987981 ]\n",
      " [0.85973996]\n",
      " [0.88710571]]\n",
      "Loss: \n",
      " 0.00015265496366578726\n",
      "\n",
      "\n",
      "Epoch: 662\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89882025]\n",
      " [0.8597674 ]\n",
      " [0.88712878]]\n",
      "Loss: \n",
      " 0.0001522933306568426\n",
      "\n",
      "\n",
      "Epoch: 663\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89884231]\n",
      " [0.85979474]\n",
      " [0.88715176]]\n",
      "Loss: \n",
      " 0.0001519341889042291\n",
      "\n",
      "\n",
      "Epoch: 664\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89886429]\n",
      " [0.85982198]\n",
      " [0.88717466]]\n",
      "Loss: \n",
      " 0.00015157751999448678\n",
      "\n",
      "\n",
      "Epoch: 665\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89888619]\n",
      " [0.85984912]\n",
      " [0.88719748]]\n",
      "Loss: \n",
      " 0.00015122330566215108\n",
      "\n",
      "\n",
      "Epoch: 666\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89890801]\n",
      " [0.85987617]\n",
      " [0.88722021]]\n",
      "Loss: \n",
      " 0.00015087152778843572\n",
      "\n",
      "\n",
      "Epoch: 667\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89892975]\n",
      " [0.85990311]\n",
      " [0.88724286]]\n",
      "Loss: \n",
      " 0.00015052216839993733\n",
      "\n",
      "\n",
      "Epoch: 668\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89895142]\n",
      " [0.85992996]\n",
      " [0.88726543]]\n",
      "Loss: \n",
      " 0.00015017520966735995\n",
      "\n",
      "\n",
      "Epoch: 669\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.898973  ]\n",
      " [0.85995671]\n",
      " [0.88728792]]\n",
      "Loss: \n",
      " 0.00014983063390420714\n",
      "\n",
      "\n",
      "Epoch: 670\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89899451]\n",
      " [0.85998337]\n",
      " [0.88731033]]\n",
      "Loss: \n",
      " 0.0001494884235655529\n",
      "\n",
      "\n",
      "Epoch: 671\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89901594]\n",
      " [0.86000993]\n",
      " [0.88733265]]\n",
      "Loss: \n",
      " 0.0001491485612467831\n",
      "\n",
      "\n",
      "Epoch: 672\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89903729]\n",
      " [0.86003639]\n",
      " [0.8873549 ]]\n",
      "Loss: \n",
      " 0.00014881102968234525\n",
      "\n",
      "\n",
      "Epoch: 673\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89905857]\n",
      " [0.86006276]\n",
      " [0.88737706]]\n",
      "Loss: \n",
      " 0.00014847581174454028\n",
      "\n",
      "\n",
      "Epoch: 674\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89907976]\n",
      " [0.86008903]\n",
      " [0.88739915]]\n",
      "Loss: \n",
      " 0.00014814289044229683\n",
      "\n",
      "\n",
      "Epoch: 675\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89910088]\n",
      " [0.8601152 ]\n",
      " [0.88742115]]\n",
      "Loss: \n",
      " 0.0001478122489199829\n",
      "\n",
      "\n",
      "Epoch: 676\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89912193]\n",
      " [0.86014129]\n",
      " [0.88744308]]\n",
      "Loss: \n",
      " 0.00014748387045619845\n",
      "\n",
      "\n",
      "Epoch: 677\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8991429 ]\n",
      " [0.86016727]\n",
      " [0.88746493]]\n",
      "Loss: \n",
      " 0.00014715773846261785\n",
      "\n",
      "\n",
      "Epoch: 678\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89916379]\n",
      " [0.86019317]\n",
      " [0.88748669]]\n",
      "Loss: \n",
      " 0.00014683383648280194\n",
      "\n",
      "\n",
      "Epoch: 679\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89918461]\n",
      " [0.86021897]\n",
      " [0.88750838]]\n",
      "Loss: \n",
      " 0.0001465121481910684\n",
      "\n",
      "\n",
      "Epoch: 680\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89920536]\n",
      " [0.86024468]\n",
      " [0.88753   ]]\n",
      "Loss: \n",
      " 0.00014619265739132078\n",
      "\n",
      "\n",
      "Epoch: 681\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89922603]\n",
      " [0.8602703 ]\n",
      " [0.88755153]]\n",
      "Loss: \n",
      " 0.000145875348015934\n",
      "\n",
      "\n",
      "Epoch: 682\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89924662]\n",
      " [0.86029582]\n",
      " [0.88757299]]\n",
      "Loss: \n",
      " 0.00014556020412462937\n",
      "\n",
      "\n",
      "Epoch: 683\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89926714]\n",
      " [0.86032125]\n",
      " [0.88759437]]\n",
      "Loss: \n",
      " 0.0001452472099033575\n",
      "\n",
      "\n",
      "Epoch: 684\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89928759]\n",
      " [0.86034659]\n",
      " [0.88761567]]\n",
      "Loss: \n",
      " 0.0001449363496632071\n",
      "\n",
      "\n",
      "Epoch: 685\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89930797]\n",
      " [0.86037184]\n",
      " [0.8876369 ]]\n",
      "Loss: \n",
      " 0.0001446276078393043\n",
      "\n",
      "\n",
      "Epoch: 686\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89932827]\n",
      " [0.860397  ]\n",
      " [0.88765805]]\n",
      "Loss: \n",
      " 0.00014432096898974912\n",
      "\n",
      "\n",
      "Epoch: 687\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8993485 ]\n",
      " [0.86042207]\n",
      " [0.88767913]]\n",
      "Loss: \n",
      " 0.00014401641779452758\n",
      "\n",
      "\n",
      "Epoch: 688\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89936865]\n",
      " [0.86044705]\n",
      " [0.88770013]]\n",
      "Loss: \n",
      " 0.0001437139390544764\n",
      "\n",
      "\n",
      "Epoch: 689\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89938874]\n",
      " [0.86047194]\n",
      " [0.88772105]]\n",
      "Loss: \n",
      " 0.00014341351769021064\n",
      "\n",
      "\n",
      "Epoch: 690\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89940875]\n",
      " [0.86049674]\n",
      " [0.8877419 ]]\n",
      "Loss: \n",
      " 0.00014311513874110872\n",
      "\n",
      "\n",
      "Epoch: 691\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89942869]\n",
      " [0.86052146]\n",
      " [0.88776268]]\n",
      "Loss: \n",
      " 0.00014281878736426438\n",
      "\n",
      "\n",
      "Epoch: 692\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89944856]\n",
      " [0.86054608]\n",
      " [0.88778338]]\n",
      "Loss: \n",
      " 0.0001425244488334864\n",
      "\n",
      "\n",
      "Epoch: 693\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89946836]\n",
      " [0.86057062]\n",
      " [0.88780401]]\n",
      "Loss: \n",
      " 0.000142232108538275\n",
      "\n",
      "\n",
      "Epoch: 694\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89948809]\n",
      " [0.86059507]\n",
      " [0.88782456]]\n",
      "Loss: \n",
      " 0.00014194175198283744\n",
      "\n",
      "\n",
      "Epoch: 695\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89950774]\n",
      " [0.86061943]\n",
      " [0.88784504]]\n",
      "Loss: \n",
      " 0.00014165336478508435\n",
      "\n",
      "\n",
      "Epoch: 696\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89952733]\n",
      " [0.8606437 ]\n",
      " [0.88786545]]\n",
      "Loss: \n",
      " 0.00014136693267566375\n",
      "\n",
      "\n",
      "Epoch: 697\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89954685]\n",
      " [0.86066789]\n",
      " [0.88788579]]\n",
      "Loss: \n",
      " 0.0001410824414969768\n",
      "\n",
      "\n",
      "Epoch: 698\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8995663 ]\n",
      " [0.86069199]\n",
      " [0.88790605]]\n",
      "Loss: \n",
      " 0.00014079987720223838\n",
      "\n",
      "\n",
      "Epoch: 699\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89958568]\n",
      " [0.86071601]\n",
      " [0.88792624]]\n",
      "Loss: \n",
      " 0.00014051922585449483\n",
      "\n",
      "\n",
      "Epoch: 700\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89960499]\n",
      " [0.86073994]\n",
      " [0.88794636]]\n",
      "Loss: \n",
      " 0.00014024047362571013\n",
      "\n",
      "\n",
      "Epoch: 701\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89962423]\n",
      " [0.86076378]\n",
      " [0.88796641]]\n",
      "Loss: \n",
      " 0.00013996360679581764\n",
      "\n",
      "\n",
      "Epoch: 702\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8996434 ]\n",
      " [0.86078754]\n",
      " [0.88798639]]\n",
      "Loss: \n",
      " 0.00013968861175179333\n",
      "\n",
      "\n",
      "Epoch: 703\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89966251]\n",
      " [0.86081122]\n",
      " [0.88800629]]\n",
      "Loss: \n",
      " 0.00013941547498674643\n",
      "\n",
      "\n",
      "Epoch: 704\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89968155]\n",
      " [0.86083481]\n",
      " [0.88802613]]\n",
      "Loss: \n",
      " 0.00013914418309901534\n",
      "\n",
      "\n",
      "Epoch: 705\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89970052]\n",
      " [0.86085832]\n",
      " [0.88804589]]\n",
      "Loss: \n",
      " 0.00013887472279125004\n",
      "\n",
      "\n",
      "Epoch: 706\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89971942]\n",
      " [0.86088175]\n",
      " [0.88806559]]\n",
      "Loss: \n",
      " 0.00013860708086954447\n",
      "\n",
      "\n",
      "Epoch: 707\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89973826]\n",
      " [0.86090509]\n",
      " [0.88808521]]\n",
      "Loss: \n",
      " 0.00013834124424254586\n",
      "\n",
      "\n",
      "Epoch: 708\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89975703]\n",
      " [0.86092835]\n",
      " [0.88810477]]\n",
      "Loss: \n",
      " 0.00013807719992057357\n",
      "\n",
      "\n",
      "Epoch: 709\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89977573]\n",
      " [0.86095152]\n",
      " [0.88812426]]\n",
      "Loss: \n",
      " 0.00013781493501476152\n",
      "\n",
      "\n",
      "Epoch: 710\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89979437]\n",
      " [0.86097462]\n",
      " [0.88814368]]\n",
      "Loss: \n",
      " 0.000137554436736206\n",
      "\n",
      "\n",
      "Epoch: 711\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89981294]\n",
      " [0.86099763]\n",
      " [0.88816302]]\n",
      "Loss: \n",
      " 0.00013729569239510512\n",
      "\n",
      "\n",
      "Epoch: 712\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89983145]\n",
      " [0.86102056]\n",
      " [0.88818231]]\n",
      "Loss: \n",
      " 0.0001370386893999173\n",
      "\n",
      "\n",
      "Epoch: 713\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89984989]\n",
      " [0.86104341]\n",
      " [0.88820152]]\n",
      "Loss: \n",
      " 0.00013678341525654833\n",
      "\n",
      "\n",
      "Epoch: 714\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89986826]\n",
      " [0.86106618]\n",
      " [0.88822066]]\n",
      "Loss: \n",
      " 0.0001365298575674994\n",
      "\n",
      "\n",
      "Epoch: 715\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89988658]\n",
      " [0.86108887]\n",
      " [0.88823974]]\n",
      "Loss: \n",
      " 0.0001362780040310618\n",
      "\n",
      "\n",
      "Epoch: 716\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89990482]\n",
      " [0.86111148]\n",
      " [0.88825875]]\n",
      "Loss: \n",
      " 0.0001360278424405105\n",
      "\n",
      "\n",
      "Epoch: 717\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.899923  ]\n",
      " [0.86113401]\n",
      " [0.8882777 ]]\n",
      "Loss: \n",
      " 0.00013577936068329835\n",
      "\n",
      "\n",
      "Epoch: 718\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89994112]\n",
      " [0.86115646]\n",
      " [0.88829657]]\n",
      "Loss: \n",
      " 0.00013553254674025198\n",
      "\n",
      "\n",
      "Epoch: 719\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89995918]\n",
      " [0.86117883]\n",
      " [0.88831538]]\n",
      "Loss: \n",
      " 0.00013528738868480442\n",
      "\n",
      "\n",
      "Epoch: 720\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89997717]\n",
      " [0.86120112]\n",
      " [0.88833413]]\n",
      "Loss: \n",
      " 0.0001350438746821915\n",
      "\n",
      "\n",
      "Epoch: 721\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8999951 ]\n",
      " [0.86122333]\n",
      " [0.88835281]]\n",
      "Loss: \n",
      " 0.00013480199298869912\n",
      "\n",
      "\n",
      "Epoch: 722\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90001296]\n",
      " [0.86124547]\n",
      " [0.88837142]]\n",
      "Loss: \n",
      " 0.00013456173195088378\n",
      "\n",
      "\n",
      "Epoch: 723\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90003076]\n",
      " [0.86126753]\n",
      " [0.88838997]]\n",
      "Loss: \n",
      " 0.0001343230800048224\n",
      "\n",
      "\n",
      "Epoch: 724\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.9000485 ]\n",
      " [0.86128951]\n",
      " [0.88840845]]\n",
      "Loss: \n",
      " 0.00013408602567535087\n",
      "\n",
      "\n",
      "Epoch: 725\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90006618]\n",
      " [0.86131141]\n",
      " [0.88842687]]\n",
      "Loss: \n",
      " 0.00013385055757533676\n",
      "\n",
      "\n",
      "Epoch: 726\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.9000838 ]\n",
      " [0.86133323]\n",
      " [0.88844522]]\n",
      "Loss: \n",
      " 0.00013361666440491767\n",
      "\n",
      "\n",
      "Epoch: 727\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90010135]\n",
      " [0.86135498]\n",
      " [0.88846351]]\n",
      "Loss: \n",
      " 0.00013338433495079636\n",
      "\n",
      "\n",
      "Epoch: 728\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90011884]\n",
      " [0.86137665]\n",
      " [0.88848173]]\n",
      "Loss: \n",
      " 0.00013315355808549468\n",
      "\n",
      "\n",
      "Epoch: 729\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90013628]\n",
      " [0.86139825]\n",
      " [0.88849989]]\n",
      "Loss: \n",
      " 0.00013292432276664864\n",
      "\n",
      "\n",
      "Epoch: 730\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90015365]\n",
      " [0.86141977]\n",
      " [0.88851799]]\n",
      "Loss: \n",
      " 0.0001326966180362913\n",
      "\n",
      "\n",
      "Epoch: 731\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90017096]\n",
      " [0.86144122]\n",
      " [0.88853603]]\n",
      "Loss: \n",
      " 0.00013247043302015604\n",
      "\n",
      "\n",
      "Epoch: 732\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90018821]\n",
      " [0.86146259]\n",
      " [0.888554  ]]\n",
      "Loss: \n",
      " 0.00013224575692697134\n",
      "\n",
      "\n",
      "Epoch: 733\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.9002054 ]\n",
      " [0.86148388]\n",
      " [0.8885719 ]]\n",
      "Loss: \n",
      " 0.0001320225790477709\n",
      "\n",
      "\n",
      "Epoch: 734\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90022252]\n",
      " [0.8615051 ]\n",
      " [0.88858975]]\n",
      "Loss: \n",
      " 0.00013180088875521345\n",
      "\n",
      "\n",
      "Epoch: 735\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90023959]\n",
      " [0.86152625]\n",
      " [0.88860753]]\n",
      "Loss: \n",
      " 0.00013158067550289682\n",
      "\n",
      "\n",
      "Epoch: 736\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.9002566 ]\n",
      " [0.86154732]\n",
      " [0.88862526]]\n",
      "Loss: \n",
      " 0.00013136192882469118\n",
      "\n",
      "\n",
      "Epoch: 737\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90027356]\n",
      " [0.86156832]\n",
      " [0.88864292]]\n",
      "Loss: \n",
      " 0.00013114463833407378\n",
      "\n",
      "\n",
      "Epoch: 738\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90029045]\n",
      " [0.86158924]\n",
      " [0.88866051]]\n",
      "Loss: \n",
      " 0.00013092879372345541\n",
      "\n",
      "\n",
      "Epoch: 739\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90030728]\n",
      " [0.8616101 ]\n",
      " [0.88867805]]\n",
      "Loss: \n",
      " 0.00013071438476355192\n",
      "\n",
      "\n",
      "Epoch: 740\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90032406]\n",
      " [0.86163088]\n",
      " [0.88869553]]\n",
      "Loss: \n",
      " 0.0001305014013027079\n",
      "\n",
      "\n",
      "Epoch: 741\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90034077]\n",
      " [0.86165158]\n",
      " [0.88871294]]\n",
      "Loss: \n",
      " 0.00013028983326626964\n",
      "\n",
      "\n",
      "Epoch: 742\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90035743]\n",
      " [0.86167222]\n",
      " [0.88873029]]\n",
      "Loss: \n",
      " 0.00013007967065595323\n",
      "\n",
      "\n",
      "Epoch: 743\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90037403]\n",
      " [0.86169278]\n",
      " [0.88874759]]\n",
      "Loss: \n",
      " 0.0001298709035491979\n",
      "\n",
      "\n",
      "Epoch: 744\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90039057]\n",
      " [0.86171327]\n",
      " [0.88876482]]\n",
      "Loss: \n",
      " 0.00012966352209855509\n",
      "\n",
      "\n",
      "Epoch: 745\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90040706]\n",
      " [0.86173369]\n",
      " [0.888782  ]]\n",
      "Loss: \n",
      " 0.00012945751653106093\n",
      "\n",
      "\n",
      "Epoch: 746\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90042349]\n",
      " [0.86175404]\n",
      " [0.88879911]]\n",
      "Loss: \n",
      " 0.0001292528771476294\n",
      "\n",
      "\n",
      "Epoch: 747\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90043986]\n",
      " [0.86177432]\n",
      " [0.88881617]]\n",
      "Loss: \n",
      " 0.00012904959432244087\n",
      "\n",
      "\n",
      "Epoch: 748\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90045617]\n",
      " [0.86179452]\n",
      " [0.88883316]]\n",
      "Loss: \n",
      " 0.00012884765850233672\n",
      "\n",
      "\n",
      "Epoch: 749\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90047243]\n",
      " [0.86181466]\n",
      " [0.8888501 ]]\n",
      "Loss: \n",
      " 0.00012864706020622636\n",
      "\n",
      "\n",
      "Epoch: 750\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90048863]\n",
      " [0.86183473]\n",
      " [0.88886698]]\n",
      "Loss: \n",
      " 0.0001284477900244999\n",
      "\n",
      "\n",
      "Epoch: 751\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90050478]\n",
      " [0.86185473]\n",
      " [0.8888838 ]]\n",
      "Loss: \n",
      " 0.0001282498386184261\n",
      "\n",
      "\n",
      "Epoch: 752\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90052087]\n",
      " [0.86187465]\n",
      " [0.88890056]]\n",
      "Loss: \n",
      " 0.00012805319671958655\n",
      "\n",
      "\n",
      "Epoch: 753\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.9005369 ]\n",
      " [0.86189451]\n",
      " [0.88891726]]\n",
      "Loss: \n",
      " 0.00012785785512930116\n",
      "\n",
      "\n",
      "Epoch: 754\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90055288]\n",
      " [0.8619143 ]\n",
      " [0.88893391]]\n",
      "Loss: \n",
      " 0.00012766380471804047\n",
      "\n",
      "\n",
      "Epoch: 755\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90056881]\n",
      " [0.86193402]\n",
      " [0.8889505 ]]\n",
      "Loss: \n",
      " 0.00012747103642487794\n",
      "\n",
      "\n",
      "Epoch: 756\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90058468]\n",
      " [0.86195368]\n",
      " [0.88896703]]\n",
      "Loss: \n",
      " 0.0001272795412569225\n",
      "\n",
      "\n",
      "Epoch: 757\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90060049]\n",
      " [0.86197326]\n",
      " [0.8889835 ]]\n",
      "Loss: \n",
      " 0.00012708931028876166\n",
      "\n",
      "\n",
      "Epoch: 758\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90061625]\n",
      " [0.86199278]\n",
      " [0.88899992]]\n",
      "Loss: \n",
      " 0.00012690033466191468\n",
      "\n",
      "\n",
      "Epoch: 759\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90063196]\n",
      " [0.86201223]\n",
      " [0.88901628]]\n",
      "Loss: \n",
      " 0.00012671260558428426\n",
      "\n",
      "\n",
      "Epoch: 760\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90064761]\n",
      " [0.86203161]\n",
      " [0.88903258]]\n",
      "Loss: \n",
      " 0.00012652611432961564\n",
      "\n",
      "\n",
      "Epoch: 761\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90066321]\n",
      " [0.86205092]\n",
      " [0.88904883]]\n",
      "Loss: \n",
      " 0.0001263408522369726\n",
      "\n",
      "\n",
      "Epoch: 762\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90067875]\n",
      " [0.86207017]\n",
      " [0.88906502]]\n",
      "Loss: \n",
      " 0.00012615681071017972\n",
      "\n",
      "\n",
      "Epoch: 763\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90069424]\n",
      " [0.86208935]\n",
      " [0.88908116]]\n",
      "Loss: \n",
      " 0.0001259739812173293\n",
      "\n",
      "\n",
      "Epoch: 764\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90070968]\n",
      " [0.86210847]\n",
      " [0.88909724]]\n",
      "Loss: \n",
      " 0.00012579235529023246\n",
      "\n",
      "\n",
      "Epoch: 765\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90072506]\n",
      " [0.86212752]\n",
      " [0.88911326]]\n",
      "Loss: \n",
      " 0.00012561192452392088\n",
      "\n",
      "\n",
      "Epoch: 766\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.9007404 ]\n",
      " [0.8621465 ]\n",
      " [0.88912923]]\n",
      "Loss: \n",
      " 0.0001254326805761271\n",
      "\n",
      "\n",
      "Epoch: 767\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90075568]\n",
      " [0.86216542]\n",
      " [0.88914514]]\n",
      "Loss: \n",
      " 0.0001252546151667723\n",
      "\n",
      "\n",
      "Epoch: 768\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.9007709 ]\n",
      " [0.86218427]\n",
      " [0.88916101]]\n",
      "Loss: \n",
      " 0.00012507772007746998\n",
      "\n",
      "\n",
      "Epoch: 769\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90078608]\n",
      " [0.86220306]\n",
      " [0.88917681]]\n",
      "Loss: \n",
      " 0.00012490198715102506\n",
      "\n",
      "\n",
      "Epoch: 770\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.9008012 ]\n",
      " [0.86222178]\n",
      " [0.88919256]]\n",
      "Loss: \n",
      " 0.00012472740829094761\n",
      "\n",
      "\n",
      "Epoch: 771\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90081627]\n",
      " [0.86224044]\n",
      " [0.88920826]]\n",
      "Loss: \n",
      " 0.00012455397546094394\n",
      "\n",
      "\n",
      "Epoch: 772\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90083129]\n",
      " [0.86225903]\n",
      " [0.8892239 ]]\n",
      "Loss: \n",
      " 0.00012438168068444852\n",
      "\n",
      "\n",
      "Epoch: 773\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90084626]\n",
      " [0.86227756]\n",
      " [0.88923949]]\n",
      "Loss: \n",
      " 0.00012421051604413863\n",
      "\n",
      "\n",
      "Epoch: 774\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90086117]\n",
      " [0.86229603]\n",
      " [0.88925503]]\n",
      "Loss: \n",
      " 0.00012404047368145282\n",
      "\n",
      "\n",
      "Epoch: 775\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90087604]\n",
      " [0.86231443]\n",
      " [0.88927051]]\n",
      "Loss: \n",
      " 0.00012387154579611922\n",
      "\n",
      "\n",
      "Epoch: 776\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90089085]\n",
      " [0.86233277]\n",
      " [0.88928594]]\n",
      "Loss: \n",
      " 0.00012370372464569376\n",
      "\n",
      "\n",
      "Epoch: 777\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90090562]\n",
      " [0.86235105]\n",
      " [0.88930132]]\n",
      "Loss: \n",
      " 0.0001235370025450855\n",
      "\n",
      "\n",
      "Epoch: 778\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90092033]\n",
      " [0.86236926]\n",
      " [0.88931664]]\n",
      "Loss: \n",
      " 0.0001233713718661085\n",
      "\n",
      "\n",
      "Epoch: 779\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.900935  ]\n",
      " [0.86238741]\n",
      " [0.88933191]]\n",
      "Loss: \n",
      " 0.0001232068250370114\n",
      "\n",
      "\n",
      "Epoch: 780\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90094961]\n",
      " [0.8624055 ]\n",
      " [0.88934713]]\n",
      "Loss: \n",
      " 0.00012304335454203628\n",
      "\n",
      "\n",
      "Epoch: 781\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90096417]\n",
      " [0.86242353]\n",
      " [0.8893623 ]]\n",
      "Loss: \n",
      " 0.00012288095292096822\n",
      "\n",
      "\n",
      "Epoch: 782\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90097869]\n",
      " [0.86244149]\n",
      " [0.88937742]]\n",
      "Loss: \n",
      " 0.00012271961276868462\n",
      "\n",
      "\n",
      "Epoch: 783\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90099315]\n",
      " [0.8624594 ]\n",
      " [0.88939248]]\n",
      "Loss: \n",
      " 0.00012255932673471999\n",
      "\n",
      "\n",
      "Epoch: 784\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90100757]\n",
      " [0.86247724]\n",
      " [0.8894075 ]]\n",
      "Loss: \n",
      " 0.00012240008752283232\n",
      "\n",
      "\n",
      "Epoch: 785\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90102193]\n",
      " [0.86249502]\n",
      " [0.88942246]]\n",
      "Loss: \n",
      " 0.00012224188789056482\n",
      "\n",
      "\n",
      "Epoch: 786\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90103625]\n",
      " [0.86251274]\n",
      " [0.88943737]]\n",
      "Loss: \n",
      " 0.00012208472064881567\n",
      "\n",
      "\n",
      "Epoch: 787\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90105052]\n",
      " [0.8625304 ]\n",
      " [0.88945223]]\n",
      "Loss: \n",
      " 0.00012192857866142303\n",
      "\n",
      "\n",
      "Epoch: 788\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90106474]\n",
      " [0.862548  ]\n",
      " [0.88946704]]\n",
      "Loss: \n",
      " 0.00012177345484473111\n",
      "\n",
      "\n",
      "Epoch: 789\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90107891]\n",
      " [0.86256554]\n",
      " [0.8894818 ]]\n",
      "Loss: \n",
      " 0.00012161934216717891\n",
      "\n",
      "\n",
      "Epoch: 790\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90109304]\n",
      " [0.86258302]\n",
      " [0.8894965 ]]\n",
      "Loss: \n",
      " 0.00012146623364887853\n",
      "\n",
      "\n",
      "Epoch: 791\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90110711]\n",
      " [0.86260044]\n",
      " [0.88951116]]\n",
      "Loss: \n",
      " 0.00012131412236122387\n",
      "\n",
      "\n",
      "Epoch: 792\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90112114]\n",
      " [0.8626178 ]\n",
      " [0.88952577]]\n",
      "Loss: \n",
      " 0.00012116300142645935\n",
      "\n",
      "\n",
      "Epoch: 793\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90113512]\n",
      " [0.8626351 ]\n",
      " [0.88954033]]\n",
      "Loss: \n",
      " 0.0001210128640172952\n",
      "\n",
      "\n",
      "Epoch: 794\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90114906]\n",
      " [0.86265234]\n",
      " [0.88955484]]\n",
      "Loss: \n",
      " 0.00012086370335648784\n",
      "\n",
      "\n",
      "Epoch: 795\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90116294]\n",
      " [0.86266952]\n",
      " [0.8895693 ]]\n",
      "Loss: \n",
      " 0.00012071551271647132\n",
      "\n",
      "\n",
      "Epoch: 796\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90117678]\n",
      " [0.86268664]\n",
      " [0.88958371]]\n",
      "Loss: \n",
      " 0.00012056828541893247\n",
      "\n",
      "\n",
      "Epoch: 797\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90119058]\n",
      " [0.86270371]\n",
      " [0.88959807]]\n",
      "Loss: \n",
      " 0.00012042201483445098\n",
      "\n",
      "\n",
      "Epoch: 798\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90120432]\n",
      " [0.86272071]\n",
      " [0.88961238]]\n",
      "Loss: \n",
      " 0.0001202766943820898\n",
      "\n",
      "\n",
      "Epoch: 799\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90121802]\n",
      " [0.86273766]\n",
      " [0.88962665]]\n",
      "Loss: \n",
      " 0.00012013231752902247\n",
      "\n",
      "\n",
      "Epoch: 800\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90123167]\n",
      " [0.86275456]\n",
      " [0.88964086]]\n",
      "Loss: \n",
      " 0.00011998887779015368\n",
      "\n",
      "\n",
      "Epoch: 801\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90124528]\n",
      " [0.86277139]\n",
      " [0.88965503]]\n",
      "Loss: \n",
      " 0.00011984636872774475\n",
      "\n",
      "\n",
      "Epoch: 802\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90125884]\n",
      " [0.86278817]\n",
      " [0.88966915]]\n",
      "Loss: \n",
      " 0.00011970478395103202\n",
      "\n",
      "\n",
      "Epoch: 803\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90127236]\n",
      " [0.86280489]\n",
      " [0.88968322]]\n",
      "Loss: \n",
      " 0.00011956411711586418\n",
      "\n",
      "\n",
      "Epoch: 804\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90128583]\n",
      " [0.86282155]\n",
      " [0.88969725]]\n",
      "Loss: \n",
      " 0.00011942436192433036\n",
      "\n",
      "\n",
      "Epoch: 805\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90129925]\n",
      " [0.86283815]\n",
      " [0.88971123]]\n",
      "Loss: \n",
      " 0.00011928551212441309\n",
      "\n",
      "\n",
      "Epoch: 806\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90131263]\n",
      " [0.8628547 ]\n",
      " [0.88972516]]\n",
      "Loss: \n",
      " 0.00011914756150959251\n",
      "\n",
      "\n",
      "Epoch: 807\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90132596]\n",
      " [0.8628712 ]\n",
      " [0.88973904]]\n",
      "Loss: \n",
      " 0.00011901050391852862\n",
      "\n",
      "\n",
      "Epoch: 808\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90133925]\n",
      " [0.86288763]\n",
      " [0.88975287]]\n",
      "Loss: \n",
      " 0.000118874333234683\n",
      "\n",
      "\n",
      "Epoch: 809\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.9013525 ]\n",
      " [0.86290402]\n",
      " [0.88976666]]\n",
      "Loss: \n",
      " 0.00011873904338597593\n",
      "\n",
      "\n",
      "Epoch: 810\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.9013657 ]\n",
      " [0.86292034]\n",
      " [0.8897804 ]]\n",
      "Loss: \n",
      " 0.00011860462834443047\n",
      "\n",
      "\n",
      "Epoch: 811\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90137885]\n",
      " [0.86293661]\n",
      " [0.8897941 ]]\n",
      "Loss: \n",
      " 0.00011847108212583579\n",
      "\n",
      "\n",
      "Epoch: 812\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90139196]\n",
      " [0.86295283]\n",
      " [0.88980775]]\n",
      "Loss: \n",
      " 0.00011833839878940573\n",
      "\n",
      "\n",
      "Epoch: 813\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90140503]\n",
      " [0.86296899]\n",
      " [0.88982135]]\n",
      "Loss: \n",
      " 0.0001182065724374285\n",
      "\n",
      "\n",
      "Epoch: 814\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90141805]\n",
      " [0.86298509]\n",
      " [0.88983491]]\n",
      "Loss: \n",
      " 0.0001180755972149456\n",
      "\n",
      "\n",
      "Epoch: 815\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90143103]\n",
      " [0.86300114]\n",
      " [0.88984842]]\n",
      "Loss: \n",
      " 0.00011794546730939616\n",
      "\n",
      "\n",
      "Epoch: 816\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90144397]\n",
      " [0.86301714]\n",
      " [0.88986189]]\n",
      "Loss: \n",
      " 0.00011781617695031467\n",
      "\n",
      "\n",
      "Epoch: 817\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90145686]\n",
      " [0.86303308]\n",
      " [0.88987531]]\n",
      "Loss: \n",
      " 0.00011768772040898156\n",
      "\n",
      "\n",
      "Epoch: 818\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90146971]\n",
      " [0.86304897]\n",
      " [0.88988869]]\n",
      "Loss: \n",
      " 0.00011756009199809777\n",
      "\n",
      "\n",
      "Epoch: 819\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90148252]\n",
      " [0.86306481]\n",
      " [0.88990202]]\n",
      "Loss: \n",
      " 0.00011743328607147853\n",
      "\n",
      "\n",
      "Epoch: 820\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90149528]\n",
      " [0.86308059]\n",
      " [0.8899153 ]]\n",
      "Loss: \n",
      " 0.00011730729702372022\n",
      "\n",
      "\n",
      "Epoch: 821\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.901508  ]\n",
      " [0.86309631]\n",
      " [0.88992854]]\n",
      "Loss: \n",
      " 0.00011718211928988852\n",
      "\n",
      "\n",
      "Epoch: 822\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90152068]\n",
      " [0.86311199]\n",
      " [0.88994174]]\n",
      "Loss: \n",
      " 0.00011705774734519598\n",
      "\n",
      "\n",
      "Epoch: 823\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90153331]\n",
      " [0.86312761]\n",
      " [0.88995489]]\n",
      "Loss: \n",
      " 0.0001169341757047072\n",
      "\n",
      "\n",
      "Epoch: 824\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90154591]\n",
      " [0.86314318]\n",
      " [0.889968  ]]\n",
      "Loss: \n",
      " 0.00011681139892301736\n",
      "\n",
      "\n",
      "Epoch: 825\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90155846]\n",
      " [0.86315869]\n",
      " [0.88998106]]\n",
      "Loss: \n",
      " 0.00011668941159394005\n",
      "\n",
      "\n",
      "Epoch: 826\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90157097]\n",
      " [0.86317416]\n",
      " [0.88999408]]\n",
      "Loss: \n",
      " 0.00011656820835021555\n",
      "\n",
      "\n",
      "Epoch: 827\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90158343]\n",
      " [0.86318957]\n",
      " [0.89000706]]\n",
      "Loss: \n",
      " 0.00011644778386321782\n",
      "\n",
      "\n",
      "Epoch: 828\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90159586]\n",
      " [0.86320493]\n",
      " [0.89001999]]\n",
      "Loss: \n",
      " 0.00011632813284262511\n",
      "\n",
      "\n",
      "Epoch: 829\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90160824]\n",
      " [0.86322024]\n",
      " [0.89003288]]\n",
      "Loss: \n",
      " 0.00011620925003614905\n",
      "\n",
      "\n",
      "Epoch: 830\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90162059]\n",
      " [0.86323549]\n",
      " [0.89004573]]\n",
      "Loss: \n",
      " 0.00011609113022924054\n",
      "\n",
      "\n",
      "Epoch: 831\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90163289]\n",
      " [0.8632507 ]\n",
      " [0.89005853]]\n",
      "Loss: \n",
      " 0.00011597376824478327\n",
      "\n",
      "\n",
      "Epoch: 832\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90164515]\n",
      " [0.86326585]\n",
      " [0.89007129]]\n",
      "Loss: \n",
      " 0.00011585715894282238\n",
      "\n",
      "\n",
      "Epoch: 833\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90165737]\n",
      " [0.86328096]\n",
      " [0.89008401]]\n",
      "Loss: \n",
      " 0.00011574129722025702\n",
      "\n",
      "\n",
      "Epoch: 834\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90166955]\n",
      " [0.86329601]\n",
      " [0.89009668]]\n",
      "Loss: \n",
      " 0.00011562617801058313\n",
      "\n",
      "\n",
      "Epoch: 835\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90168169]\n",
      " [0.86331101]\n",
      " [0.89010932]]\n",
      "Loss: \n",
      " 0.00011551179628358932\n",
      "\n",
      "\n",
      "Epoch: 836\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90169378]\n",
      " [0.86332596]\n",
      " [0.89012191]]\n",
      "Loss: \n",
      " 0.000115398147045085\n",
      "\n",
      "\n",
      "Epoch: 837\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90170584]\n",
      " [0.86334086]\n",
      " [0.89013445]]\n",
      "Loss: \n",
      " 0.00011528522533662769\n",
      "\n",
      "\n",
      "Epoch: 838\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90171786]\n",
      " [0.86335571]\n",
      " [0.89014696]]\n",
      "Loss: \n",
      " 0.00011517302623524812\n",
      "\n",
      "\n",
      "Epoch: 839\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90172984]\n",
      " [0.86337051]\n",
      " [0.89015942]]\n",
      "Loss: \n",
      " 0.00011506154485316977\n",
      "\n",
      "\n",
      "Epoch: 840\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90174177]\n",
      " [0.86338526]\n",
      " [0.89017185]]\n",
      "Loss: \n",
      " 0.00011495077633754293\n",
      "\n",
      "\n",
      "Epoch: 841\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90175367]\n",
      " [0.86339996]\n",
      " [0.89018423]]\n",
      "Loss: \n",
      " 0.00011484071587018327\n",
      "\n",
      "\n",
      "Epoch: 842\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90176553]\n",
      " [0.86341461]\n",
      " [0.89019657]]\n",
      "Loss: \n",
      " 0.00011473135866730188\n",
      "\n",
      "\n",
      "Epoch: 843\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90177735]\n",
      " [0.86342922]\n",
      " [0.89020887]]\n",
      "Loss: \n",
      " 0.00011462269997923353\n",
      "\n",
      "\n",
      "Epoch: 844\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90178913]\n",
      " [0.86344377]\n",
      " [0.89022112]]\n",
      "Loss: \n",
      " 0.00011451473509019165\n",
      "\n",
      "\n",
      "Epoch: 845\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90180087]\n",
      " [0.86345827]\n",
      " [0.89023334]]\n",
      "Loss: \n",
      " 0.00011440745931799903\n",
      "\n",
      "\n",
      "Epoch: 846\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90181257]\n",
      " [0.86347273]\n",
      " [0.89024552]]\n",
      "Loss: \n",
      " 0.00011430086801382713\n",
      "\n",
      "\n",
      "Epoch: 847\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90182424]\n",
      " [0.86348714]\n",
      " [0.89025765]]\n",
      "Loss: \n",
      " 0.00011419495656195729\n",
      "\n",
      "\n",
      "Epoch: 848\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90183586]\n",
      " [0.8635015 ]\n",
      " [0.89026975]]\n",
      "Loss: \n",
      " 0.00011408972037950951\n",
      "\n",
      "\n",
      "Epoch: 849\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90184745]\n",
      " [0.86351581]\n",
      " [0.8902818 ]]\n",
      "Loss: \n",
      " 0.00011398515491620608\n",
      "\n",
      "\n",
      "Epoch: 850\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.901859  ]\n",
      " [0.86353007]\n",
      " [0.89029382]]\n",
      "Loss: \n",
      " 0.00011388125565411461\n",
      "\n",
      "\n",
      "Epoch: 851\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90187051]\n",
      " [0.86354429]\n",
      " [0.89030579]]\n",
      "Loss: \n",
      " 0.00011377801810740911\n",
      "\n",
      "\n",
      "Epoch: 852\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90188198]\n",
      " [0.86355845]\n",
      " [0.89031772]]\n",
      "Loss: \n",
      " 0.00011367543782211634\n",
      "\n",
      "\n",
      "Epoch: 853\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90189341]\n",
      " [0.86357258]\n",
      " [0.89032962]]\n",
      "Loss: \n",
      " 0.00011357351037588258\n",
      "\n",
      "\n",
      "Epoch: 854\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90190481]\n",
      " [0.86358665]\n",
      " [0.89034147]]\n",
      "Loss: \n",
      " 0.00011347223137772762\n",
      "\n",
      "\n",
      "Epoch: 855\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90191616]\n",
      " [0.86360067]\n",
      " [0.89035329]]\n",
      "Loss: \n",
      " 0.00011337159646781017\n",
      "\n",
      "\n",
      "Epoch: 856\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90192748]\n",
      " [0.86361465]\n",
      " [0.89036507]]\n",
      "Loss: \n",
      " 0.00011327160131718655\n",
      "\n",
      "\n",
      "Epoch: 857\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90193877]\n",
      " [0.86362859]\n",
      " [0.8903768 ]]\n",
      "Loss: \n",
      " 0.0001131722416275858\n",
      "\n",
      "\n",
      "Epoch: 858\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90195001]\n",
      " [0.86364247]\n",
      " [0.8903885 ]]\n",
      "Loss: \n",
      " 0.00011307351313116148\n",
      "\n",
      "\n",
      "Epoch: 859\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90196122]\n",
      " [0.86365631]\n",
      " [0.89040016]]\n",
      "Loss: \n",
      " 0.00011297541159027789\n",
      "\n",
      "\n",
      "Epoch: 860\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90197239]\n",
      " [0.86367011]\n",
      " [0.89041178]]\n",
      "Loss: \n",
      " 0.00011287793279727579\n",
      "\n",
      "\n",
      "Epoch: 861\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90198353]\n",
      " [0.86368385]\n",
      " [0.89042337]]\n",
      "Loss: \n",
      " 0.00011278107257423573\n",
      "\n",
      "\n",
      "Epoch: 862\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90199463]\n",
      " [0.86369755]\n",
      " [0.89043491]]\n",
      "Loss: \n",
      " 0.00011268482677276499\n",
      "\n",
      "\n",
      "Epoch: 863\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90200569]\n",
      " [0.86371121]\n",
      " [0.89044642]]\n",
      "Loss: \n",
      " 0.00011258919127377727\n",
      "\n",
      "\n",
      "Epoch: 864\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90201671]\n",
      " [0.86372482]\n",
      " [0.89045788]]\n",
      "Loss: \n",
      " 0.00011249416198725389\n",
      "\n",
      "\n",
      "Epoch: 865\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.9020277 ]\n",
      " [0.86373838]\n",
      " [0.89046931]]\n",
      "Loss: \n",
      " 0.00011239973485204336\n",
      "\n",
      "\n",
      "Epoch: 866\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90203866]\n",
      " [0.8637519 ]\n",
      " [0.8904807 ]]\n",
      "Loss: \n",
      " 0.00011230590583563518\n",
      "\n",
      "\n",
      "Epoch: 867\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90204957]\n",
      " [0.86376538]\n",
      " [0.89049206]]\n",
      "Loss: \n",
      " 0.00011221267093394374\n",
      "\n",
      "\n",
      "Epoch: 868\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90206045]\n",
      " [0.86377881]\n",
      " [0.89050337]]\n",
      "Loss: \n",
      " 0.00011212002617109138\n",
      "\n",
      "\n",
      "Epoch: 869\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.9020713 ]\n",
      " [0.86379219]\n",
      " [0.89051465]]\n",
      "Loss: \n",
      " 0.00011202796759920599\n",
      "\n",
      "\n",
      "Epoch: 870\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90208211]\n",
      " [0.86380553]\n",
      " [0.89052589]]\n",
      "Loss: \n",
      " 0.00011193649129820258\n",
      "\n",
      "\n",
      "Epoch: 871\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90209288]\n",
      " [0.86381883]\n",
      " [0.8905371 ]]\n",
      "Loss: \n",
      " 0.00011184559337557109\n",
      "\n",
      "\n",
      "Epoch: 872\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90210362]\n",
      " [0.86383208]\n",
      " [0.89054827]]\n",
      "Loss: \n",
      " 0.00011175526996618205\n",
      "\n",
      "\n",
      "Epoch: 873\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90211432]\n",
      " [0.86384529]\n",
      " [0.8905594 ]]\n",
      "Loss: \n",
      " 0.00011166551723206833\n",
      "\n",
      "\n",
      "Epoch: 874\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90212499]\n",
      " [0.86385845]\n",
      " [0.89057049]]\n",
      "Loss: \n",
      " 0.00011157633136222629\n",
      "\n",
      "\n",
      "Epoch: 875\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90213563]\n",
      " [0.86387157]\n",
      " [0.89058155]]\n",
      "Loss: \n",
      " 0.00011148770857241652\n",
      "\n",
      "\n",
      "Epoch: 876\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90214622]\n",
      " [0.86388465]\n",
      " [0.89059257]]\n",
      "Loss: \n",
      " 0.0001113996451049576\n",
      "\n",
      "\n",
      "Epoch: 877\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90215679]\n",
      " [0.86389768]\n",
      " [0.89060355]]\n",
      "Loss: \n",
      " 0.00011131213722852923\n",
      "\n",
      "\n",
      "Epoch: 878\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90216732]\n",
      " [0.86391067]\n",
      " [0.8906145 ]]\n",
      "Loss: \n",
      " 0.00011122518123797422\n",
      "\n",
      "\n",
      "Epoch: 879\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90217781]\n",
      " [0.86392362]\n",
      " [0.89062541]]\n",
      "Loss: \n",
      " 0.00011113877345411391\n",
      "\n",
      "\n",
      "Epoch: 880\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90218827]\n",
      " [0.86393652]\n",
      " [0.89063629]]\n",
      "Loss: \n",
      " 0.00011105291022352915\n",
      "\n",
      "\n",
      "Epoch: 881\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.9021987 ]\n",
      " [0.86394938]\n",
      " [0.89064713]]\n",
      "Loss: \n",
      " 0.00011096758791839276\n",
      "\n",
      "\n",
      "Epoch: 882\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90220909]\n",
      " [0.8639622 ]\n",
      " [0.89065793]]\n",
      "Loss: \n",
      " 0.00011088280293626835\n",
      "\n",
      "\n",
      "Epoch: 883\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90221945]\n",
      " [0.86397498]\n",
      " [0.8906687 ]]\n",
      "Loss: \n",
      " 0.0001107985516999163\n",
      "\n",
      "\n",
      "Epoch: 884\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90222977]\n",
      " [0.86398771]\n",
      " [0.89067943]]\n",
      "Loss: \n",
      " 0.00011071483065711649\n",
      "\n",
      "\n",
      "Epoch: 885\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90224006]\n",
      " [0.8640004 ]\n",
      " [0.89069013]]\n",
      "Loss: \n",
      " 0.00011063163628047098\n",
      "\n",
      "\n",
      "Epoch: 886\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90225032]\n",
      " [0.86401305]\n",
      " [0.89070079]]\n",
      "Loss: \n",
      " 0.00011054896506722181\n",
      "\n",
      "\n",
      "Epoch: 887\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90226054]\n",
      " [0.86402565]\n",
      " [0.89071142]]\n",
      "Loss: \n",
      " 0.00011046681353907843\n",
      "\n",
      "\n",
      "Epoch: 888\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90227073]\n",
      " [0.86403822]\n",
      " [0.89072201]]\n",
      "Loss: \n",
      " 0.00011038517824202056\n",
      "\n",
      "\n",
      "Epoch: 889\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90228089]\n",
      " [0.86405074]\n",
      " [0.89073257]]\n",
      "Loss: \n",
      " 0.00011030405574612589\n",
      "\n",
      "\n",
      "Epoch: 890\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90229101]\n",
      " [0.86406323]\n",
      " [0.89074309]]\n",
      "Loss: \n",
      " 0.00011022344264539018\n",
      "\n",
      "\n",
      "Epoch: 891\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.9023011 ]\n",
      " [0.86407567]\n",
      " [0.89075358]]\n",
      "Loss: \n",
      " 0.0001101433355575504\n",
      "\n",
      "\n",
      "Epoch: 892\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90231116]\n",
      " [0.86408807]\n",
      " [0.89076404]]\n",
      "Loss: \n",
      " 0.00011006373112390124\n",
      "\n",
      "\n",
      "Epoch: 893\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90232118]\n",
      " [0.86410042]\n",
      " [0.89077445]]\n",
      "Loss: \n",
      " 0.00010998462600913019\n",
      "\n",
      "\n",
      "Epoch: 894\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90233117]\n",
      " [0.86411274]\n",
      " [0.89078484]]\n",
      "Loss: \n",
      " 0.00010990601690114445\n",
      "\n",
      "\n",
      "Epoch: 895\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90234113]\n",
      " [0.86412502]\n",
      " [0.89079519]]\n",
      "Loss: \n",
      " 0.00010982790051088482\n",
      "\n",
      "\n",
      "Epoch: 896\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90235106]\n",
      " [0.86413725]\n",
      " [0.89080551]]\n",
      "Loss: \n",
      " 0.00010975027357217693\n",
      "\n",
      "\n",
      "Epoch: 897\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90236095]\n",
      " [0.86414945]\n",
      " [0.89081579]]\n",
      "Loss: \n",
      " 0.00010967313284153308\n",
      "\n",
      "\n",
      "Epoch: 898\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90237082]\n",
      " [0.86416161]\n",
      " [0.89082604]]\n",
      "Loss: \n",
      " 0.00010959647509801712\n",
      "\n",
      "\n",
      "Epoch: 899\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90238065]\n",
      " [0.86417372]\n",
      " [0.89083626]]\n",
      "Loss: \n",
      " 0.00010952029714305572\n",
      "\n",
      "\n",
      "Epoch: 900\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90239044]\n",
      " [0.8641858 ]\n",
      " [0.89084644]]\n",
      "Loss: \n",
      " 0.00010944459580028101\n",
      "\n",
      "\n",
      "Epoch: 901\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90240021]\n",
      " [0.86419783]\n",
      " [0.89085659]]\n",
      "Loss: \n",
      " 0.00010936936791536159\n",
      "\n",
      "\n",
      "Epoch: 902\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90240995]\n",
      " [0.86420983]\n",
      " [0.8908667 ]]\n",
      "Loss: \n",
      " 0.00010929461035584421\n",
      "\n",
      "\n",
      "Epoch: 903\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90241965]\n",
      " [0.86422178]\n",
      " [0.89087679]]\n",
      "Loss: \n",
      " 0.0001092203200109954\n",
      "\n",
      "\n",
      "Epoch: 904\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90242932]\n",
      " [0.8642337 ]\n",
      " [0.89088684]]\n",
      "Loss: \n",
      " 0.00010914649379163546\n",
      "\n",
      "\n",
      "Epoch: 905\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90243896]\n",
      " [0.86424558]\n",
      " [0.89089685]]\n",
      "Loss: \n",
      " 0.00010907312862997995\n",
      "\n",
      "\n",
      "Epoch: 906\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90244857]\n",
      " [0.86425742]\n",
      " [0.89090684]]\n",
      "Loss: \n",
      " 0.00010900022147948791\n",
      "\n",
      "\n",
      "Epoch: 907\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90245815]\n",
      " [0.86426922]\n",
      " [0.89091679]]\n",
      "Loss: \n",
      " 0.00010892776931469845\n",
      "\n",
      "\n",
      "Epoch: 908\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90246769]\n",
      " [0.86428098]\n",
      " [0.89092671]]\n",
      "Loss: \n",
      " 0.00010885576913107908\n",
      "\n",
      "\n",
      "Epoch: 909\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90247721]\n",
      " [0.8642927 ]\n",
      " [0.89093659]]\n",
      "Loss: \n",
      " 0.00010878421794487538\n",
      "\n",
      "\n",
      "Epoch: 910\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90248669]\n",
      " [0.86430438]\n",
      " [0.89094645]]\n",
      "Loss: \n",
      " 0.00010871311279295403\n",
      "\n",
      "\n",
      "Epoch: 911\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90249615]\n",
      " [0.86431603]\n",
      " [0.89095627]]\n",
      "Loss: \n",
      " 0.00010864245073264803\n",
      "\n",
      "\n",
      "Epoch: 912\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90250557]\n",
      " [0.86432763]\n",
      " [0.89096606]]\n",
      "Loss: \n",
      " 0.000108572228841617\n",
      "\n",
      "\n",
      "Epoch: 913\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90251496]\n",
      " [0.8643392 ]\n",
      " [0.89097582]]\n",
      "Loss: \n",
      " 0.00010850244421768739\n",
      "\n",
      "\n",
      "Epoch: 914\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90252433]\n",
      " [0.86435073]\n",
      " [0.89098554]]\n",
      "Loss: \n",
      " 0.0001084330939787124\n",
      "\n",
      "\n",
      "Epoch: 915\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90253366]\n",
      " [0.86436222]\n",
      " [0.89099524]]\n",
      "Loss: \n",
      " 0.00010836417526242233\n",
      "\n",
      "\n",
      "Epoch: 916\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90254296]\n",
      " [0.86437368]\n",
      " [0.8910049 ]]\n",
      "Loss: \n",
      " 0.00010829568522627665\n",
      "\n",
      "\n",
      "Epoch: 917\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90255223]\n",
      " [0.86438509]\n",
      " [0.89101453]]\n",
      "Loss: \n",
      " 0.00010822762104732574\n",
      "\n",
      "\n",
      "Epoch: 918\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90256148]\n",
      " [0.86439647]\n",
      " [0.89102413]]\n",
      "Loss: \n",
      " 0.00010815997992205842\n",
      "\n",
      "\n",
      "Epoch: 919\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90257069]\n",
      " [0.86440781]\n",
      " [0.8910337 ]]\n",
      "Loss: \n",
      " 0.00010809275906627387\n",
      "\n",
      "\n",
      "Epoch: 920\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90257987]\n",
      " [0.86441912]\n",
      " [0.89104324]]\n",
      "Loss: \n",
      " 0.00010802595571492235\n",
      "\n",
      "\n",
      "Epoch: 921\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90258902]\n",
      " [0.86443038]\n",
      " [0.89105274]]\n",
      "Loss: \n",
      " 0.00010795956712198605\n",
      "\n",
      "\n",
      "Epoch: 922\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90259815]\n",
      " [0.86444161]\n",
      " [0.89106222]]\n",
      "Loss: \n",
      " 0.00010789359056032049\n",
      "\n",
      "\n",
      "Epoch: 923\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90260724]\n",
      " [0.86445281]\n",
      " [0.89107166]]\n",
      "Loss: \n",
      " 0.00010782802332152902\n",
      "\n",
      "\n",
      "Epoch: 924\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.9026163 ]\n",
      " [0.86446396]\n",
      " [0.89108107]]\n",
      "Loss: \n",
      " 0.00010776286271582825\n",
      "\n",
      "\n",
      "Epoch: 925\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90262534]\n",
      " [0.86447508]\n",
      " [0.89109046]]\n",
      "Loss: \n",
      " 0.00010769810607189828\n",
      "\n",
      "\n",
      "Epoch: 926\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90263434]\n",
      " [0.86448617]\n",
      " [0.89109981]]\n",
      "Loss: \n",
      " 0.0001076337507367655\n",
      "\n",
      "\n",
      "Epoch: 927\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90264332]\n",
      " [0.86449721]\n",
      " [0.89110913]]\n",
      "Loss: \n",
      " 0.00010756979407565815\n",
      "\n",
      "\n",
      "Epoch: 928\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90265227]\n",
      " [0.86450823]\n",
      " [0.89111842]]\n",
      "Loss: \n",
      " 0.0001075062334718754\n",
      "\n",
      "\n",
      "Epoch: 929\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90266119]\n",
      " [0.8645192 ]\n",
      " [0.89112768]]\n",
      "Loss: \n",
      " 0.0001074430663266573\n",
      "\n",
      "\n",
      "Epoch: 930\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90267008]\n",
      " [0.86453014]\n",
      " [0.89113692]]\n",
      "Loss: \n",
      " 0.00010738029005906062\n",
      "\n",
      "\n",
      "Epoch: 931\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90267894]\n",
      " [0.86454104]\n",
      " [0.89114612]]\n",
      "Loss: \n",
      " 0.00010731790210581682\n",
      "\n",
      "\n",
      "Epoch: 932\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90268777]\n",
      " [0.86455191]\n",
      " [0.89115529]]\n",
      "Loss: \n",
      " 0.00010725589992121323\n",
      "\n",
      "\n",
      "Epoch: 933\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90269658]\n",
      " [0.86456274]\n",
      " [0.89116443]]\n",
      "Loss: \n",
      " 0.00010719428097696388\n",
      "\n",
      "\n",
      "Epoch: 934\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90270536]\n",
      " [0.86457354]\n",
      " [0.89117354]]\n",
      "Loss: \n",
      " 0.00010713304276208109\n",
      "\n",
      "\n",
      "Epoch: 935\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.9027141 ]\n",
      " [0.8645843 ]\n",
      " [0.89118262]]\n",
      "Loss: \n",
      " 0.00010707218278275339\n",
      "\n",
      "\n",
      "Epoch: 936\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90272283]\n",
      " [0.86459502]\n",
      " [0.89119168]]\n",
      "Loss: \n",
      " 0.00010701169856221732\n",
      "\n",
      "\n",
      "Epoch: 937\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90273152]\n",
      " [0.86460571]\n",
      " [0.8912007 ]]\n",
      "Loss: \n",
      " 0.00010695158764063743\n",
      "\n",
      "\n",
      "Epoch: 938\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90274018]\n",
      " [0.86461637]\n",
      " [0.89120969]]\n",
      "Loss: \n",
      " 0.00010689184757498424\n",
      "\n",
      "\n",
      "Epoch: 939\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90274882]\n",
      " [0.86462699]\n",
      " [0.89121866]]\n",
      "Loss: \n",
      " 0.00010683247593890756\n",
      "\n",
      "\n",
      "Epoch: 940\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90275743]\n",
      " [0.86463757]\n",
      " [0.89122759]]\n",
      "Loss: \n",
      " 0.0001067734703226221\n",
      "\n",
      "\n",
      "Epoch: 941\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90276601]\n",
      " [0.86464813]\n",
      " [0.8912365 ]]\n",
      "Loss: \n",
      " 0.00010671482833278445\n",
      "\n",
      "\n",
      "Epoch: 942\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90277456]\n",
      " [0.86465864]\n",
      " [0.89124538]]\n",
      "Loss: \n",
      " 0.00010665654759237372\n",
      "\n",
      "\n",
      "Epoch: 943\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90278309]\n",
      " [0.86466912]\n",
      " [0.89125423]]\n",
      "Loss: \n",
      " 0.00010659862574057903\n",
      "\n",
      "\n",
      "Epoch: 944\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90279159]\n",
      " [0.86467957]\n",
      " [0.89126305]]\n",
      "Loss: \n",
      " 0.00010654106043267576\n",
      "\n",
      "\n",
      "Epoch: 945\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90280006]\n",
      " [0.86468999]\n",
      " [0.89127184]]\n",
      "Loss: \n",
      " 0.00010648384933991278\n",
      "\n",
      "\n",
      "Epoch: 946\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.9028085 ]\n",
      " [0.86470037]\n",
      " [0.8912806 ]]\n",
      "Loss: \n",
      " 0.00010642699014940282\n",
      "\n",
      "\n",
      "Epoch: 947\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90281692]\n",
      " [0.86471071]\n",
      " [0.89128934]]\n",
      "Loss: \n",
      " 0.0001063704805639951\n",
      "\n",
      "\n",
      "Epoch: 948\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90282531]\n",
      " [0.86472102]\n",
      " [0.89129805]]\n",
      "Loss: \n",
      " 0.00010631431830217703\n",
      "\n",
      "\n",
      "Epoch: 949\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90283367]\n",
      " [0.8647313 ]\n",
      " [0.89130672]]\n",
      "Loss: \n",
      " 0.00010625850109794988\n",
      "\n",
      "\n",
      "Epoch: 950\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90284201]\n",
      " [0.86474155]\n",
      " [0.89131537]]\n",
      "Loss: \n",
      " 0.00010620302670072364\n",
      "\n",
      "\n",
      "Epoch: 951\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90285032]\n",
      " [0.86475176]\n",
      " [0.891324  ]]\n",
      "Loss: \n",
      " 0.000106147892875209\n",
      "\n",
      "\n",
      "Epoch: 952\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.9028586 ]\n",
      " [0.86476194]\n",
      " [0.89133259]]\n",
      "Loss: \n",
      " 0.00010609309740129572\n",
      "\n",
      "\n",
      "Epoch: 953\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90286686]\n",
      " [0.86477208]\n",
      " [0.89134116]]\n",
      "Loss: \n",
      " 0.0001060386380739573\n",
      "\n",
      "\n",
      "Epoch: 954\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90287509]\n",
      " [0.86478219]\n",
      " [0.8913497 ]]\n",
      "Loss: \n",
      " 0.00010598451270313489\n",
      "\n",
      "\n",
      "Epoch: 955\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.9028833 ]\n",
      " [0.86479227]\n",
      " [0.89135821]]\n",
      "Loss: \n",
      " 0.00010593071911363363\n",
      "\n",
      "\n",
      "Epoch: 956\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90289147]\n",
      " [0.86480232]\n",
      " [0.89136669]]\n",
      "Loss: \n",
      " 0.00010587725514500989\n",
      "\n",
      "\n",
      "Epoch: 957\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90289963]\n",
      " [0.86481233]\n",
      " [0.89137515]]\n",
      "Loss: \n",
      " 0.00010582411865147604\n",
      "\n",
      "\n",
      "Epoch: 958\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90290775]\n",
      " [0.86482231]\n",
      " [0.89138358]]\n",
      "Loss: \n",
      " 0.00010577130750178836\n",
      "\n",
      "\n",
      "Epoch: 959\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90291585]\n",
      " [0.86483226]\n",
      " [0.89139198]]\n",
      "Loss: \n",
      " 0.00010571881957914163\n",
      "\n",
      "\n",
      "Epoch: 960\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90292393]\n",
      " [0.86484218]\n",
      " [0.89140036]]\n",
      "Loss: \n",
      " 0.0001056666527810711\n",
      "\n",
      "\n",
      "Epoch: 961\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90293198]\n",
      " [0.86485206]\n",
      " [0.89140871]]\n",
      "Loss: \n",
      " 0.00010561480501934689\n",
      "\n",
      "\n",
      "Epoch: 962\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90294   ]\n",
      " [0.86486191]\n",
      " [0.89141703]]\n",
      "Loss: \n",
      " 0.00010556327421987171\n",
      "\n",
      "\n",
      "Epoch: 963\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.902948  ]\n",
      " [0.86487173]\n",
      " [0.89142532]]\n",
      "Loss: \n",
      " 0.00010551205832258591\n",
      "\n",
      "\n",
      "Epoch: 964\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90295597]\n",
      " [0.86488152]\n",
      " [0.89143359]]\n",
      "Loss: \n",
      " 0.00010546115528136383\n",
      "\n",
      "\n",
      "Epoch: 965\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90296391]\n",
      " [0.86489127]\n",
      " [0.89144183]]\n",
      "Loss: \n",
      " 0.00010541056306389802\n",
      "\n",
      "\n",
      "Epoch: 966\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90297183]\n",
      " [0.864901  ]\n",
      " [0.89145005]]\n",
      "Loss: \n",
      " 0.00010536027965163623\n",
      "\n",
      "\n",
      "Epoch: 967\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90297973]\n",
      " [0.86491069]\n",
      " [0.89145823]]\n",
      "Loss: \n",
      " 0.00010531030303965293\n",
      "\n",
      "\n",
      "Epoch: 968\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.9029876 ]\n",
      " [0.86492035]\n",
      " [0.89146639]]\n",
      "Loss: \n",
      " 0.00010526063123656185\n",
      "\n",
      "\n",
      "Epoch: 969\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90299545]\n",
      " [0.86492998]\n",
      " [0.89147453]]\n",
      "Loss: \n",
      " 0.00010521126226442329\n",
      "\n",
      "\n",
      "Epoch: 970\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90300327]\n",
      " [0.86493958]\n",
      " [0.89148264]]\n",
      "Loss: \n",
      " 0.00010516219415864608\n",
      "\n",
      "\n",
      "Epoch: 971\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90301106]\n",
      " [0.86494914]\n",
      " [0.89149072]]\n",
      "Loss: \n",
      " 0.00010511342496788993\n",
      "\n",
      "\n",
      "Epoch: 972\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90301883]\n",
      " [0.86495868]\n",
      " [0.89149878]]\n",
      "Loss: \n",
      " 0.00010506495275397437\n",
      "\n",
      "\n",
      "Epoch: 973\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90302658]\n",
      " [0.86496819]\n",
      " [0.89150681]]\n",
      "Loss: \n",
      " 0.00010501677559178196\n",
      "\n",
      "\n",
      "Epoch: 974\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.9030343 ]\n",
      " [0.86497766]\n",
      " [0.89151482]]\n",
      "Loss: \n",
      " 0.0001049688915691742\n",
      "\n",
      "\n",
      "Epoch: 975\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.903042 ]\n",
      " [0.8649871]\n",
      " [0.8915228]]\n",
      "Loss: \n",
      " 0.00010492129878688662\n",
      "\n",
      "\n",
      "Epoch: 976\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90304967]\n",
      " [0.86499651]\n",
      " [0.89153075]]\n",
      "Loss: \n",
      " 0.00010487399535844411\n",
      "\n",
      "\n",
      "Epoch: 977\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90305732]\n",
      " [0.8650059 ]\n",
      " [0.89153868]]\n",
      "Loss: \n",
      " 0.00010482697941007584\n",
      "\n",
      "\n",
      "Epoch: 978\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90306494]\n",
      " [0.86501525]\n",
      " [0.89154658]]\n",
      "Loss: \n",
      " 0.00010478024908061355\n",
      "\n",
      "\n",
      "Epoch: 979\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90307254]\n",
      " [0.86502457]\n",
      " [0.89155446]]\n",
      "Loss: \n",
      " 0.00010473380252141178\n",
      "\n",
      "\n",
      "Epoch: 980\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90308012]\n",
      " [0.86503386]\n",
      " [0.89156231]]\n",
      "Loss: \n",
      " 0.00010468763789625547\n",
      "\n",
      "\n",
      "Epoch: 981\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90308767]\n",
      " [0.86504312]\n",
      " [0.89157014]]\n",
      "Loss: \n",
      " 0.00010464175338126795\n",
      "\n",
      "\n",
      "Epoch: 982\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.9030952 ]\n",
      " [0.86505235]\n",
      " [0.89157794]]\n",
      "Loss: \n",
      " 0.0001045961471648293\n",
      "\n",
      "\n",
      "Epoch: 983\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.9031027 ]\n",
      " [0.86506155]\n",
      " [0.89158572]]\n",
      "Loss: \n",
      " 0.00010455081744749615\n",
      "\n",
      "\n",
      "Epoch: 984\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90311018]\n",
      " [0.86507072]\n",
      " [0.89159347]]\n",
      "Loss: \n",
      " 0.000104505762441898\n",
      "\n",
      "\n",
      "Epoch: 985\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90311764]\n",
      " [0.86507986]\n",
      " [0.8916012 ]]\n",
      "Loss: \n",
      " 0.00010446098037266262\n",
      "\n",
      "\n",
      "Epoch: 986\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90312507]\n",
      " [0.86508897]\n",
      " [0.8916089 ]]\n",
      "Loss: \n",
      " 0.00010441646947633636\n",
      "\n",
      "\n",
      "Epoch: 987\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90313248]\n",
      " [0.86509806]\n",
      " [0.89161658]]\n",
      "Loss: \n",
      " 0.0001043722280012904\n",
      "\n",
      "\n",
      "Epoch: 988\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90313987]\n",
      " [0.86510711]\n",
      " [0.89162423]]\n",
      "Loss: \n",
      " 0.00010432825420763818\n",
      "\n",
      "\n",
      "Epoch: 989\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90314723]\n",
      " [0.86511613]\n",
      " [0.89163186]]\n",
      "Loss: \n",
      " 0.00010428454636716252\n",
      "\n",
      "\n",
      "Epoch: 990\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90315457]\n",
      " [0.86512513]\n",
      " [0.89163946]]\n",
      "Loss: \n",
      " 0.00010424110276321956\n",
      "\n",
      "\n",
      "Epoch: 991\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90316188]\n",
      " [0.86513409]\n",
      " [0.89164704]]\n",
      "Loss: \n",
      " 0.00010419792169066915\n",
      "\n",
      "\n",
      "Epoch: 992\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90316918]\n",
      " [0.86514303]\n",
      " [0.8916546 ]]\n",
      "Loss: \n",
      " 0.00010415500145578609\n",
      "\n",
      "\n",
      "Epoch: 993\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90317645]\n",
      " [0.86515193]\n",
      " [0.89166213]]\n",
      "Loss: \n",
      " 0.00010411234037618212\n",
      "\n",
      "\n",
      "Epoch: 994\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90318369]\n",
      " [0.86516081]\n",
      " [0.89166963]]\n",
      "Loss: \n",
      " 0.00010406993678072653\n",
      "\n",
      "\n",
      "Epoch: 995\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90319092]\n",
      " [0.86516966]\n",
      " [0.89167712]]\n",
      "Loss: \n",
      " 0.00010402778900946873\n",
      "\n",
      "\n",
      "Epoch: 996\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90319812]\n",
      " [0.86517848]\n",
      " [0.89168458]]\n",
      "Loss: \n",
      " 0.00010398589541355732\n",
      "\n",
      "\n",
      "Epoch: 997\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.9032053 ]\n",
      " [0.86518727]\n",
      " [0.89169201]]\n",
      "Loss: \n",
      " 0.0001039442543551613\n",
      "\n",
      "\n",
      "Epoch: 998\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90321245]\n",
      " [0.86519604]\n",
      " [0.89169942]]\n",
      "Loss: \n",
      " 0.00010390286420739829\n",
      "\n",
      "\n",
      "Epoch: 999\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90321959]\n",
      " [0.86520477]\n",
      " [0.89170681]]\n",
      "Loss: \n",
      " 0.00010386172335424873\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "X = np.array(([2, 9], [1, 5], [3, 6]), dtype=float)\n",
    "print(np.amax(X, axis=0))\n",
    "y = np.array(([92], [86], [89]), dtype=float)\n",
    "X = X/np.amax(X, axis=0)\n",
    "y = y/100\n",
    "\n",
    "class Neural_Network(object):\n",
    "    def __init__(self):\n",
    "        self.inputSize = 2\n",
    "        self.outputSize = 1\n",
    "        self.hiddenSize = 3\n",
    "        self.W1 = np.random.randn(self.inputSize, self.hiddenSize)\n",
    "        self.W2 = np.random.randn(self.hiddenSize, self.outputSize)\n",
    "\n",
    "    def forward(self, X):\n",
    "        self.z = np.dot(X, self.W1)\n",
    "        self.z2 = self.sigmoid(self.z)\n",
    "        self.z3 = np.dot(self.z2, self.W2)\n",
    "        o = self.sigmoid(self.z3) \n",
    "        return o \n",
    "\n",
    "    def sigmoid(self, s):\n",
    "        return 1/(1+np.exp(-s))\n",
    "\n",
    "    def sigmoidPrime(self, s):\n",
    "        return s * (1 - s)\n",
    "    \n",
    "    def backward(self, X, y, o):\n",
    "        self.o_error = y - o\n",
    "        self.o_delta = self.o_error*self.sigmoidPrime(o)\n",
    "        self.z2_error = self.o_delta.dot(self.W2.T)\n",
    "        self.z2_delta = self.z2_error*self.sigmoidPrime(self.z2)\n",
    "        self.W1 += l_rate*X.T.dot(self.z2_delta)\n",
    "        self.W2 += l_rate*self.z2.T.dot(self.o_delta)\n",
    "\n",
    "    def train (self, X, y):\n",
    "        o = self.forward(X)\n",
    "        self.backward(X, y, o)\n",
    "\n",
    "NN = Neural_Network()\n",
    "l_rate = 0.1 \n",
    "for i in range(1000):\n",
    "    print(\"Epoch:\",i)\n",
    "    print(\"l_rate\",l_rate)\n",
    "    print (\"Input: \\n\",str(X))\n",
    "    print (\"Actual Output: \\n\",str(y))\n",
    "    print (\"Predicted Output: \\n\",str(NN.forward(X)) )\n",
    "    print (\"Loss: \\n\",str(np.mean(np.square(y - NN.forward(X)))))\n",
    "    print(\"\\n\")\n",
    "    NN.train(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5eb8be3-179c-4a13-be73-3734502cd50a",
   "metadata": {},
   "source": [
    "# Program 6 Source Code\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e9dd9f23-7123-41ff-89ab-6e3dc5b84c9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first 5 values of data is:\n",
      "     Outlook Temperature Humidity  Windy PlayTennis\n",
      "0     Sunny         Hot     High  False         No\n",
      "1     Sunny         Hot     High   True         No\n",
      "2  Overcast         Hot     High  False        Yes\n",
      "3     Rainy        Mild     High  False        Yes\n",
      "4     Rainy        Cool   Normal  False        Yes\n",
      "\n",
      "The First 5 values of train data is\n",
      "     Outlook Temperature Humidity  Windy\n",
      "0     Sunny         Hot     High  False\n",
      "1     Sunny         Hot     High   True\n",
      "2  Overcast         Hot     High  False\n",
      "3     Rainy        Mild     High  False\n",
      "4     Rainy        Cool   Normal  False\n",
      "\n",
      "The First 5 values of train output is\n",
      " 0     No\n",
      "1     No\n",
      "2    Yes\n",
      "3    Yes\n",
      "4    Yes\n",
      "Name: PlayTennis, dtype: object\n",
      "\n",
      "Now the train data is:\n",
      "    Outlook  Temperature  Humidity  Windy\n",
      "0        2            1         0      0\n",
      "1        2            1         0      1\n",
      "2        0            1         0      0\n",
      "3        1            2         0      0\n",
      "4        1            0         1      0\n",
      "\n",
      "Now the train output is\n",
      " [0 0 1 1 1 0 1 0 1 1 1 1 1 0]\n",
      "Accuracy is: 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "pro6.csv\n",
    "Outlook,Temperature,Humidity,Windy,PlayTennis\n",
    "Sunny,Hot,High,False,No\n",
    "Sunny,Hot,High,True,No\n",
    "Overcast,Hot,High,False,Yes\n",
    "Rainy,Mild,High,False,Yes\n",
    "Rainy,Cool,Normal,False,Yes\n",
    "Rainy,Cool,Normal,True,No\n",
    "Overcast,Cool,Normal,True,Yes\n",
    "Sunny,Mild,High,False,No\n",
    "Sunny,Cool,Normal,False,Yes\n",
    "Rainy,Mild,Normal,False,Yes\n",
    "Sunny,Mild,Normal,True,Yes\n",
    "Overcast,Mild,High,True,Yes\n",
    "Overcast,Hot,Normal,False,Yes\n",
    "Rainy,Mild,High,True,No\n",
    "\n",
    "'''\n",
    "import pandas as pd\n",
    "from sklearn import tree\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "data = pd.read_csv('pro6.csv') \n",
    "print(\"The first 5 values of data is:\\n\",data.head())\n",
    "\n",
    "X = data.iloc[:,:-1]\n",
    "print(\"\\nThe First 5 values of train data is\\n\",X.head())\n",
    "y = data.iloc[:,-1]\n",
    "print(\"\\nThe First 5 values of train output is\\n\",y.head())\n",
    "\n",
    "le_outlook = LabelEncoder()\n",
    "X.Outlook = le_outlook.fit_transform(X.Outlook) \n",
    "le_Temperature = LabelEncoder() \n",
    "X.Temperature = le_Temperature.fit_transform(X.Temperature)\n",
    "le_Humidity = LabelEncoder()\n",
    "X.Humidity = le_Humidity.fit_transform(X.Humidity)\n",
    "le_Windy = LabelEncoder()\n",
    "X.Windy = le_Windy.fit_transform(X.Windy)\n",
    "\n",
    "print(\"\\nNow the train data is:\\n\", X.head())\n",
    "le_PlayTennis = LabelEncoder()\n",
    "y = le_PlayTennis.fit_transform(y)\n",
    "print(\"\\nNow the train output is\\n\",y)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.20)\n",
    "classifier=GaussianNB()\n",
    "classifier.fit(X_train,y_train)\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Accuracy is:\",accuracy_score(classifier.predict(X_test),y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aeb90ef",
   "metadata": {},
   "source": [
    "# Program 7 Source Code ðŸ‘‡\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "619c2467",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\91966\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\91966\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'Petal_Length'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 22\u001b[0m\n\u001b[0;32m     19\u001b[0m colormap \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mred\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlime\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblack\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     21\u001b[0m plt\u001b[38;5;241m.\u001b[39msubplot(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 22\u001b[0m plt\u001b[38;5;241m.\u001b[39mscatter(\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPetal_Length\u001b[49m,X\u001b[38;5;241m.\u001b[39mPetal_Width,c\u001b[38;5;241m=\u001b[39mcolormap[y\u001b[38;5;241m.\u001b[39mTargets], s\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m40\u001b[39m)\n\u001b[0;32m     23\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReal Clusters\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     24\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPetal Length\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\91966\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:5989\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5982\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   5983\u001b[0m     name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_names_set\n\u001b[0;32m   5984\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata\n\u001b[0;32m   5985\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessors\n\u001b[0;32m   5986\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info_axis\u001b[38;5;241m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[0;32m   5987\u001b[0m ):\n\u001b[0;32m   5988\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[name]\n\u001b[1;32m-> 5989\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'Petal_Length'"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.cluster import KMeans\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = pd.DataFrame(iris.data)\n",
    "X_columns = ['Sepal_Length','Sepal_Width','Petal_Length','Petal_Width']\n",
    "y = pd.DataFrame(iris.target)\n",
    "y.columns = [\"Targets\"]\n",
    "\n",
    "#Build K Means Model\n",
    "model = KMeans(n_clusters=3)\n",
    "model.fit(X)\n",
    "\n",
    "#Visualise the clustering results\n",
    "plt.figure(figsize=(14,7))\n",
    "colormap = np.array(['red','lime','black'])\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.scatter(X.Petal_Length,X.Petal_Width,c=colormap[y.Targets], s=40)\n",
    "plt.title(\"Real Clusters\")\n",
    "plt.xlabel(\"Petal Length\")\n",
    "plt.ylabel(\"Petal Width\")\n",
    "\n",
    "#plot model classifications\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.scatter(X.Petal_Length, X.Petal_Width, c=colormap[model.labels_],s=40)\n",
    "plt.title(\"K_Means Clustering\")\n",
    "plt.xlabel(\"Petal Length\")\n",
    "plt.ylabel(\"Petal Width\")\n",
    "\n",
    "\n",
    "#General EM for GMM\n",
    "from sklearn import preprocessing\n",
    "\n",
    "#transform your data\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(X)\n",
    "xsa = scaler.transform(X)\n",
    "xs = pd.DataFrame(xsa, columns=X.columns)\n",
    "\n",
    "from sklearn.mixture import GaussianMixture\n",
    "gmm = GaussianMixture(n_components=40)\n",
    "gmm.fit(xs)\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.scatter(X.Petal_Length,X.Petal_Width,c=colormap[0], s=40)\n",
    "plt.title(\"GMM Clustering\")\n",
    "plt.xlabel(\"Petal Length\")\n",
    "plt.ylabel(\"Petal Width\")\n",
    "\n",
    "\n",
    "print(\"Done !! âœ…\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7358d802",
   "metadata": {},
   "source": [
    "# Program 8 Source Code ðŸ‘‡\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7363b625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iris Data set Loaded...\n",
      "Label 0 - setosa\n",
      "Label 1 - versicolor\n",
      "Label 2 - virginica\n",
      "Results of Classification using k-nn with k=1\n",
      "Sample [5.7 3.  4.2 1.2] Actual-label: 1 Predicted-label: 1\n",
      "Classification Accuracy : 1.0\n",
      "Sample [6.7 3.1 4.7 1.5] Actual-label: 1 Predicted-label: 1\n",
      "Classification Accuracy : 1.0\n",
      "Sample [4.8 3.  1.4 0.1] Actual-label: 0 Predicted-label: 0\n",
      "Classification Accuracy : 1.0\n",
      "Sample [7.7 2.6 6.9 2.3] Actual-label: 2 Predicted-label: 2\n",
      "Classification Accuracy : 1.0\n",
      "Sample [5.5 2.5 4.  1.3] Actual-label: 1 Predicted-label: 1\n",
      "Classification Accuracy : 1.0\n",
      "Sample [6.7 3.1 4.4 1.4] Actual-label: 1 Predicted-label: 1\n",
      "Classification Accuracy : 1.0\n",
      "Sample [4.6 3.2 1.4 0.2] Actual-label: 0 Predicted-label: 0\n",
      "Classification Accuracy : 1.0\n",
      "Sample [7.  3.2 4.7 1.4] Actual-label: 1 Predicted-label: 1\n",
      "Classification Accuracy : 1.0\n",
      "Sample [6.1 3.  4.6 1.4] Actual-label: 1 Predicted-label: 1\n",
      "Classification Accuracy : 1.0\n",
      "Sample [5.4 3.4 1.5 0.4] Actual-label: 0 Predicted-label: 0\n",
      "Classification Accuracy : 1.0\n",
      "Sample [6.4 3.2 4.5 1.5] Actual-label: 1 Predicted-label: 1\n",
      "Classification Accuracy : 1.0\n",
      "Sample [5.5 2.4 3.8 1.1] Actual-label: 1 Predicted-label: 1\n",
      "Classification Accuracy : 1.0\n",
      "Sample [5.8 2.7 5.1 1.9] Actual-label: 2 Predicted-label: 2\n",
      "Classification Accuracy : 1.0\n",
      "Sample [5.  3.  1.6 0.2] Actual-label: 0 Predicted-label: 0\n",
      "Classification Accuracy : 1.0\n",
      "Sample [5.6 2.7 4.2 1.3] Actual-label: 1 Predicted-label: 1\n",
      "Classification Accuracy : 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import datasets\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "print(\"Iris Data set Loaded...\")\n",
    "\n",
    "X_train, X_test, y_train,y_test = train_test_split(iris.data,iris.target,test_size=0.1)\n",
    "\n",
    "#random_state=0\n",
    "\n",
    "for i in range(len(iris.target_names)):\n",
    "    print(\"Label\", i, \"-\",str(iris.target_names[i]))\n",
    "\n",
    "classifier = KNeighborsClassifier(n_neighbors=2)\n",
    "classifier.fit(X_train,y_train)\n",
    "y_pred=classifier.predict(X_test)\n",
    "\n",
    "print(\"Results of Classification using k-nn with k=1\")\n",
    "\n",
    "for r in range(0,len(X_test)):\n",
    "    print(\"Sample\", str(X_test[r]), \"Actual-label:\", str(y_test[r]), \"Predicted-label:\", str(y_pred[r]))\n",
    "\n",
    "    print(\"Classification Accuracy :\", classifier.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689ec4f0",
   "metadata": {},
   "source": [
    "# Program 9 Source Code ðŸ‘‡\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cae28ac9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def local_regression(x0, X,Y,tau):\n",
    "    x0=[1,x0]\n",
    "    X=[[1,i] for i in X ]\n",
    "    X=np.asarray(X)\n",
    "    xw = (X.T) * np.exp(np.sum((X-x0)**2,axis=1)/(-2*tau)) \n",
    "    beta = np.linalg.pinv(xw @ X) @ xw @ Y @x0\n",
    "    return beta\n",
    "\n",
    "def draw(tau):\n",
    "    prediction=[local_regression(x0,X,Y,tau) for x0 in domain]\n",
    "    plt.plot(X,Y,'o',color=\"black\")\n",
    "    plt.plot(domain,prediction,color=\"red\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "X = np.linspace(-3,3,num=1000)\n",
    "domain = X\n",
    "Y = np.log(np.abs(X**2-1)+.5)\n",
    "\n",
    "draw(10)\n",
    "draw(0.1)\n",
    "draw(0.01)\n",
    "draw(0.001)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
