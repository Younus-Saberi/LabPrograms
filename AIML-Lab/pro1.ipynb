{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2052c1d-2847-46d6-adea-ee732388352a",
   "metadata": {},
   "source": [
    "# Program 1 Source Code ðŸ‘‡\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d2fb57d-a71d-405a-b71b-0faf1ef8b654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph-1\n",
      "Path\n",
      "A -> B -> D\n",
      "Cost\n",
      "0 -> 1 -> 6\n"
     ]
    }
   ],
   "source": [
    "from heuristicsearch.a_star_search import AStar\n",
    "\n",
    "print(\"Graph-1\")\n",
    "\n",
    "heuristic = {'A':1,'B':1,'C':11,'D':1}\n",
    "adjance_list = {'A':[('B',1),('C',3),('D',7),],'B':[('D',5 )],'C':[('D',12)]}\n",
    "\n",
    "graph=AStar(adjance_list,heuristic)\n",
    "graph.apply_a_star(start='A',stop='D')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deeb8580-f7b2-4100-9f3b-55753a9d90fd",
   "metadata": {},
   "source": [
    "# Program 2 Source Code ðŸ‘‡\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ac1577d-5ad0-48c3-90ca-571a17c8311a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph-1\n",
      "PROCESSING NODE : A\n",
      "-----------------------------------------------------------------------------------------\n",
      "11 ['D']\n",
      "\n",
      "PROCESSING NODE : D\n",
      "-----------------------------------------------------------------------------------------\n",
      "6 ['E', 'F']\n",
      "\n",
      "PROCESSING NODE : A\n",
      "-----------------------------------------------------------------------------------------\n",
      "7 ['D']\n",
      "\n",
      "PROCESSING NODE : E\n",
      "-----------------------------------------------------------------------------------------\n",
      "0 []\n",
      "\n",
      "PROCESSING NODE : D\n",
      "-----------------------------------------------------------------------------------------\n",
      "2 ['E', 'F']\n",
      "\n",
      "PROCESSING NODE : A\n",
      "-----------------------------------------------------------------------------------------\n",
      "3 ['D']\n",
      "\n",
      "PROCESSING NODE : F\n",
      "-----------------------------------------------------------------------------------------\n",
      "0 []\n",
      "\n",
      "PROCESSING NODE : D\n",
      "-----------------------------------------------------------------------------------------\n",
      "2 ['E', 'F']\n",
      "\n",
      "PROCESSING NODE : A\n",
      "-----------------------------------------------------------------------------------------\n",
      "3 ['D']\n",
      "\n",
      "FOR THE SOLUTION, TRAVERSE THE GRAPH FROM THE START NODE: A\n",
      "------------------------------------------------------------\n",
      "{'E': [], 'F': [], 'D': ['E', 'F'], 'A': ['D']}\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from heuristicsearch.ao_star import AOStar\n",
    "print(\"Graph-1\")\n",
    "heuristic={'A':1,'B':6,'C':12,'D':10,'E':4,'G':5,'H':7}\n",
    "adjancency_list = {'A':[[('B',1),('C',1)],[('D',1)]],\n",
    "                   'B':[[('G',1)],[('H',1)]],\n",
    "                   'C':[[('J',1)]],\n",
    "                   'D':[[('E',1),('F',1)]],\n",
    "                   'G':[[('I',1)]]\n",
    "                  }\n",
    "graph=AOStar(adjancency_list, heuristic, 'A')\n",
    "graph.applyAOStar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3adbca7-d00a-40d9-b552-8da65dce052b",
   "metadata": {},
   "source": [
    "# Program 3 Source CodeðŸ‘‡\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74a3d429-5889-4a1a-b1c9-33fea01bf7bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Steps for candidate elimination algorithm 1\n",
      "['Sunny', 'Warm', '?', 'Strong', 'Warm', 'Same']\n",
      "[['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?']]\n",
      "\n",
      " Steps for candidate elimination algorithm 2\n",
      "['Sunny', 'Warm', '?', 'Strong', 'Warm', 'Same']\n",
      "[['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?']]\n",
      "\n",
      " Steps for candidate elimination algorithm 3\n",
      "['Sunny', 'Warm', '?', 'Strong', 'Warm', 'Same']\n",
      "[['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?']]\n",
      "\n",
      " Steps for candidate elimination algorithm 4\n",
      "['?', 'Warm', '?', 'Strong', '?', '?']\n",
      "[['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?']]\n",
      "\n",
      " Final Specific Hypothesis:\n",
      " ['?', 'Warm', '?', 'Strong', '?', '?']\n",
      "\n",
      " Final General Hypothesis:\n",
      " []\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Copy the CSV File Format as given below\n",
    "\n",
    "Sunny,Warm,Normal,Strong,Warm,Same,Yes\n",
    "Sunny,Warm,High,Strong,Warm,Same,Yes\n",
    "Rainy,Cold,High,Strong,Warm,Change,No \n",
    "Rainy,Warm,High,Strong,Cool,Change,Yes\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "import csv\n",
    "\n",
    "with open('pro3.csv') as f:\n",
    "    csv_file=csv.reader(f)\n",
    "    data=list(csv_file)\n",
    "\n",
    "    s=data[1][:-1]\n",
    "    g=[['?' for i in range(len(s))] for j in range(len(s))] \n",
    "\n",
    "    for i in data:\n",
    "        if i[-1]==\"Yes\":\n",
    "            for j in range(len(s)):\n",
    "                if i[j]!=s[j]:\n",
    "                    s[j]='?'\n",
    "                    g[j][j]='?'\n",
    "        elif i[-1]==\"No\":\n",
    "            for j in range(len(s)):\n",
    "                if i[j]!=s[j]:\n",
    "                    g[j][j]=s[j]\n",
    "                else:\n",
    "                    g[j][j]=\"?\"\n",
    "        print(\"\\n Steps for candidate elimination algorithm\",data.index(i)+1)\n",
    "        print(s)\n",
    "        print(g)\n",
    "\n",
    "    gh=[]\n",
    "\n",
    "    for i in g:\n",
    "        for j in i:\n",
    "            if j!=\"?\":\n",
    "                gh.append(i)\n",
    "                break\n",
    "\n",
    "    print(\"\\n Final Specific Hypothesis:\\n\",s)\n",
    "    print(\"\\n Final General Hypothesis:\\n\", gh)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba1bc87-6032-47ba-a9d2-f6396da28418",
   "metadata": {},
   "source": [
    "# Program 4 Source CodeðŸ‘‡\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20246fe6-4b68-4f84-8921-e6005d843b99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "X= [[0,0],[1,1]]\n",
    "Y= [0,1]\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(X,Y)\n",
    "clf.predict([[2.,2.]])\n",
    "clf.predict_proba([[2.,2.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12908f39-d659-45f8-b9e7-c373025bc813",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(0.5, 0.9166666666666666, 'x[3] <= 0.8\\ngini = 0.667\\nsamples = 150\\nvalue = [50, 50, 50]'),\n",
       " Text(0.4230769230769231, 0.75, 'gini = 0.0\\nsamples = 50\\nvalue = [50, 0, 0]'),\n",
       " Text(0.5769230769230769, 0.75, 'x[3] <= 1.75\\ngini = 0.5\\nsamples = 100\\nvalue = [0, 50, 50]'),\n",
       " Text(0.3076923076923077, 0.5833333333333334, 'x[2] <= 4.95\\ngini = 0.168\\nsamples = 54\\nvalue = [0, 49, 5]'),\n",
       " Text(0.15384615384615385, 0.4166666666666667, 'x[3] <= 1.65\\ngini = 0.041\\nsamples = 48\\nvalue = [0, 47, 1]'),\n",
       " Text(0.07692307692307693, 0.25, 'gini = 0.0\\nsamples = 47\\nvalue = [0, 47, 0]'),\n",
       " Text(0.23076923076923078, 0.25, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(0.46153846153846156, 0.4166666666666667, 'x[3] <= 1.55\\ngini = 0.444\\nsamples = 6\\nvalue = [0, 2, 4]'),\n",
       " Text(0.38461538461538464, 0.25, 'gini = 0.0\\nsamples = 3\\nvalue = [0, 0, 3]'),\n",
       " Text(0.5384615384615384, 0.25, 'x[2] <= 5.45\\ngini = 0.444\\nsamples = 3\\nvalue = [0, 2, 1]'),\n",
       " Text(0.46153846153846156, 0.08333333333333333, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 2, 0]'),\n",
       " Text(0.6153846153846154, 0.08333333333333333, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(0.8461538461538461, 0.5833333333333334, 'x[2] <= 4.85\\ngini = 0.043\\nsamples = 46\\nvalue = [0, 1, 45]'),\n",
       " Text(0.7692307692307693, 0.4166666666666667, 'x[0] <= 5.95\\ngini = 0.444\\nsamples = 3\\nvalue = [0, 1, 2]'),\n",
       " Text(0.6923076923076923, 0.25, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1, 0]'),\n",
       " Text(0.8461538461538461, 0.25, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 0, 2]'),\n",
       " Text(0.9230769230769231, 0.4166666666666667, 'gini = 0.0\\nsamples = 43\\nvalue = [0, 0, 43]')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn import tree\n",
    "iris= load_iris()\n",
    "X,y = iris.data,iris.target\n",
    "clf=tree.DecisionTreeClassifier()\n",
    "clf=clf.fit(X,y)\n",
    "tree.plot_tree(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65094142-a355-4481-9fe8-36f106cf0a45",
   "metadata": {},
   "source": [
    "# Program 5 Source CodeðŸ‘‡\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e41c50e2-6634-47d8-8df6-d8660230de6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3. 9.]\n",
      "Epoch: 0\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.30762436]\n",
      " [0.32156977]\n",
      " [0.27260458]]\n",
      "Loss: \n",
      " 0.348696045811852\n",
      "\n",
      "\n",
      "Epoch: 1\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.31665617]\n",
      " [0.32981612]\n",
      " [0.2820617 ]]\n",
      "Loss: \n",
      " 0.3382358993088525\n",
      "\n",
      "\n",
      "Epoch: 2\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.32578676]\n",
      " [0.33814536]\n",
      " [0.2916854 ]]\n",
      "Loss: \n",
      " 0.3278006681880984\n",
      "\n",
      "\n",
      "Epoch: 3\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.3349999 ]\n",
      " [0.34654364]\n",
      " [0.30145835]]\n",
      "Loss: \n",
      " 0.31741460864419874\n",
      "\n",
      "\n",
      "Epoch: 4\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.34427884]\n",
      " [0.35499661]\n",
      " [0.31136204]]\n",
      "Loss: \n",
      " 0.30710172003435005\n",
      "\n",
      "\n",
      "Epoch: 5\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.35360645]\n",
      " [0.3634896 ]\n",
      " [0.32137698]]\n",
      "Loss: \n",
      " 0.29688545911052405\n",
      "\n",
      "\n",
      "Epoch: 6\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.36296537]\n",
      " [0.3720077 ]\n",
      " [0.33148292]]\n",
      "Loss: \n",
      " 0.2867884648729973\n",
      "\n",
      "\n",
      "Epoch: 7\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.37233825]\n",
      " [0.38053598]\n",
      " [0.34165908]]\n",
      "Loss: \n",
      " 0.27683230162398204\n",
      "\n",
      "\n",
      "Epoch: 8\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.38170789]\n",
      " [0.3890596 ]\n",
      " [0.35188438]]\n",
      "Loss: \n",
      " 0.2670372270325439\n",
      "\n",
      "\n",
      "Epoch: 9\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.39105741]\n",
      " [0.39756397]\n",
      " [0.36213768]]\n",
      "Loss: \n",
      " 0.2574219909310594\n",
      "\n",
      "\n",
      "Epoch: 10\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.40037043]\n",
      " [0.40603491]\n",
      " [0.37239802]]\n",
      "Loss: \n",
      " 0.24800366922529138\n",
      "\n",
      "\n",
      "Epoch: 11\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.40963121]\n",
      " [0.41445871]\n",
      " [0.38264483]]\n",
      "Loss: \n",
      " 0.2387975358070614\n",
      "\n",
      "\n",
      "Epoch: 12\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.41882478]\n",
      " [0.42282232]\n",
      " [0.39285817]]\n",
      "Loss: \n",
      " 0.229816973809849\n",
      "\n",
      "\n",
      "Epoch: 13\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.42793703]\n",
      " [0.43111342]\n",
      " [0.40301888]]\n",
      "Loss: \n",
      " 0.22107342604038183\n",
      "\n",
      "\n",
      "Epoch: 14\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.43695482]\n",
      " [0.43932048]\n",
      " [0.41310877]]\n",
      "Loss: \n",
      " 0.21257638303954673\n",
      "\n",
      "\n",
      "Epoch: 15\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.44586606]\n",
      " [0.44743286]\n",
      " [0.42311074]]\n",
      "Loss: \n",
      " 0.20433340604246922\n",
      "\n",
      "\n",
      "Epoch: 16\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.45465973]\n",
      " [0.45544082]\n",
      " [0.43300892]]\n",
      "Loss: \n",
      " 0.19635018116771072\n",
      "\n",
      "\n",
      "Epoch: 17\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.46332593]\n",
      " [0.46333558]\n",
      " [0.44278871]]\n",
      "Loss: \n",
      " 0.18863060049376534\n",
      "\n",
      "\n",
      "Epoch: 18\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.47185586]\n",
      " [0.47110934]\n",
      " [0.45243688]]\n",
      "Loss: \n",
      " 0.18117686528025542\n",
      "\n",
      "\n",
      "Epoch: 19\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.48024187]\n",
      " [0.47875522]\n",
      " [0.46194157]]\n",
      "Loss: \n",
      " 0.1739896064456207\n",
      "\n",
      "\n",
      "Epoch: 20\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.48847735]\n",
      " [0.48626732]\n",
      " [0.4712923 ]]\n",
      "Loss: \n",
      " 0.16706801749252212\n",
      "\n",
      "\n",
      "Epoch: 21\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.4965568 ]\n",
      " [0.49364063]\n",
      " [0.48047997]]\n",
      "Loss: \n",
      " 0.16040999533697362\n",
      "\n",
      "\n",
      "Epoch: 22\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.50447569]\n",
      " [0.50087106]\n",
      " [0.4894968 ]]\n",
      "Loss: \n",
      " 0.15401228490304042\n",
      "\n",
      "\n",
      "Epoch: 23\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.51223047]\n",
      " [0.50795533]\n",
      " [0.49833633]]\n",
      "Loss: \n",
      " 0.14787062384698088\n",
      "\n",
      "\n",
      "Epoch: 24\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.51981848]\n",
      " [0.51489095]\n",
      " [0.50699329]]\n",
      "Loss: \n",
      " 0.14197988433106148\n",
      "\n",
      "\n",
      "Epoch: 25\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.52723787]\n",
      " [0.52167618]\n",
      " [0.51546358]]\n",
      "Loss: \n",
      " 0.1363342093413014\n",
      "\n",
      "\n",
      "Epoch: 26\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.5344876 ]\n",
      " [0.52830995]\n",
      " [0.52374418]]\n",
      "Loss: \n",
      " 0.13092714160511607\n",
      "\n",
      "\n",
      "Epoch: 27\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.54156729]\n",
      " [0.53479182]\n",
      " [0.53183307]]\n",
      "Loss: \n",
      " 0.12575174369139538\n",
      "\n",
      "\n",
      "Epoch: 28\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.5484772 ]\n",
      " [0.5411219 ]\n",
      " [0.53972911]]\n",
      "Loss: \n",
      " 0.12080070835110701\n",
      "\n",
      "\n",
      "Epoch: 29\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.55521817]\n",
      " [0.54730082]\n",
      " [0.54743203]]\n",
      "Loss: \n",
      " 0.11606645857150288\n",
      "\n",
      "\n",
      "Epoch: 30\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.56179151]\n",
      " [0.55332964]\n",
      " [0.55494227]]\n",
      "Loss: \n",
      " 0.11154123716721194\n",
      "\n",
      "\n",
      "Epoch: 31\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.56819901]\n",
      " [0.55920985]\n",
      " [0.56226092]]\n",
      "Loss: \n",
      " 0.10721718601694831\n",
      "\n",
      "\n",
      "Epoch: 32\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.57444279]\n",
      " [0.56494324]\n",
      " [0.56938969]]\n",
      "Loss: \n",
      " 0.10308641527843841\n",
      "\n",
      "\n",
      "Epoch: 33\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.58052534]\n",
      " [0.57053195]\n",
      " [0.57633076]]\n",
      "Loss: \n",
      " 0.09914106308179745\n",
      "\n",
      "\n",
      "Epoch: 34\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.58644941]\n",
      " [0.57597832]\n",
      " [0.58308677]]\n",
      "Loss: \n",
      " 0.09537334631957144\n",
      "\n",
      "\n",
      "Epoch: 35\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.59221798]\n",
      " [0.58128496]\n",
      " [0.58966072]]\n",
      "Loss: \n",
      " 0.09177560322718414\n",
      "\n",
      "\n",
      "Epoch: 36\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.59783423]\n",
      " [0.58645461]\n",
      " [0.59605592]]\n",
      "Loss: \n",
      " 0.08834032848782175\n",
      "\n",
      "\n",
      "Epoch: 37\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.60330149]\n",
      " [0.59149018]\n",
      " [0.60227595]]\n",
      "Loss: \n",
      " 0.08506020160771509\n",
      "\n",
      "\n",
      "Epoch: 38\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.60862319]\n",
      " [0.59639467]\n",
      " [0.60832459]]\n",
      "Loss: \n",
      " 0.08192810929764692\n",
      "\n",
      "\n",
      "Epoch: 39\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.61380286]\n",
      " [0.60117119]\n",
      " [0.61420579]]\n",
      "Loss: \n",
      " 0.07893716256985706\n",
      "\n",
      "\n",
      "Epoch: 40\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.6188441 ]\n",
      " [0.60582289]\n",
      " [0.61992363]]\n",
      "Loss: \n",
      " 0.07608070922111998\n",
      "\n",
      "\n",
      "Epoch: 41\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.62375054]\n",
      " [0.61035296]\n",
      " [0.62548225]]\n",
      "Loss: \n",
      " 0.07335234232658559\n",
      "\n",
      "\n",
      "Epoch: 42\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.62852581]\n",
      " [0.61476462]\n",
      " [0.63088589]]\n",
      "Loss: \n",
      " 0.07074590531824347\n",
      "\n",
      "\n",
      "Epoch: 43\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.63317356]\n",
      " [0.61906108]\n",
      " [0.6361388 ]]\n",
      "Loss: \n",
      " 0.06825549416913866\n",
      "\n",
      "\n",
      "Epoch: 44\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.6376974 ]\n",
      " [0.62324555]\n",
      " [0.64124522]]\n",
      "Loss: \n",
      " 0.06587545715168971\n",
      "\n",
      "\n",
      "Epoch: 45\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.64210092]\n",
      " [0.6273212 ]\n",
      " [0.6462094 ]]\n",
      "Loss: \n",
      " 0.06360039258708992\n",
      "\n",
      "\n",
      "Epoch: 46\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.64638767]\n",
      " [0.63129118]\n",
      " [0.65103556]]\n",
      "Loss: \n",
      " 0.06142514495383091\n",
      "\n",
      "\n",
      "Epoch: 47\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.65056113]\n",
      " [0.6351586 ]\n",
      " [0.65572785]]\n",
      "Loss: \n",
      " 0.059344799677562426\n",
      "\n",
      "\n",
      "Epoch: 48\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.65462475]\n",
      " [0.63892649]\n",
      " [0.66029038]]\n",
      "Loss: \n",
      " 0.057354676882196455\n",
      "\n",
      "\n",
      "Epoch: 49\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.65858187]\n",
      " [0.64259786]\n",
      " [0.66472718]]\n",
      "Loss: \n",
      " 0.055450324343579084\n",
      "\n",
      "\n",
      "Epoch: 50\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.66243579]\n",
      " [0.64617562]\n",
      " [0.66904221]]\n",
      "Loss: \n",
      " 0.05362750985222376\n",
      "\n",
      "\n",
      "Epoch: 51\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.66618972]\n",
      " [0.64966265]\n",
      " [0.67323935]]\n",
      "Loss: \n",
      " 0.0518822131604443\n",
      "\n",
      "\n",
      "Epoch: 52\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.66984679]\n",
      " [0.65306174]\n",
      " [0.67732236]]\n",
      "Loss: \n",
      " 0.050210617661588325\n",
      "\n",
      "\n",
      "Epoch: 53\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.67341004]\n",
      " [0.6563756 ]\n",
      " [0.68129494]]\n",
      "Loss: \n",
      " 0.04860910192472775\n",
      "\n",
      "\n",
      "Epoch: 54\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.67688245]\n",
      " [0.65960689]\n",
      " [0.68516066]]\n",
      "Loss: \n",
      " 0.047074231186874434\n",
      "\n",
      "\n",
      "Epoch: 55\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.68026689]\n",
      " [0.66275819]\n",
      " [0.68892302]]\n",
      "Loss: \n",
      " 0.045602748886282525\n",
      "\n",
      "\n",
      "Epoch: 56\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.68356615]\n",
      " [0.66583199]\n",
      " [0.6925854 ]]\n",
      "Loss: \n",
      " 0.04419156830441703\n",
      "\n",
      "\n",
      "Epoch: 57\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.68678294]\n",
      " [0.66883072]\n",
      " [0.69615108]]\n",
      "Loss: \n",
      " 0.042837764370440345\n",
      "\n",
      "\n",
      "Epoch: 58\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.68991989]\n",
      " [0.67175672]\n",
      " [0.69962324]]\n",
      "Loss: \n",
      " 0.04153856567035181\n",
      "\n",
      "\n",
      "Epoch: 59\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.69297954]\n",
      " [0.67461229]\n",
      " [0.70300495]]\n",
      "Loss: \n",
      " 0.040291346692969736\n",
      "\n",
      "\n",
      "Epoch: 60\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.69596434]\n",
      " [0.67739961]\n",
      " [0.7062992 ]]\n",
      "Loss: \n",
      " 0.0390936203365576\n",
      "\n",
      "\n",
      "Epoch: 61\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.69887667]\n",
      " [0.68012083]\n",
      " [0.70950886]]\n",
      "Loss: \n",
      " 0.037943030692864525\n",
      "\n",
      "\n",
      "Epoch: 62\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.70171883]\n",
      " [0.68277801]\n",
      " [0.71263672]]\n",
      "Loss: \n",
      " 0.03683734611949897\n",
      "\n",
      "\n",
      "Epoch: 63\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.70449303]\n",
      " [0.68537314]\n",
      " [0.71568545]]\n",
      "Loss: \n",
      " 0.03577445260671971\n",
      "\n",
      "\n",
      "Epoch: 64\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.70720142]\n",
      " [0.68790815]\n",
      " [0.71865765]]\n",
      "Loss: \n",
      " 0.03475234744076962\n",
      "\n",
      "\n",
      "Epoch: 65\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.70984607]\n",
      " [0.69038489]\n",
      " [0.72155583]]\n",
      "Loss: \n",
      " 0.033769133162666574\n",
      "\n",
      "\n",
      "Epoch: 66\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.71242897]\n",
      " [0.69280518]\n",
      " [0.72438239]]\n",
      "Loss: \n",
      " 0.032823011818793345\n",
      "\n",
      "\n",
      "Epoch: 67\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.71495205]\n",
      " [0.69517073]\n",
      " [0.72713966]]\n",
      "Loss: \n",
      " 0.03191227949759529\n",
      "\n",
      "\n",
      "Epoch: 68\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.71741718]\n",
      " [0.69748324]\n",
      " [0.72982988]]\n",
      "Loss: \n",
      " 0.031035321145118464\n",
      "\n",
      "\n",
      "Epoch: 69\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.71982614]\n",
      " [0.69974432]\n",
      " [0.73245521]]\n",
      "Loss: \n",
      " 0.03019060565092663\n",
      "\n",
      "\n",
      "Epoch: 70\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.72218067]\n",
      " [0.70195552]\n",
      " [0.73501775]]\n",
      "Loss: \n",
      " 0.029376681195062412\n",
      "\n",
      "\n",
      "Epoch: 71\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.72448244]\n",
      " [0.70411835]\n",
      " [0.73751948]]\n",
      "Loss: \n",
      " 0.02859217084610768\n",
      "\n",
      "\n",
      "Epoch: 72\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.72673305]\n",
      " [0.70623427]\n",
      " [0.73996236]]\n",
      "Loss: \n",
      " 0.027835768400010643\n",
      "\n",
      "\n",
      "Epoch: 73\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.72893407]\n",
      " [0.70830468]\n",
      " [0.74234824]]\n",
      "Loss: \n",
      " 0.027106234449135087\n",
      "\n",
      "\n",
      "Epoch: 74\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.73108698]\n",
      " [0.71033094]\n",
      " [0.74467891]]\n",
      "Loss: \n",
      " 0.026402392670923935\n",
      "\n",
      "\n",
      "Epoch: 75\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.73319323]\n",
      " [0.71231434]\n",
      " [0.74695611]]\n",
      "Loss: \n",
      " 0.02572312632562059\n",
      "\n",
      "\n",
      "Epoch: 76\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.73525421]\n",
      " [0.71425615]\n",
      " [0.74918151]]\n",
      "Loss: \n",
      " 0.02506737495263894\n",
      "\n",
      "\n",
      "Epoch: 77\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.73727127]\n",
      " [0.71615758]\n",
      " [0.7513567 ]]\n",
      "Loss: \n",
      " 0.02443413125538964\n",
      "\n",
      "\n",
      "Epoch: 78\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.73924571]\n",
      " [0.71801981]\n",
      " [0.75348323]]\n",
      "Loss: \n",
      " 0.023822438164646142\n",
      "\n",
      "\n",
      "Epoch: 79\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.74117877]\n",
      " [0.71984397]\n",
      " [0.7555626 ]]\n",
      "Loss: \n",
      " 0.023231386070849593\n",
      "\n",
      "\n",
      "Epoch: 80\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.74307167]\n",
      " [0.72163114]\n",
      " [0.75759624]]\n",
      "Loss: \n",
      " 0.022660110216098598\n",
      "\n",
      "\n",
      "Epoch: 81\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.74492555]\n",
      " [0.7233824 ]\n",
      " [0.75958553]]\n",
      "Loss: \n",
      " 0.022107788236936782\n",
      "\n",
      "\n",
      "Epoch: 82\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.74674155]\n",
      " [0.72509875]\n",
      " [0.76153181]]\n",
      "Loss: \n",
      " 0.021573637849430824\n",
      "\n",
      "\n",
      "Epoch: 83\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.74852075]\n",
      " [0.72678117]\n",
      " [0.76343636]]\n",
      "Loss: \n",
      " 0.021056914668417442\n",
      "\n",
      "\n",
      "Epoch: 84\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.7502642 ]\n",
      " [0.72843062]\n",
      " [0.76530042]]\n",
      "Loss: \n",
      " 0.02055691015318511\n",
      "\n",
      "\n",
      "Epoch: 85\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.7519729 ]\n",
      " [0.730048  ]\n",
      " [0.76712518]]\n",
      "Loss: \n",
      " 0.0200729496722397\n",
      "\n",
      "\n",
      "Epoch: 86\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.75364783]\n",
      " [0.73163422]\n",
      " [0.76891179]]\n",
      "Loss: \n",
      " 0.019604390680180966\n",
      "\n",
      "\n",
      "Epoch: 87\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.75528993]\n",
      " [0.73319011]\n",
      " [0.77066137]]\n",
      "Loss: \n",
      " 0.019150621000085875\n",
      "\n",
      "\n",
      "Epoch: 88\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.75690011]\n",
      " [0.73471651]\n",
      " [0.77237498]]\n",
      "Loss: \n",
      " 0.018711057205152\n",
      "\n",
      "\n",
      "Epoch: 89\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.75847924]\n",
      " [0.73621421]\n",
      " [0.77405366]]\n",
      "Loss: \n",
      " 0.018285143093700034\n",
      "\n",
      "\n",
      "Epoch: 90\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.76002818]\n",
      " [0.73768398]\n",
      " [0.77569841]]\n",
      "Loss: \n",
      " 0.017872348251967856\n",
      "\n",
      "\n",
      "Epoch: 91\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.76154774]\n",
      " [0.73912658]\n",
      " [0.77731018]]\n",
      "Loss: \n",
      " 0.017472166699446064\n",
      "\n",
      "\n",
      "Epoch: 92\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.7630387 ]\n",
      " [0.74054271]\n",
      " [0.7788899 ]]\n",
      "Loss: \n",
      " 0.017084115611810165\n",
      "\n",
      "\n",
      "Epoch: 93\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.76450185]\n",
      " [0.74193308]\n",
      " [0.78043847]]\n",
      "Loss: \n",
      " 0.016707734116794926\n",
      "\n",
      "\n",
      "Epoch: 94\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.76593791]\n",
      " [0.74329835]\n",
      " [0.78195675]]\n",
      "Loss: \n",
      " 0.016342582158631488\n",
      "\n",
      "\n",
      "Epoch: 95\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.7673476 ]\n",
      " [0.74463918]\n",
      " [0.78344558]]\n",
      "Loss: \n",
      " 0.01598823942693036\n",
      "\n",
      "\n",
      "Epoch: 96\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.7687316 ]\n",
      " [0.74595621]\n",
      " [0.78490576]]\n",
      "Loss: \n",
      " 0.015644304346140957\n",
      "\n",
      "\n",
      "Epoch: 97\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.7700906 ]\n",
      " [0.74725002]\n",
      " [0.78633808]]\n",
      "Loss: \n",
      " 0.015310393121952343\n",
      "\n",
      "\n",
      "Epoch: 98\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.77142523]\n",
      " [0.74852123]\n",
      " [0.78774327]]\n",
      "Loss: \n",
      " 0.014986138841221781\n",
      "\n",
      "\n",
      "Epoch: 99\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.77273612]\n",
      " [0.74977039]\n",
      " [0.78912208]]\n",
      "Loss: \n",
      " 0.014671190622226127\n",
      "\n",
      "\n",
      "Epoch: 100\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.77402387]\n",
      " [0.75099806]\n",
      " [0.79047519]]\n",
      "Loss: \n",
      " 0.014365212812227517\n",
      "\n",
      "\n",
      "Epoch: 101\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.77528908]\n",
      " [0.75220478]\n",
      " [0.7918033 ]]\n",
      "Loss: \n",
      " 0.014067884229529906\n",
      "\n",
      "\n",
      "Epoch: 102\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.77653229]\n",
      " [0.75339106]\n",
      " [0.79310706]]\n",
      "Loss: \n",
      " 0.013778897447378056\n",
      "\n",
      "\n",
      "Epoch: 103\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.77775407]\n",
      " [0.7545574 ]\n",
      " [0.79438709]]\n",
      "Loss: \n",
      " 0.01349795811721212\n",
      "\n",
      "\n",
      "Epoch: 104\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.77895495]\n",
      " [0.75570429]\n",
      " [0.79564403]]\n",
      "Loss: \n",
      " 0.013224784328947269\n",
      "\n",
      "\n",
      "Epoch: 105\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.78013543]\n",
      " [0.75683219]\n",
      " [0.79687845]]\n",
      "Loss: \n",
      " 0.012959106006089363\n",
      "\n",
      "\n",
      "Epoch: 106\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.78129602]\n",
      " [0.75794157]\n",
      " [0.79809093]]\n",
      "Loss: \n",
      " 0.012700664333635264\n",
      "\n",
      "\n",
      "Epoch: 107\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.7824372 ]\n",
      " [0.75903287]\n",
      " [0.79928203]]\n",
      "Loss: \n",
      " 0.012449211216831945\n",
      "\n",
      "\n",
      "Epoch: 108\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.78355944]\n",
      " [0.76010652]\n",
      " [0.80045229]]\n",
      "Loss: \n",
      " 0.012204508768987992\n",
      "\n",
      "\n",
      "Epoch: 109\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.78466319]\n",
      " [0.76116292]\n",
      " [0.80160223]]\n",
      "Loss: \n",
      " 0.011966328826642858\n",
      "\n",
      "\n",
      "Epoch: 110\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.78574889]\n",
      " [0.76220249]\n",
      " [0.80273234]]\n",
      "Loss: \n",
      " 0.011734452490503623\n",
      "\n",
      "\n",
      "Epoch: 111\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.78681697]\n",
      " [0.76322561]\n",
      " [0.80384313]]\n",
      "Loss: \n",
      " 0.011508669690656713\n",
      "\n",
      "\n",
      "Epoch: 112\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.78786783]\n",
      " [0.76423266]\n",
      " [0.80493507]]\n",
      "Loss: \n",
      " 0.011288778774654298\n",
      "\n",
      "\n",
      "Epoch: 113\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.78890189]\n",
      " [0.76522401]\n",
      " [0.8060086 ]]\n",
      "Loss: \n",
      " 0.011074586117160763\n",
      "\n",
      "\n",
      "Epoch: 114\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.78991952]\n",
      " [0.76620002]\n",
      " [0.80706418]]\n",
      "Loss: \n",
      " 0.010865905749924938\n",
      "\n",
      "\n",
      "Epoch: 115\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.79092111]\n",
      " [0.76716104]\n",
      " [0.80810223]]\n",
      "Loss: \n",
      " 0.010662559010919836\n",
      "\n",
      "\n",
      "Epoch: 116\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.79190702]\n",
      " [0.76810739]\n",
      " [0.80912318]]\n",
      "Loss: \n",
      " 0.010464374211561591\n",
      "\n",
      "\n",
      "Epoch: 117\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.79287761]\n",
      " [0.76903941]\n",
      " [0.81012743]]\n",
      "Loss: \n",
      " 0.010271186320985462\n",
      "\n",
      "\n",
      "Epoch: 118\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.79383322]\n",
      " [0.76995741]\n",
      " [0.81111537]]\n",
      "Loss: \n",
      " 0.010082836666419572\n",
      "\n",
      "\n",
      "Epoch: 119\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.79477419]\n",
      " [0.7708617 ]\n",
      " [0.81208737]]\n",
      "Loss: \n",
      " 0.009899172648753713\n",
      "\n",
      "\n",
      "Epoch: 120\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.79570084]\n",
      " [0.77175258]\n",
      " [0.81304382]]\n",
      "Loss: \n",
      " 0.009720047472456042\n",
      "\n",
      "\n",
      "Epoch: 121\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.79661349]\n",
      " [0.77263034]\n",
      " [0.81398506]]\n",
      "Loss: \n",
      " 0.00954531988904058\n",
      "\n",
      "\n",
      "Epoch: 122\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.79751244]\n",
      " [0.77349527]\n",
      " [0.81491145]]\n",
      "Loss: \n",
      " 0.009374853953336792\n",
      "\n",
      "\n",
      "Epoch: 123\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.79839799]\n",
      " [0.77434763]\n",
      " [0.81582332]]\n",
      "Loss: \n",
      " 0.00920851879185654\n",
      "\n",
      "\n",
      "Epoch: 124\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.79927044]\n",
      " [0.77518769]\n",
      " [0.816721  ]]\n",
      "Loss: \n",
      " 0.00904618838259596\n",
      "\n",
      "\n",
      "Epoch: 125\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.80013006]\n",
      " [0.77601572]\n",
      " [0.81760481]]\n",
      "Loss: \n",
      " 0.008887741345649096\n",
      "\n",
      "\n",
      "Epoch: 126\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.80097713]\n",
      " [0.77683197]\n",
      " [0.81847505]]\n",
      "Loss: \n",
      " 0.008733060744046412\n",
      "\n",
      "\n",
      "Epoch: 127\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.80181192]\n",
      " [0.77763667]\n",
      " [0.81933203]]\n",
      "Loss: \n",
      " 0.008582033894266379\n",
      "\n",
      "\n",
      "Epoch: 128\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.80263467]\n",
      " [0.77843008]\n",
      " [0.82017604]]\n",
      "Loss: \n",
      " 0.008434552185900198\n",
      "\n",
      "\n",
      "Epoch: 129\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.80344566]\n",
      " [0.77921242]\n",
      " [0.82100736]]\n",
      "Loss: \n",
      " 0.008290510909980163\n",
      "\n",
      "\n",
      "Epoch: 130\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.80424511]\n",
      " [0.77998392]\n",
      " [0.82182627]]\n",
      "Loss: \n",
      " 0.008149809095510725\n",
      "\n",
      "\n",
      "Epoch: 131\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.80503327]\n",
      " [0.78074479]\n",
      " [0.82263302]]\n",
      "Loss: \n",
      " 0.008012349353767725\n",
      "\n",
      "\n",
      "Epoch: 132\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.80581036]\n",
      " [0.78149526]\n",
      " [0.82342789]]\n",
      "Loss: \n",
      " 0.007878037729956464\n",
      "\n",
      "\n",
      "Epoch: 133\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.80657663]\n",
      " [0.78223553]\n",
      " [0.82421113]]\n",
      "Loss: \n",
      " 0.007746783561842667\n",
      "\n",
      "\n",
      "Epoch: 134\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.80733228]\n",
      " [0.7829658 ]\n",
      " [0.82498297]]\n",
      "Loss: \n",
      " 0.00761849934499258\n",
      "\n",
      "\n",
      "Epoch: 135\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.80807752]\n",
      " [0.78368627]\n",
      " [0.82574367]]\n",
      "Loss: \n",
      " 0.007493100604278859\n",
      "\n",
      "\n",
      "Epoch: 136\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.80881258]\n",
      " [0.78439714]\n",
      " [0.82649345]]\n",
      "Loss: \n",
      " 0.007370505771328519\n",
      "\n",
      "\n",
      "Epoch: 137\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.80953764]\n",
      " [0.78509859]\n",
      " [0.82723254]]\n",
      "Loss: \n",
      " 0.007250636067607615\n",
      "\n",
      "\n",
      "Epoch: 138\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.81025291]\n",
      " [0.7857908 ]\n",
      " [0.82796116]]\n",
      "Loss: \n",
      " 0.007133415392854087\n",
      "\n",
      "\n",
      "Epoch: 139\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.81095858]\n",
      " [0.78647396]\n",
      " [0.82867952]]\n",
      "Loss: \n",
      " 0.007018770218586577\n",
      "\n",
      "\n",
      "Epoch: 140\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.81165484]\n",
      " [0.78714823]\n",
      " [0.82938783]]\n",
      "Loss: \n",
      " 0.006906629486432312\n",
      "\n",
      "\n",
      "Epoch: 141\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.81234187]\n",
      " [0.78781379]\n",
      " [0.8300863 ]]\n",
      "Loss: \n",
      " 0.006796924511030753\n",
      "\n",
      "\n",
      "Epoch: 142\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.81301985]\n",
      " [0.7884708 ]\n",
      " [0.83077512]]\n",
      "Loss: \n",
      " 0.006689588887284115\n",
      "\n",
      "\n",
      "Epoch: 143\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.81368894]\n",
      " [0.78911942]\n",
      " [0.83145448]]\n",
      "Loss: \n",
      " 0.00658455840173739\n",
      "\n",
      "\n",
      "Epoch: 144\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.81434933]\n",
      " [0.78975981]\n",
      " [0.83212458]]\n",
      "Loss: \n",
      " 0.006481770947883019\n",
      "\n",
      "\n",
      "Epoch: 145\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.81500117]\n",
      " [0.79039212]\n",
      " [0.8327856 ]]\n",
      "Loss: \n",
      " 0.006381166445196584\n",
      "\n",
      "\n",
      "Epoch: 146\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.81564463]\n",
      " [0.7910165 ]\n",
      " [0.8334377 ]]\n",
      "Loss: \n",
      " 0.006282686761719639\n",
      "\n",
      "\n",
      "Epoch: 147\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.81627986]\n",
      " [0.79163309]\n",
      " [0.83408108]]\n",
      "Loss: \n",
      " 0.006186275640016652\n",
      "\n",
      "\n",
      "Epoch: 148\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.81690702]\n",
      " [0.79224205]\n",
      " [0.83471589]]\n",
      "Loss: \n",
      " 0.006091878626341623\n",
      "\n",
      "\n",
      "Epoch: 149\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.81752625]\n",
      " [0.7928435 ]\n",
      " [0.8353423 ]]\n",
      "Loss: \n",
      " 0.005999443002859039\n",
      "\n",
      "\n",
      "Epoch: 150\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.81813771]\n",
      " [0.79343758]\n",
      " [0.83596047]]\n",
      "Loss: \n",
      " 0.00590891772277199\n",
      "\n",
      "\n",
      "Epoch: 151\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.81874152]\n",
      " [0.79402443]\n",
      " [0.83657056]]\n",
      "Loss: \n",
      " 0.0058202533482181115\n",
      "\n",
      "\n",
      "Epoch: 152\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.81933784]\n",
      " [0.79460417]\n",
      " [0.83717272]]\n",
      "Loss: \n",
      " 0.005733401990801263\n",
      "\n",
      "\n",
      "Epoch: 153\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8199268 ]\n",
      " [0.79517693]\n",
      " [0.8377671 ]]\n",
      "Loss: \n",
      " 0.0056483172546339215\n",
      "\n",
      "\n",
      "Epoch: 154\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.82050853]\n",
      " [0.79574283]\n",
      " [0.83835384]]\n",
      "Loss: \n",
      " 0.0055649541817716875\n",
      "\n",
      "\n",
      "Epoch: 155\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.82108315]\n",
      " [0.796302  ]\n",
      " [0.83893309]]\n",
      "Loss: \n",
      " 0.0054832691999273766\n",
      "\n",
      "\n",
      "Epoch: 156\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8216508 ]\n",
      " [0.79685454]\n",
      " [0.83950499]]\n",
      "Loss: \n",
      " 0.005403220072358324\n",
      "\n",
      "\n",
      "Epoch: 157\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8222116 ]\n",
      " [0.79740058]\n",
      " [0.84006966]]\n",
      "Loss: \n",
      " 0.005324765849825521\n",
      "\n",
      "\n",
      "Epoch: 158\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.82276566]\n",
      " [0.79794023]\n",
      " [0.84062725]]\n",
      "Loss: \n",
      " 0.005247866824528906\n",
      "\n",
      "\n",
      "Epoch: 159\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.82331311]\n",
      " [0.79847359]\n",
      " [0.84117788]]\n",
      "Loss: \n",
      " 0.005172484485927521\n",
      "\n",
      "\n",
      "Epoch: 160\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.82385406]\n",
      " [0.79900077]\n",
      " [0.84172167]]\n",
      "Loss: \n",
      " 0.005098581478358303\n",
      "\n",
      "\n",
      "Epoch: 161\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.82438863]\n",
      " [0.79952188]\n",
      " [0.84225875]]\n",
      "Loss: \n",
      " 0.005026121560371356\n",
      "\n",
      "\n",
      "Epoch: 162\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.82491691]\n",
      " [0.80003702]\n",
      " [0.84278924]]\n",
      "Loss: \n",
      " 0.004955069565703813\n",
      "\n",
      "\n",
      "Epoch: 163\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.82543903]\n",
      " [0.80054629]\n",
      " [0.84331325]]\n",
      "Loss: \n",
      " 0.004885391365818175\n",
      "\n",
      "\n",
      "Epoch: 164\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.82595507]\n",
      " [0.80104978]\n",
      " [0.8438309 ]]\n",
      "Loss: \n",
      " 0.004817053833934991\n",
      "\n",
      "\n",
      "Epoch: 165\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.82646516]\n",
      " [0.8015476 ]\n",
      " [0.8443423 ]]\n",
      "Loss: \n",
      " 0.004750024810492733\n",
      "\n",
      "\n",
      "Epoch: 166\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.82696938]\n",
      " [0.80203984]\n",
      " [0.84484756]]\n",
      "Loss: \n",
      " 0.004684273069971572\n",
      "\n",
      "\n",
      "Epoch: 167\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.82746783]\n",
      " [0.80252658]\n",
      " [0.84534679]]\n",
      "Loss: \n",
      " 0.00461976828902052\n",
      "\n",
      "\n",
      "Epoch: 168\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.82796062]\n",
      " [0.80300792]\n",
      " [0.84584009]]\n",
      "Loss: \n",
      " 0.004556481015830436\n",
      "\n",
      "\n",
      "Epoch: 169\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.82844782]\n",
      " [0.80348394]\n",
      " [0.84632756]]\n",
      "Loss: \n",
      " 0.0044943826406983215\n",
      "\n",
      "\n",
      "Epoch: 170\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.82892955]\n",
      " [0.80395474]\n",
      " [0.84680929]]\n",
      "Loss: \n",
      " 0.004433445367730721\n",
      "\n",
      "\n",
      "Epoch: 171\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.82940587]\n",
      " [0.80442038]\n",
      " [0.8472854 ]]\n",
      "Loss: \n",
      " 0.0043736421876369135\n",
      "\n",
      "\n",
      "Epoch: 172\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.82987689]\n",
      " [0.80488097]\n",
      " [0.84775597]]\n",
      "Loss: \n",
      " 0.004314946851564657\n",
      "\n",
      "\n",
      "Epoch: 173\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.83034269]\n",
      " [0.80533657]\n",
      " [0.84822109]]\n",
      "Loss: \n",
      " 0.004257333845933473\n",
      "\n",
      "\n",
      "Epoch: 174\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.83080335]\n",
      " [0.80578726]\n",
      " [0.84868087]]\n",
      "Loss: \n",
      " 0.004200778368223063\n",
      "\n",
      "\n",
      "Epoch: 175\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.83125895]\n",
      " [0.80623313]\n",
      " [0.84913537]]\n",
      "Loss: \n",
      " 0.004145256303675719\n",
      "\n",
      "\n",
      "Epoch: 176\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.83170957]\n",
      " [0.80667424]\n",
      " [0.8495847 ]]\n",
      "Loss: \n",
      " 0.004090744202874338\n",
      "\n",
      "\n",
      "Epoch: 177\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8321553 ]\n",
      " [0.80711067]\n",
      " [0.85002894]]\n",
      "Loss: \n",
      " 0.004037219260158718\n",
      "\n",
      "\n",
      "Epoch: 178\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.83259621]\n",
      " [0.8075425 ]\n",
      " [0.85046816]]\n",
      "Loss: \n",
      " 0.003984659292845102\n",
      "\n",
      "\n",
      "Epoch: 179\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.83303238]\n",
      " [0.80796978]\n",
      " [0.85090246]]\n",
      "Loss: \n",
      " 0.003933042721215232\n",
      "\n",
      "\n",
      "Epoch: 180\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.83346387]\n",
      " [0.80839261]\n",
      " [0.85133191]]\n",
      "Loss: \n",
      " 0.0038823485492429613\n",
      "\n",
      "\n",
      "Epoch: 181\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.83389077]\n",
      " [0.80881103]\n",
      " [0.85175659]]\n",
      "Loss: \n",
      " 0.0038325563460278387\n",
      "\n",
      "\n",
      "Epoch: 182\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.83431314]\n",
      " [0.80922512]\n",
      " [0.85217658]]\n",
      "Loss: \n",
      " 0.003783646227906293\n",
      "\n",
      "\n",
      "Epoch: 183\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.83473105]\n",
      " [0.80963494]\n",
      " [0.85259194]]\n",
      "Loss: \n",
      " 0.003735598841212958\n",
      "\n",
      "\n",
      "Epoch: 184\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.83514457]\n",
      " [0.81004056]\n",
      " [0.85300276]]\n",
      "Loss: \n",
      " 0.0036883953456651603\n",
      "\n",
      "\n",
      "Epoch: 185\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.83555377]\n",
      " [0.81044203]\n",
      " [0.85340911]]\n",
      "Loss: \n",
      " 0.0036420173983455102\n",
      "\n",
      "\n",
      "Epoch: 186\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.83595871]\n",
      " [0.81083943]\n",
      " [0.85381105]]\n",
      "Loss: \n",
      " 0.0035964471382581554\n",
      "\n",
      "\n",
      "Epoch: 187\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.83635945]\n",
      " [0.8112328 ]\n",
      " [0.85420865]]\n",
      "Loss: \n",
      " 0.0035516671714357164\n",
      "\n",
      "\n",
      "Epoch: 188\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.83675607]\n",
      " [0.81162222]\n",
      " [0.85460198]]\n",
      "Loss: \n",
      " 0.00350766055657469\n",
      "\n",
      "\n",
      "Epoch: 189\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.83714861]\n",
      " [0.81200773]\n",
      " [0.85499111]]\n",
      "Loss: \n",
      " 0.003464410791178296\n",
      "\n",
      "\n",
      "Epoch: 190\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.83753715]\n",
      " [0.8123894 ]\n",
      " [0.85537611]]\n",
      "Loss: \n",
      " 0.0034219017981864806\n",
      "\n",
      "\n",
      "Epoch: 191\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.83792173]\n",
      " [0.81276728]\n",
      " [0.85575702]]\n",
      "Loss: \n",
      " 0.003380117913073787\n",
      "\n",
      "\n",
      "Epoch: 192\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.83830242]\n",
      " [0.81314141]\n",
      " [0.85613393]]\n",
      "Loss: \n",
      " 0.0033390438713968486\n",
      "\n",
      "\n",
      "Epoch: 193\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.83867928]\n",
      " [0.81351187]\n",
      " [0.85650688]]\n",
      "Loss: \n",
      " 0.0032986647967735\n",
      "\n",
      "\n",
      "Epoch: 194\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.83905236]\n",
      " [0.8138787 ]\n",
      " [0.85687594]]\n",
      "Loss: \n",
      " 0.003258966189277037\n",
      "\n",
      "\n",
      "Epoch: 195\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.83942171]\n",
      " [0.81424195]\n",
      " [0.85724116]]\n",
      "Loss: \n",
      " 0.003219933914229112\n",
      "\n",
      "\n",
      "Epoch: 196\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.83978739]\n",
      " [0.81460166]\n",
      " [0.85760261]]\n",
      "Loss: \n",
      " 0.0031815541913761\n",
      "\n",
      "\n",
      "Epoch: 197\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.84014945]\n",
      " [0.8149579 ]\n",
      " [0.85796033]]\n",
      "Loss: \n",
      " 0.003143813584434033\n",
      "\n",
      "\n",
      "Epoch: 198\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.84050795]\n",
      " [0.81531071]\n",
      " [0.85831439]]\n",
      "Loss: \n",
      " 0.0031066989909879217\n",
      "\n",
      "\n",
      "Epoch: 199\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.84086292]\n",
      " [0.81566014]\n",
      " [0.85866483]]\n",
      "Loss: \n",
      " 0.0030701976327320497\n",
      "\n",
      "\n",
      "Epoch: 200\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.84121443]\n",
      " [0.81600623]\n",
      " [0.85901171]]\n",
      "Loss: \n",
      " 0.0030342970460380397\n",
      "\n",
      "\n",
      "Epoch: 201\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.84156252]\n",
      " [0.81634903]\n",
      " [0.85935509]]\n",
      "Loss: \n",
      " 0.0029989850728385768\n",
      "\n",
      "\n",
      "Epoch: 202\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.84190724]\n",
      " [0.81668859]\n",
      " [0.85969501]]\n",
      "Loss: \n",
      " 0.0029642498518146847\n",
      "\n",
      "\n",
      "Epoch: 203\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.84224864]\n",
      " [0.81702495]\n",
      " [0.86003152]]\n",
      "Loss: \n",
      " 0.0029300798098750524\n",
      "\n",
      "\n",
      "Epoch: 204\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.84258676]\n",
      " [0.81735815]\n",
      " [0.86036467]]\n",
      "Loss: \n",
      " 0.002896463653916812\n",
      "\n",
      "\n",
      "Epoch: 205\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.84292164]\n",
      " [0.81768823]\n",
      " [0.86069451]]\n",
      "Loss: \n",
      " 0.0028633903628570347\n",
      "\n",
      "\n",
      "Epoch: 206\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.84325334]\n",
      " [0.81801524]\n",
      " [0.86102109]]\n",
      "Loss: \n",
      " 0.0028308491799249377\n",
      "\n",
      "\n",
      "Epoch: 207\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.84358189]\n",
      " [0.81833922]\n",
      " [0.86134444]]\n",
      "Loss: \n",
      " 0.0027988296052052566\n",
      "\n",
      "\n",
      "Epoch: 208\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.84390734]\n",
      " [0.81866021]\n",
      " [0.86166463]]\n",
      "Loss: \n",
      " 0.0027673213884235382\n",
      "\n",
      "\n",
      "Epoch: 209\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.84422973]\n",
      " [0.81897825]\n",
      " [0.86198169]]\n",
      "Loss: \n",
      " 0.0027363145219643802\n",
      "\n",
      "\n",
      "Epoch: 210\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8445491 ]\n",
      " [0.81929338]\n",
      " [0.86229566]]\n",
      "Loss: \n",
      " 0.002705799234114376\n",
      "\n",
      "\n",
      "Epoch: 211\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.84486549]\n",
      " [0.81960563]\n",
      " [0.8626066 ]]\n",
      "Loss: \n",
      " 0.0026757659825212706\n",
      "\n",
      "\n",
      "Epoch: 212\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.84517895]\n",
      " [0.81991505]\n",
      " [0.86291453]]\n",
      "Loss: \n",
      " 0.002646205447861795\n",
      "\n",
      "\n",
      "Epoch: 213\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8454895 ]\n",
      " [0.82022166]\n",
      " [0.8632195 ]]\n",
      "Loss: \n",
      " 0.002617108527710598\n",
      "\n",
      "\n",
      "Epoch: 214\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.84579719]\n",
      " [0.82052552]\n",
      " [0.86352156]]\n",
      "Loss: \n",
      " 0.0025884663306029276\n",
      "\n",
      "\n",
      "Epoch: 215\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.84610206]\n",
      " [0.82082665]\n",
      " [0.86382074]]\n",
      "Loss: \n",
      " 0.0025602701702843495\n",
      "\n",
      "\n",
      "Epoch: 216\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.84640415]\n",
      " [0.82112508]\n",
      " [0.86411708]]\n",
      "Loss: \n",
      " 0.002532511560140729\n",
      "\n",
      "\n",
      "Epoch: 217\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.84670348]\n",
      " [0.82142086]\n",
      " [0.86441062]]\n",
      "Loss: \n",
      " 0.002505182207802112\n",
      "\n",
      "\n",
      "Epoch: 218\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8470001 ]\n",
      " [0.82171401]\n",
      " [0.86470139]]\n",
      "Loss: \n",
      " 0.0024782740099144034\n",
      "\n",
      "\n",
      "Epoch: 219\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.84729404]\n",
      " [0.82200457]\n",
      " [0.86498944]]\n",
      "Loss: \n",
      " 0.0024517790470729266\n",
      "\n",
      "\n",
      "Epoch: 220\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.84758534]\n",
      " [0.82229257]\n",
      " [0.86527481]]\n",
      "Loss: \n",
      " 0.002425689578912254\n",
      "\n",
      "\n",
      "Epoch: 221\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.84787402]\n",
      " [0.82257805]\n",
      " [0.86555751]]\n",
      "Loss: \n",
      " 0.002399998039346741\n",
      "\n",
      "\n",
      "Epoch: 222\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.84816013]\n",
      " [0.82286104]\n",
      " [0.8658376 ]]\n",
      "Loss: \n",
      " 0.002374697031956734\n",
      "\n",
      "\n",
      "Epoch: 223\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.84844369]\n",
      " [0.82314156]\n",
      " [0.86611511]]\n",
      "Loss: \n",
      " 0.0023497793255151966\n",
      "\n",
      "\n",
      "Epoch: 224\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.84872474]\n",
      " [0.82341965]\n",
      " [0.86639006]]\n",
      "Loss: \n",
      " 0.002325237849650143\n",
      "\n",
      "\n",
      "Epoch: 225\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.84900331]\n",
      " [0.82369534]\n",
      " [0.8666625 ]]\n",
      "Loss: \n",
      " 0.002301065690638008\n",
      "\n",
      "\n",
      "Epoch: 226\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.84927944]\n",
      " [0.82396865]\n",
      " [0.86693245]]\n",
      "Loss: \n",
      " 0.0022772560873236818\n",
      "\n",
      "\n",
      "Epoch: 227\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.84955314]\n",
      " [0.82423962]\n",
      " [0.86719995]]\n",
      "Loss: \n",
      " 0.0022538024271627835\n",
      "\n",
      "\n",
      "Epoch: 228\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.84982445]\n",
      " [0.82450828]\n",
      " [0.86746503]]\n",
      "Loss: \n",
      " 0.002230698242382058\n",
      "\n",
      "\n",
      "Epoch: 229\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.85009341]\n",
      " [0.82477465]\n",
      " [0.86772772]]\n",
      "Loss: \n",
      " 0.002207937206253959\n",
      "\n",
      "\n",
      "Epoch: 230\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.85036003]\n",
      " [0.82503876]\n",
      " [0.86798805]]\n",
      "Loss: \n",
      " 0.0021855131294814738\n",
      "\n",
      "\n",
      "Epoch: 231\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.85062436]\n",
      " [0.82530064]\n",
      " [0.86824605]]\n",
      "Loss: \n",
      " 0.00216341995668964\n",
      "\n",
      "\n",
      "Epoch: 232\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.85088641]\n",
      " [0.82556031]\n",
      " [0.86850175]]\n",
      "Loss: \n",
      " 0.0021416517630201384\n",
      "\n",
      "\n",
      "Epoch: 233\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.85114622]\n",
      " [0.82581781]\n",
      " [0.86875518]]\n",
      "Loss: \n",
      " 0.002120202750825475\n",
      "\n",
      "\n",
      "Epoch: 234\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.85140381]\n",
      " [0.82607315]\n",
      " [0.86900636]]\n",
      "Loss: \n",
      " 0.0020990672464595663\n",
      "\n",
      "\n",
      "Epoch: 235\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8516592 ]\n",
      " [0.82632636]\n",
      " [0.86925534]]\n",
      "Loss: \n",
      " 0.002078239697161466\n",
      "\n",
      "\n",
      "Epoch: 236\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.85191244]\n",
      " [0.82657748]\n",
      " [0.86950213]]\n",
      "Loss: \n",
      " 0.0020577146680292604\n",
      "\n",
      "\n",
      "Epoch: 237\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.85216353]\n",
      " [0.82682652]\n",
      " [0.86974675]]\n",
      "Loss: \n",
      " 0.0020374868390811087\n",
      "\n",
      "\n",
      "Epoch: 238\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.85241251]\n",
      " [0.8270735 ]\n",
      " [0.86998925]]\n",
      "Loss: \n",
      " 0.002017551002400621\n",
      "\n",
      "\n",
      "Epoch: 239\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.85265941]\n",
      " [0.82731845]\n",
      " [0.87022964]]\n",
      "Loss: \n",
      " 0.001997902059363847\n",
      "\n",
      "\n",
      "Epoch: 240\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.85290424]\n",
      " [0.8275614 ]\n",
      " [0.87046794]]\n",
      "Loss: \n",
      " 0.001978535017945232\n",
      "\n",
      "\n",
      "Epoch: 241\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.85314703]\n",
      " [0.82780237]\n",
      " [0.8707042 ]]\n",
      "Loss: \n",
      " 0.0019594449900999984\n",
      "\n",
      "\n",
      "Epoch: 242\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.85338781]\n",
      " [0.82804138]\n",
      " [0.87093842]]\n",
      "Loss: \n",
      " 0.0019406271892204857\n",
      "\n",
      "\n",
      "Epoch: 243\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.85362659]\n",
      " [0.82827845]\n",
      " [0.87117063]]\n",
      "Loss: \n",
      " 0.0019220769276640992\n",
      "\n",
      "\n",
      "Epoch: 244\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.85386341]\n",
      " [0.82851361]\n",
      " [0.87140087]]\n",
      "Loss: \n",
      " 0.0019037896143506575\n",
      "\n",
      "\n",
      "Epoch: 245\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.85409829]\n",
      " [0.82874687]\n",
      " [0.87162914]]\n",
      "Loss: \n",
      " 0.0018857607524267322\n",
      "\n",
      "\n",
      "Epoch: 246\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.85433124]\n",
      " [0.82897827]\n",
      " [0.87185548]]\n",
      "Loss: \n",
      " 0.0018679859369951448\n",
      "\n",
      "\n",
      "Epoch: 247\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.85456229]\n",
      " [0.82920781]\n",
      " [0.87207991]]\n",
      "Loss: \n",
      " 0.0018504608529073359\n",
      "\n",
      "\n",
      "Epoch: 248\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.85479146]\n",
      " [0.82943553]\n",
      " [0.87230245]]\n",
      "Loss: \n",
      " 0.0018331812726167776\n",
      "\n",
      "\n",
      "Epoch: 249\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.85501878]\n",
      " [0.82966143]\n",
      " [0.87252313]]\n",
      "Loss: \n",
      " 0.001816143054091424\n",
      "\n",
      "\n",
      "Epoch: 250\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.85524426]\n",
      " [0.82988555]\n",
      " [0.87274196]]\n",
      "Loss: \n",
      " 0.001799342138783457\n",
      "\n",
      "\n",
      "Epoch: 251\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.85546792]\n",
      " [0.8301079 ]\n",
      " [0.87295897]]\n",
      "Loss: \n",
      " 0.0017827745496544957\n",
      "\n",
      "\n",
      "Epoch: 252\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.85568979]\n",
      " [0.8303285 ]\n",
      " [0.87317417]]\n",
      "Loss: \n",
      " 0.001766436389254501\n",
      "\n",
      "\n",
      "Epoch: 253\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.85590989]\n",
      " [0.83054737]\n",
      " [0.8733876 ]]\n",
      "Loss: \n",
      " 0.001750323837852889\n",
      "\n",
      "\n",
      "Epoch: 254\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.85612823]\n",
      " [0.83076453]\n",
      " [0.87359926]]\n",
      "Loss: \n",
      " 0.001734433151620068\n",
      "\n",
      "\n",
      "Epoch: 255\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.85634484]\n",
      " [0.83098   ]\n",
      " [0.87380919]]\n",
      "Loss: \n",
      " 0.001718760660857948\n",
      "\n",
      "\n",
      "Epoch: 256\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.85655973]\n",
      " [0.8311938 ]\n",
      " [0.8740174 ]]\n",
      "Loss: \n",
      " 0.001703302768277966\n",
      "\n",
      "\n",
      "Epoch: 257\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.85677293]\n",
      " [0.83140594]\n",
      " [0.8742239 ]]\n",
      "Loss: \n",
      " 0.0016880559473250961\n",
      "\n",
      "\n",
      "Epoch: 258\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.85698445]\n",
      " [0.83161644]\n",
      " [0.87442873]]\n",
      "Loss: \n",
      " 0.0016730167405465245\n",
      "\n",
      "\n",
      "Epoch: 259\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.85719431]\n",
      " [0.83182533]\n",
      " [0.87463189]]\n",
      "Loss: \n",
      " 0.0016581817580035914\n",
      "\n",
      "\n",
      "Epoch: 260\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.85740253]\n",
      " [0.83203261]\n",
      " [0.87483341]]\n",
      "Loss: \n",
      " 0.0016435476757257483\n",
      "\n",
      "\n",
      "Epoch: 261\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.85760913]\n",
      " [0.83223831]\n",
      " [0.87503331]]\n",
      "Loss: \n",
      " 0.0016291112342052706\n",
      "\n",
      "\n",
      "Epoch: 262\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.85781412]\n",
      " [0.83244244]\n",
      " [0.8752316 ]]\n",
      "Loss: \n",
      " 0.001614869236931447\n",
      "\n",
      "\n",
      "Epoch: 263\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.85801753]\n",
      " [0.83264502]\n",
      " [0.87542831]]\n",
      "Loss: \n",
      " 0.0016008185489631748\n",
      "\n",
      "\n",
      "Epoch: 264\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.85821937]\n",
      " [0.83284607]\n",
      " [0.87562344]]\n",
      "Loss: \n",
      " 0.001586956095538706\n",
      "\n",
      "\n",
      "Epoch: 265\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.85841965]\n",
      " [0.8330456 ]\n",
      " [0.87581702]]\n",
      "Loss: \n",
      " 0.0015732788607215867\n",
      "\n",
      "\n",
      "Epoch: 266\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.85861839]\n",
      " [0.83324362]\n",
      " [0.87600907]]\n",
      "Loss: \n",
      " 0.0015597838860815945\n",
      "\n",
      "\n",
      "Epoch: 267\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.85881562]\n",
      " [0.83344016]\n",
      " [0.8761996 ]]\n",
      "Loss: \n",
      " 0.001546468269409731\n",
      "\n",
      "\n",
      "Epoch: 268\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.85901134]\n",
      " [0.83363523]\n",
      " [0.87638862]]\n",
      "Loss: \n",
      " 0.0015333291634662474\n",
      "\n",
      "\n",
      "Epoch: 269\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.85920557]\n",
      " [0.83382884]\n",
      " [0.87657616]]\n",
      "Loss: \n",
      " 0.0015203637747607404\n",
      "\n",
      "\n",
      "Epoch: 270\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.85939833]\n",
      " [0.83402101]\n",
      " [0.87676224]]\n",
      "Loss: \n",
      " 0.0015075693623633985\n",
      "\n",
      "\n",
      "Epoch: 271\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.85958964]\n",
      " [0.83421176]\n",
      " [0.87694685]]\n",
      "Loss: \n",
      " 0.0014949432367465368\n",
      "\n",
      "\n",
      "Epoch: 272\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8597795 ]\n",
      " [0.83440109]\n",
      " [0.87713004]]\n",
      "Loss: \n",
      " 0.001482482758655405\n",
      "\n",
      "\n",
      "Epoch: 273\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.85996794]\n",
      " [0.83458903]\n",
      " [0.8773118 ]]\n",
      "Loss: \n",
      " 0.0014701853380076374\n",
      "\n",
      "\n",
      "Epoch: 274\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86015497]\n",
      " [0.83477559]\n",
      " [0.87749215]]\n",
      "Loss: \n",
      " 0.0014580484328203574\n",
      "\n",
      "\n",
      "Epoch: 275\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86034059]\n",
      " [0.83496078]\n",
      " [0.87767111]]\n",
      "Loss: \n",
      " 0.0014460695481642227\n",
      "\n",
      "\n",
      "Epoch: 276\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86052484]\n",
      " [0.83514462]\n",
      " [0.87784869]]\n",
      "Loss: \n",
      " 0.001434246235143684\n",
      "\n",
      "\n",
      "Epoch: 277\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86070772]\n",
      " [0.83532711]\n",
      " [0.87802492]]\n",
      "Loss: \n",
      " 0.00142257608990256\n",
      "\n",
      "\n",
      "Epoch: 278\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86088925]\n",
      " [0.83550828]\n",
      " [0.87819979]]\n",
      "Loss: \n",
      " 0.001411056752654424\n",
      "\n",
      "\n",
      "Epoch: 279\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86106943]\n",
      " [0.83568814]\n",
      " [0.87837334]]\n",
      "Loss: \n",
      " 0.0013996859067369487\n",
      "\n",
      "\n",
      "Epoch: 280\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86124829]\n",
      " [0.83586669]\n",
      " [0.87854556]]\n",
      "Loss: \n",
      " 0.0013884612776896117\n",
      "\n",
      "\n",
      "Epoch: 281\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86142584]\n",
      " [0.83604396]\n",
      " [0.87871648]]\n",
      "Loss: \n",
      " 0.001377380632354059\n",
      "\n",
      "\n",
      "Epoch: 282\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86160209]\n",
      " [0.83621995]\n",
      " [0.8788861 ]]\n",
      "Loss: \n",
      " 0.0013664417779965488\n",
      "\n",
      "\n",
      "Epoch: 283\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86177705]\n",
      " [0.83639469]\n",
      " [0.87905445]]\n",
      "Loss: \n",
      " 0.0013556425614518518\n",
      "\n",
      "\n",
      "Epoch: 284\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86195074]\n",
      " [0.83656817]\n",
      " [0.87922153]]\n",
      "Loss: \n",
      " 0.0013449808682879838\n",
      "\n",
      "\n",
      "Epoch: 285\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86212317]\n",
      " [0.83674042]\n",
      " [0.87938737]]\n",
      "Loss: \n",
      " 0.001334454621991191\n",
      "\n",
      "\n",
      "Epoch: 286\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86229435]\n",
      " [0.83691144]\n",
      " [0.87955196]]\n",
      "Loss: \n",
      " 0.0013240617831706914\n",
      "\n",
      "\n",
      "Epoch: 287\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8624643 ]\n",
      " [0.83708125]\n",
      " [0.87971533]]\n",
      "Loss: \n",
      " 0.0013138003487826195\n",
      "\n",
      "\n",
      "Epoch: 288\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86263302]\n",
      " [0.83724986]\n",
      " [0.87987748]]\n",
      "Loss: \n",
      " 0.0013036683513725465\n",
      "\n",
      "\n",
      "Epoch: 289\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86280053]\n",
      " [0.83741727]\n",
      " [0.88003843]]\n",
      "Loss: \n",
      " 0.001293663858336221\n",
      "\n",
      "\n",
      "Epoch: 290\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86296685]\n",
      " [0.83758352]\n",
      " [0.88019819]]\n",
      "Loss: \n",
      " 0.0012837849711979552\n",
      "\n",
      "\n",
      "Epoch: 291\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86313197]\n",
      " [0.83774859]\n",
      " [0.88035678]]\n",
      "Loss: \n",
      " 0.0012740298249061571\n",
      "\n",
      "\n",
      "Epoch: 292\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86329592]\n",
      " [0.83791251]\n",
      " [0.8805142 ]]\n",
      "Loss: \n",
      " 0.001264396587145616\n",
      "\n",
      "\n",
      "Epoch: 293\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86345871]\n",
      " [0.83807529]\n",
      " [0.88067047]]\n",
      "Loss: \n",
      " 0.0012548834576660381\n",
      "\n",
      "\n",
      "Epoch: 294\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86362035]\n",
      " [0.83823693]\n",
      " [0.8808256 ]]\n",
      "Loss: \n",
      " 0.0012454886676264152\n",
      "\n",
      "\n",
      "Epoch: 295\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86378084]\n",
      " [0.83839746]\n",
      " [0.88097959]]\n",
      "Loss: \n",
      " 0.001236210478954839\n",
      "\n",
      "\n",
      "Epoch: 296\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86394021]\n",
      " [0.83855687]\n",
      " [0.88113247]]\n",
      "Loss: \n",
      " 0.0012270471837232339\n",
      "\n",
      "\n",
      "Epoch: 297\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86409845]\n",
      " [0.83871518]\n",
      " [0.88128424]]\n",
      "Loss: \n",
      " 0.0012179971035368106\n",
      "\n",
      "\n",
      "Epoch: 298\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86425559]\n",
      " [0.8388724 ]\n",
      " [0.88143491]]\n",
      "Loss: \n",
      " 0.0012090585889376032\n",
      "\n",
      "\n",
      "Epoch: 299\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86441163]\n",
      " [0.83902853]\n",
      " [0.8815845 ]]\n",
      "Loss: \n",
      " 0.0012002300188219907\n",
      "\n",
      "\n",
      "Epoch: 300\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86456658]\n",
      " [0.8391836 ]\n",
      " [0.88173301]]\n",
      "Loss: \n",
      " 0.001191509799871548\n",
      "\n",
      "\n",
      "Epoch: 301\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86472046]\n",
      " [0.83933761]\n",
      " [0.88188046]]\n",
      "Loss: \n",
      " 0.0011828963659971747\n",
      "\n",
      "\n",
      "Epoch: 302\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86487327]\n",
      " [0.83949057]\n",
      " [0.88202685]]\n",
      "Loss: \n",
      " 0.001174388177795877\n",
      "\n",
      "\n",
      "Epoch: 303\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86502502]\n",
      " [0.83964249]\n",
      " [0.8821722 ]]\n",
      "Loss: \n",
      " 0.0011659837220201106\n",
      "\n",
      "\n",
      "Epoch: 304\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86517572]\n",
      " [0.83979338]\n",
      " [0.88231652]]\n",
      "Loss: \n",
      " 0.001157681511059127\n",
      "\n",
      "\n",
      "Epoch: 305\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86532539]\n",
      " [0.83994325]\n",
      " [0.88245981]]\n",
      "Loss: \n",
      " 0.0011494800824322772\n",
      "\n",
      "\n",
      "Epoch: 306\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86547404]\n",
      " [0.84009211]\n",
      " [0.88260209]]\n",
      "Loss: \n",
      " 0.0011413779982937325\n",
      "\n",
      "\n",
      "Epoch: 307\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86562166]\n",
      " [0.84023996]\n",
      " [0.88274336]]\n",
      "Loss: \n",
      " 0.0011333738449484229\n",
      "\n",
      "\n",
      "Epoch: 308\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86576828]\n",
      " [0.84038682]\n",
      " [0.88288364]]\n",
      "Loss: \n",
      " 0.0011254662323789335\n",
      "\n",
      "\n",
      "Epoch: 309\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8659139 ]\n",
      " [0.8405327 ]\n",
      " [0.88302294]]\n",
      "Loss: \n",
      " 0.001117653793783047\n",
      "\n",
      "\n",
      "Epoch: 310\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86605853]\n",
      " [0.8406776 ]\n",
      " [0.88316126]]\n",
      "Loss: \n",
      " 0.0011099351851216637\n",
      "\n",
      "\n",
      "Epoch: 311\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86620218]\n",
      " [0.84082153]\n",
      " [0.88329861]]\n",
      "Loss: \n",
      " 0.001102309084676779\n",
      "\n",
      "\n",
      "Epoch: 312\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86634486]\n",
      " [0.84096451]\n",
      " [0.88343501]]\n",
      "Loss: \n",
      " 0.001094774192619433\n",
      "\n",
      "\n",
      "Epoch: 313\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86648658]\n",
      " [0.84110654]\n",
      " [0.88357045]]\n",
      "Loss: \n",
      " 0.0010873292305871277\n",
      "\n",
      "\n",
      "Epoch: 314\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86662735]\n",
      " [0.84124763]\n",
      " [0.88370496]]\n",
      "Loss: \n",
      " 0.0010799729412707428\n",
      "\n",
      "\n",
      "Epoch: 315\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86676717]\n",
      " [0.84138779]\n",
      " [0.88383854]]\n",
      "Loss: \n",
      " 0.0010727040880105145\n",
      "\n",
      "\n",
      "Epoch: 316\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86690606]\n",
      " [0.84152702]\n",
      " [0.8839712 ]]\n",
      "Loss: \n",
      " 0.0010655214544008837\n",
      "\n",
      "\n",
      "Epoch: 317\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86704401]\n",
      " [0.84166534]\n",
      " [0.88410294]]\n",
      "Loss: \n",
      " 0.0010584238439041397\n",
      "\n",
      "\n",
      "Epoch: 318\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86718105]\n",
      " [0.84180275]\n",
      " [0.88423378]]\n",
      "Loss: \n",
      " 0.0010514100794724267\n",
      "\n",
      "\n",
      "Epoch: 319\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86731718]\n",
      " [0.84193926]\n",
      " [0.88436373]]\n",
      "Loss: \n",
      " 0.0010444790031780352\n",
      "\n",
      "\n",
      "Epoch: 320\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86745241]\n",
      " [0.84207488]\n",
      " [0.88449278]]\n",
      "Loss: \n",
      " 0.0010376294758517634\n",
      "\n",
      "\n",
      "Epoch: 321\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86758674]\n",
      " [0.84220962]\n",
      " [0.88462096]]\n",
      "Loss: \n",
      " 0.0010308603767291346\n",
      "\n",
      "\n",
      "Epoch: 322\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86772019]\n",
      " [0.84234348]\n",
      " [0.88474826]]\n",
      "Loss: \n",
      " 0.0010241706031042486\n",
      "\n",
      "\n",
      "Epoch: 323\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86785276]\n",
      " [0.84247647]\n",
      " [0.8848747 ]]\n",
      "Loss: \n",
      " 0.0010175590699911018\n",
      "\n",
      "\n",
      "Epoch: 324\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86798446]\n",
      " [0.84260861]\n",
      " [0.88500029]]\n",
      "Loss: \n",
      " 0.0010110247097922644\n",
      "\n",
      "\n",
      "Epoch: 325\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86811529]\n",
      " [0.84273989]\n",
      " [0.88512503]]\n",
      "Loss: \n",
      " 0.0010045664719745726\n",
      "\n",
      "\n",
      "Epoch: 326\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86824528]\n",
      " [0.84287033]\n",
      " [0.88524893]]\n",
      "Loss: \n",
      " 0.0009981833227518523\n",
      "\n",
      "\n",
      "Epoch: 327\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86837441]\n",
      " [0.84299992]\n",
      " [0.88537199]]\n",
      "Loss: \n",
      " 0.0009918742447743614\n",
      "\n",
      "\n",
      "Epoch: 328\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8685027 ]\n",
      " [0.84312869]\n",
      " [0.88549423]]\n",
      "Loss: \n",
      " 0.0009856382368248348\n",
      "\n",
      "\n",
      "Epoch: 329\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86863016]\n",
      " [0.84325663]\n",
      " [0.88561566]]\n",
      "Loss: \n",
      " 0.0009794743135210268\n",
      "\n",
      "\n",
      "Epoch: 330\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8687568 ]\n",
      " [0.84338376]\n",
      " [0.88573627]]\n",
      "Loss: \n",
      " 0.0009733815050245097\n",
      "\n",
      "\n",
      "Epoch: 331\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86888262]\n",
      " [0.84351008]\n",
      " [0.88585608]]\n",
      "Loss: \n",
      " 0.0009673588567556398\n",
      "\n",
      "\n",
      "Epoch: 332\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86900762]\n",
      " [0.84363559]\n",
      " [0.8859751 ]]\n",
      "Loss: \n",
      " 0.0009614054291144754\n",
      "\n",
      "\n",
      "Epoch: 333\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86913182]\n",
      " [0.84376031]\n",
      " [0.88609332]]\n",
      "Loss: \n",
      " 0.000955520297207635\n",
      "\n",
      "\n",
      "Epoch: 334\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86925523]\n",
      " [0.84388424]\n",
      " [0.88621077]]\n",
      "Loss: \n",
      " 0.0009497025505807796\n",
      "\n",
      "\n",
      "Epoch: 335\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86937784]\n",
      " [0.84400739]\n",
      " [0.88632744]]\n",
      "Loss: \n",
      " 0.000943951292956742\n",
      "\n",
      "\n",
      "Epoch: 336\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86949968]\n",
      " [0.84412976]\n",
      " [0.88644334]]\n",
      "Loss: \n",
      " 0.0009382656419790614\n",
      "\n",
      "\n",
      "Epoch: 337\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86962073]\n",
      " [0.84425137]\n",
      " [0.88655848]]\n",
      "Loss: \n",
      " 0.0009326447289608685\n",
      "\n",
      "\n",
      "Epoch: 338\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86974102]\n",
      " [0.84437221]\n",
      " [0.88667287]]\n",
      "Loss: \n",
      " 0.000927087698638964\n",
      "\n",
      "\n",
      "Epoch: 339\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86986054]\n",
      " [0.84449229]\n",
      " [0.88678651]]\n",
      "Loss: \n",
      " 0.0009215937089329494\n",
      "\n",
      "\n",
      "Epoch: 340\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8699793 ]\n",
      " [0.84461163]\n",
      " [0.8868994 ]]\n",
      "Loss: \n",
      " 0.0009161619307093377\n",
      "\n",
      "\n",
      "Epoch: 341\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87009732]\n",
      " [0.84473022]\n",
      " [0.88701157]]\n",
      "Loss: \n",
      " 0.000910791547550481\n",
      "\n",
      "\n",
      "Epoch: 342\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87021459]\n",
      " [0.84484807]\n",
      " [0.887123  ]]\n",
      "Loss: \n",
      " 0.0009054817555282758\n",
      "\n",
      "\n",
      "Epoch: 343\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87033112]\n",
      " [0.84496519]\n",
      " [0.88723371]]\n",
      "Loss: \n",
      " 0.0009002317629824081\n",
      "\n",
      "\n",
      "Epoch: 344\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87044692]\n",
      " [0.84508159]\n",
      " [0.88734371]]\n",
      "Loss: \n",
      " 0.0008950407903031885\n",
      "\n",
      "\n",
      "Epoch: 345\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.870562  ]\n",
      " [0.84519726]\n",
      " [0.887453  ]]\n",
      "Loss: \n",
      " 0.0008899080697187535\n",
      "\n",
      "\n",
      "Epoch: 346\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87067636]\n",
      " [0.84531222]\n",
      " [0.88756158]]\n",
      "Loss: \n",
      " 0.0008848328450865774\n",
      "\n",
      "\n",
      "Epoch: 347\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87079   ]\n",
      " [0.84542648]\n",
      " [0.88766947]]\n",
      "Loss: \n",
      " 0.0008798143716892021\n",
      "\n",
      "\n",
      "Epoch: 348\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87090293]\n",
      " [0.84554003]\n",
      " [0.88777666]]\n",
      "Loss: \n",
      " 0.0008748519160340892\n",
      "\n",
      "\n",
      "Epoch: 349\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87101517]\n",
      " [0.84565289]\n",
      " [0.88788317]]\n",
      "Loss: \n",
      " 0.0008699447556574673\n",
      "\n",
      "\n",
      "Epoch: 350\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87112671]\n",
      " [0.84576506]\n",
      " [0.887989  ]]\n",
      "Loss: \n",
      " 0.000865092178932111\n",
      "\n",
      "\n",
      "Epoch: 351\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87123755]\n",
      " [0.84587654]\n",
      " [0.88809415]]\n",
      "Loss: \n",
      " 0.0008602934848789941\n",
      "\n",
      "\n",
      "Epoch: 352\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87134772]\n",
      " [0.84598734]\n",
      " [0.88819864]]\n",
      "Loss: \n",
      " 0.0008555479829826348\n",
      "\n",
      "\n",
      "Epoch: 353\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8714572 ]\n",
      " [0.84609747]\n",
      " [0.88830246]]\n",
      "Loss: \n",
      " 0.0008508549930101708\n",
      "\n",
      "\n",
      "Epoch: 354\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87156602]\n",
      " [0.84620693]\n",
      " [0.88840563]]\n",
      "Loss: \n",
      " 0.0008462138448339825\n",
      "\n",
      "\n",
      "Epoch: 355\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87167416]\n",
      " [0.84631573]\n",
      " [0.88850814]]\n",
      "Loss: \n",
      " 0.0008416238782578061\n",
      "\n",
      "\n",
      "Epoch: 356\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87178164]\n",
      " [0.84642387]\n",
      " [0.88861001]]\n",
      "Loss: \n",
      " 0.000837084442846329\n",
      "\n",
      "\n",
      "Epoch: 357\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87188847]\n",
      " [0.84653136]\n",
      " [0.88871124]]\n",
      "Loss: \n",
      " 0.0008325948977580991\n",
      "\n",
      "\n",
      "Epoch: 358\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87199464]\n",
      " [0.8466382 ]\n",
      " [0.88881183]]\n",
      "Loss: \n",
      " 0.0008281546115817012\n",
      "\n",
      "\n",
      "Epoch: 359\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87210017]\n",
      " [0.84674439]\n",
      " [0.88891179]]\n",
      "Loss: \n",
      " 0.0008237629621751502\n",
      "\n",
      "\n",
      "Epoch: 360\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87220506]\n",
      " [0.84684995]\n",
      " [0.88901112]]\n",
      "Loss: \n",
      " 0.0008194193365084301\n",
      "\n",
      "\n",
      "Epoch: 361\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87230931]\n",
      " [0.84695488]\n",
      " [0.88910984]]\n",
      "Loss: \n",
      " 0.0008151231305090711\n",
      "\n",
      "\n",
      "Epoch: 362\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87241293]\n",
      " [0.84705918]\n",
      " [0.88920794]]\n",
      "Loss: \n",
      " 0.0008108737489107653\n",
      "\n",
      "\n",
      "Epoch: 363\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87251593]\n",
      " [0.84716286]\n",
      " [0.88930543]]\n",
      "Loss: \n",
      " 0.0008066706051048281\n",
      "\n",
      "\n",
      "Epoch: 364\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8726183 ]\n",
      " [0.84726592]\n",
      " [0.88940232]]\n",
      "Loss: \n",
      " 0.0008025131209946306\n",
      "\n",
      "\n",
      "Epoch: 365\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87272006]\n",
      " [0.84736837]\n",
      " [0.88949861]]\n",
      "Loss: \n",
      " 0.0007984007268527607\n",
      "\n",
      "\n",
      "Epoch: 366\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87282121]\n",
      " [0.84747022]\n",
      " [0.8895943 ]]\n",
      "Loss: \n",
      " 0.0007943328611809654\n",
      "\n",
      "\n",
      "Epoch: 367\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87292175]\n",
      " [0.84757146]\n",
      " [0.8896894 ]]\n",
      "Loss: \n",
      " 0.0007903089705727562\n",
      "\n",
      "\n",
      "Epoch: 368\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87302169]\n",
      " [0.8476721 ]\n",
      " [0.88978392]]\n",
      "Loss: \n",
      " 0.0007863285095786435\n",
      "\n",
      "\n",
      "Epoch: 369\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87312103]\n",
      " [0.84777214]\n",
      " [0.88987785]]\n",
      "Loss: \n",
      " 0.0007823909405739594\n",
      "\n",
      "\n",
      "Epoch: 370\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87321979]\n",
      " [0.8478716 ]\n",
      " [0.88997121]]\n",
      "Loss: \n",
      " 0.0007784957336291503\n",
      "\n",
      "\n",
      "Epoch: 371\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87331795]\n",
      " [0.84797048]\n",
      " [0.890064  ]]\n",
      "Loss: \n",
      " 0.0007746423663825814\n",
      "\n",
      "\n",
      "Epoch: 372\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87341554]\n",
      " [0.84806877]\n",
      " [0.89015622]]\n",
      "Loss: \n",
      " 0.0007708303239157094\n",
      "\n",
      "\n",
      "Epoch: 373\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87351254]\n",
      " [0.84816649]\n",
      " [0.89024788]]\n",
      "Loss: \n",
      " 0.000767059098630635\n",
      "\n",
      "\n",
      "Epoch: 374\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87360897]\n",
      " [0.84826364]\n",
      " [0.89033898]]\n",
      "Loss: \n",
      " 0.0007633281901299289\n",
      "\n",
      "\n",
      "Epoch: 375\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87370483]\n",
      " [0.84836022]\n",
      " [0.89042953]]\n",
      "Loss: \n",
      " 0.0007596371050987409\n",
      "\n",
      "\n",
      "Epoch: 376\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87380013]\n",
      " [0.84845624]\n",
      " [0.89051953]]\n",
      "Loss: \n",
      " 0.0007559853571891176\n",
      "\n",
      "\n",
      "Epoch: 377\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87389487]\n",
      " [0.8485517 ]\n",
      " [0.89060899]]\n",
      "Loss: \n",
      " 0.0007523724669064677\n",
      "\n",
      "\n",
      "Epoch: 378\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87398905]\n",
      " [0.8486466 ]\n",
      " [0.8906979 ]]\n",
      "Loss: \n",
      " 0.0007487979614981443\n",
      "\n",
      "\n",
      "Epoch: 379\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87408268]\n",
      " [0.84874096]\n",
      " [0.89078628]]\n",
      "Loss: \n",
      " 0.0007452613748441065\n",
      "\n",
      "\n",
      "Epoch: 380\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87417577]\n",
      " [0.84883477]\n",
      " [0.89087413]]\n",
      "Loss: \n",
      " 0.0007417622473496064\n",
      "\n",
      "\n",
      "Epoch: 381\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87426831]\n",
      " [0.84892804]\n",
      " [0.89096145]]\n",
      "Loss: \n",
      " 0.0007383001258398487\n",
      "\n",
      "\n",
      "Epoch: 382\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87436031]\n",
      " [0.84902078]\n",
      " [0.89104824]]\n",
      "Loss: \n",
      " 0.0007348745634566204\n",
      "\n",
      "\n",
      "Epoch: 383\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87445177]\n",
      " [0.84911297]\n",
      " [0.89113452]]\n",
      "Loss: \n",
      " 0.0007314851195567941\n",
      "\n",
      "\n",
      "Epoch: 384\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87454271]\n",
      " [0.84920464]\n",
      " [0.89122028]]\n",
      "Loss: \n",
      " 0.0007281313596127216\n",
      "\n",
      "\n",
      "Epoch: 385\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87463312]\n",
      " [0.84929579]\n",
      " [0.89130553]]\n",
      "Loss: \n",
      " 0.0007248128551144269\n",
      "\n",
      "\n",
      "Epoch: 386\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.874723  ]\n",
      " [0.84938641]\n",
      " [0.89139027]]\n",
      "Loss: \n",
      " 0.0007215291834736016\n",
      "\n",
      "\n",
      "Epoch: 387\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87481237]\n",
      " [0.84947652]\n",
      " [0.89147451]]\n",
      "Loss: \n",
      " 0.0007182799279293659\n",
      "\n",
      "\n",
      "Epoch: 388\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87490122]\n",
      " [0.84956611]\n",
      " [0.89155825]]\n",
      "Loss: \n",
      " 0.000715064677455702\n",
      "\n",
      "\n",
      "Epoch: 389\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87498956]\n",
      " [0.84965519]\n",
      " [0.8916415 ]]\n",
      "Loss: \n",
      " 0.0007118830266705883\n",
      "\n",
      "\n",
      "Epoch: 390\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8750774 ]\n",
      " [0.84974376]\n",
      " [0.89172425]]\n",
      "Loss: \n",
      " 0.0007087345757468276\n",
      "\n",
      "\n",
      "Epoch: 391\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87516473]\n",
      " [0.84983184]\n",
      " [0.89180651]]\n",
      "Loss: \n",
      " 0.0007056189303243616\n",
      "\n",
      "\n",
      "Epoch: 392\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87525156]\n",
      " [0.84991941]\n",
      " [0.89188829]]\n",
      "Loss: \n",
      " 0.0007025357014243161\n",
      "\n",
      "\n",
      "Epoch: 393\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87533789]\n",
      " [0.85000649]\n",
      " [0.89196959]]\n",
      "Loss: \n",
      " 0.0006994845053644819\n",
      "\n",
      "\n",
      "Epoch: 394\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87542373]\n",
      " [0.85009308]\n",
      " [0.89205041]]\n",
      "Loss: \n",
      " 0.0006964649636763412\n",
      "\n",
      "\n",
      "Epoch: 395\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87550909]\n",
      " [0.85017917]\n",
      " [0.89213076]]\n",
      "Loss: \n",
      " 0.0006934767030235893\n",
      "\n",
      "\n",
      "Epoch: 396\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87559396]\n",
      " [0.85026479]\n",
      " [0.89221064]]\n",
      "Loss: \n",
      " 0.0006905193551221324\n",
      "\n",
      "\n",
      "Epoch: 397\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87567834]\n",
      " [0.85034992]\n",
      " [0.89229005]]\n",
      "Loss: \n",
      " 0.0006875925566614239\n",
      "\n",
      "\n",
      "Epoch: 398\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87576225]\n",
      " [0.85043458]\n",
      " [0.892369  ]]\n",
      "Loss: \n",
      " 0.0006846959492273127\n",
      "\n",
      "\n",
      "Epoch: 399\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87584569]\n",
      " [0.85051876]\n",
      " [0.89244749]]\n",
      "Loss: \n",
      " 0.0006818291792261725\n",
      "\n",
      "\n",
      "Epoch: 400\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87592865]\n",
      " [0.85060247]\n",
      " [0.89252552]]\n",
      "Loss: \n",
      " 0.0006789918978104014\n",
      "\n",
      "\n",
      "Epoch: 401\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87601115]\n",
      " [0.85068572]\n",
      " [0.8926031 ]]\n",
      "Loss: \n",
      " 0.0006761837608052437\n",
      "\n",
      "\n",
      "Epoch: 402\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87609318]\n",
      " [0.8507685 ]\n",
      " [0.89268023]]\n",
      "Loss: \n",
      " 0.0006734044286368814\n",
      "\n",
      "\n",
      "Epoch: 403\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87617475]\n",
      " [0.85085082]\n",
      " [0.89275692]]\n",
      "Loss: \n",
      " 0.0006706535662618203\n",
      "\n",
      "\n",
      "Epoch: 404\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87625586]\n",
      " [0.85093268]\n",
      " [0.89283316]]\n",
      "Loss: \n",
      " 0.0006679308430974628\n",
      "\n",
      "\n",
      "Epoch: 405\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87633652]\n",
      " [0.85101409]\n",
      " [0.89290896]]\n",
      "Loss: \n",
      " 0.0006652359329539413\n",
      "\n",
      "\n",
      "Epoch: 406\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87641673]\n",
      " [0.85109505]\n",
      " [0.89298433]]\n",
      "Loss: \n",
      " 0.00066256851396711\n",
      "\n",
      "\n",
      "Epoch: 407\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8764965 ]\n",
      " [0.85117556]\n",
      " [0.89305927]]\n",
      "Loss: \n",
      " 0.000659928268532724\n",
      "\n",
      "\n",
      "Epoch: 408\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87657581]\n",
      " [0.85125562]\n",
      " [0.89313377]]\n",
      "Loss: \n",
      " 0.0006573148832417393\n",
      "\n",
      "\n",
      "Epoch: 409\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87665469]\n",
      " [0.85133525]\n",
      " [0.89320785]]\n",
      "Loss: \n",
      " 0.0006547280488167583\n",
      "\n",
      "\n",
      "Epoch: 410\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87673313]\n",
      " [0.85141443]\n",
      " [0.89328151]]\n",
      "Loss: \n",
      " 0.0006521674600495348\n",
      "\n",
      "\n",
      "Epoch: 411\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87681113]\n",
      " [0.85149318]\n",
      " [0.89335474]]\n",
      "Loss: \n",
      " 0.000649632815739609\n",
      "\n",
      "\n",
      "Epoch: 412\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87688871]\n",
      " [0.8515715 ]\n",
      " [0.89342756]]\n",
      "Loss: \n",
      " 0.0006471238186339675\n",
      "\n",
      "\n",
      "Epoch: 413\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87696585]\n",
      " [0.85164939]\n",
      " [0.89349997]]\n",
      "Loss: \n",
      " 0.0006446401753677032\n",
      "\n",
      "\n",
      "Epoch: 414\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87704257]\n",
      " [0.85172686]\n",
      " [0.89357196]]\n",
      "Loss: \n",
      " 0.0006421815964057781\n",
      "\n",
      "\n",
      "Epoch: 415\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87711886]\n",
      " [0.8518039 ]\n",
      " [0.89364355]]\n",
      "Loss: \n",
      " 0.0006397477959857086\n",
      "\n",
      "\n",
      "Epoch: 416\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87719474]\n",
      " [0.85188052]\n",
      " [0.89371473]]\n",
      "Loss: \n",
      " 0.0006373384920612642\n",
      "\n",
      "\n",
      "Epoch: 417\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8772702 ]\n",
      " [0.85195673]\n",
      " [0.89378551]]\n",
      "Loss: \n",
      " 0.0006349534062470797\n",
      "\n",
      "\n",
      "Epoch: 418\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87734524]\n",
      " [0.85203252]\n",
      " [0.89385588]]\n",
      "Loss: \n",
      " 0.0006325922637642828\n",
      "\n",
      "\n",
      "Epoch: 419\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87741988]\n",
      " [0.85210789]\n",
      " [0.89392587]]\n",
      "Loss: \n",
      " 0.0006302547933869732\n",
      "\n",
      "\n",
      "Epoch: 420\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87749411]\n",
      " [0.85218286]\n",
      " [0.89399545]]\n",
      "Loss: \n",
      " 0.0006279407273896363\n",
      "\n",
      "\n",
      "Epoch: 421\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87756793]\n",
      " [0.85225743]\n",
      " [0.89406465]]\n",
      "Loss: \n",
      " 0.0006256498014954396\n",
      "\n",
      "\n",
      "Epoch: 422\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87764135]\n",
      " [0.85233159]\n",
      " [0.89413346]]\n",
      "Loss: \n",
      " 0.0006233817548253911\n",
      "\n",
      "\n",
      "Epoch: 423\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87771437]\n",
      " [0.85240535]\n",
      " [0.89420189]]\n",
      "Loss: \n",
      " 0.00062113632984838\n",
      "\n",
      "\n",
      "Epoch: 424\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87778699]\n",
      " [0.85247871]\n",
      " [0.89426993]]\n",
      "Loss: \n",
      " 0.0006189132723320087\n",
      "\n",
      "\n",
      "Epoch: 425\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87785923]\n",
      " [0.85255168]\n",
      " [0.89433759]]\n",
      "Loss: \n",
      " 0.0006167123312942728\n",
      "\n",
      "\n",
      "Epoch: 426\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87793106]\n",
      " [0.85262426]\n",
      " [0.89440488]]\n",
      "Loss: \n",
      " 0.0006145332589560666\n",
      "\n",
      "\n",
      "Epoch: 427\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87800252]\n",
      " [0.85269645]\n",
      " [0.89447179]]\n",
      "Loss: \n",
      " 0.0006123758106944386\n",
      "\n",
      "\n",
      "Epoch: 428\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87807358]\n",
      " [0.85276825]\n",
      " [0.89453832]]\n",
      "Loss: \n",
      " 0.0006102397449966325\n",
      "\n",
      "\n",
      "Epoch: 429\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87814426]\n",
      " [0.85283967]\n",
      " [0.89460449]]\n",
      "Loss: \n",
      " 0.0006081248234149194\n",
      "\n",
      "\n",
      "Epoch: 430\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87821456]\n",
      " [0.8529107 ]\n",
      " [0.8946703 ]]\n",
      "Loss: \n",
      " 0.000606030810522149\n",
      "\n",
      "\n",
      "Epoch: 431\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87828449]\n",
      " [0.85298136]\n",
      " [0.89473573]]\n",
      "Loss: \n",
      " 0.0006039574738680416\n",
      "\n",
      "\n",
      "Epoch: 432\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87835404]\n",
      " [0.85305164]\n",
      " [0.89480081]]\n",
      "Loss: \n",
      " 0.0006019045839361862\n",
      "\n",
      "\n",
      "Epoch: 433\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87842321]\n",
      " [0.85312154]\n",
      " [0.89486553]]\n",
      "Loss: \n",
      " 0.0005998719141017834\n",
      "\n",
      "\n",
      "Epoch: 434\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87849202]\n",
      " [0.85319108]\n",
      " [0.89492989]]\n",
      "Loss: \n",
      " 0.0005978592405900311\n",
      "\n",
      "\n",
      "Epoch: 435\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87856046]\n",
      " [0.85326024]\n",
      " [0.8949939 ]]\n",
      "Loss: \n",
      " 0.0005958663424352355\n",
      "\n",
      "\n",
      "Epoch: 436\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87862853]\n",
      " [0.85332904]\n",
      " [0.89505756]]\n",
      "Loss: \n",
      " 0.0005938930014405491\n",
      "\n",
      "\n",
      "Epoch: 437\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87869624]\n",
      " [0.85339748]\n",
      " [0.89512086]]\n",
      "Loss: \n",
      " 0.000591939002138411\n",
      "\n",
      "\n",
      "Epoch: 438\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87876359]\n",
      " [0.85346555]\n",
      " [0.89518382]]\n",
      "Loss: \n",
      " 0.000590004131751584\n",
      "\n",
      "\n",
      "Epoch: 439\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87883058]\n",
      " [0.85353327]\n",
      " [0.89524644]]\n",
      "Loss: \n",
      " 0.0005880881801548433\n",
      "\n",
      "\n",
      "Epoch: 440\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87889722]\n",
      " [0.85360062]\n",
      " [0.89530871]]\n",
      "Loss: \n",
      " 0.0005861909398373078\n",
      "\n",
      "\n",
      "Epoch: 441\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87896351]\n",
      " [0.85366763]\n",
      " [0.89537065]]\n",
      "Loss: \n",
      " 0.0005843122058653362\n",
      "\n",
      "\n",
      "Epoch: 442\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87902944]\n",
      " [0.85373428]\n",
      " [0.89543224]]\n",
      "Loss: \n",
      " 0.0005824517758460446\n",
      "\n",
      "\n",
      "Epoch: 443\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87909503]\n",
      " [0.85380058]\n",
      " [0.8954935 ]]\n",
      "Loss: \n",
      " 0.0005806094498914296\n",
      "\n",
      "\n",
      "Epoch: 444\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87916026]\n",
      " [0.85386653]\n",
      " [0.89555443]]\n",
      "Loss: \n",
      " 0.0005787850305830357\n",
      "\n",
      "\n",
      "Epoch: 445\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87922516]\n",
      " [0.85393214]\n",
      " [0.89561503]]\n",
      "Loss: \n",
      " 0.0005769783229371848\n",
      "\n",
      "\n",
      "Epoch: 446\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87928972]\n",
      " [0.85399741]\n",
      " [0.8956753 ]]\n",
      "Loss: \n",
      " 0.0005751891343707983\n",
      "\n",
      "\n",
      "Epoch: 447\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87935393]\n",
      " [0.85406234]\n",
      " [0.89573525]]\n",
      "Loss: \n",
      " 0.0005734172746677495\n",
      "\n",
      "\n",
      "Epoch: 448\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87941781]\n",
      " [0.85412692]\n",
      " [0.89579487]]\n",
      "Loss: \n",
      " 0.0005716625559457176\n",
      "\n",
      "\n",
      "Epoch: 449\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87948135]\n",
      " [0.85419117]\n",
      " [0.89585417]]\n",
      "Loss: \n",
      " 0.0005699247926236171\n",
      "\n",
      "\n",
      "Epoch: 450\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87954457]\n",
      " [0.85425509]\n",
      " [0.89591315]]\n",
      "Loss: \n",
      " 0.0005682038013895247\n",
      "\n",
      "\n",
      "Epoch: 451\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87960745]\n",
      " [0.85431868]\n",
      " [0.89597181]]\n",
      "Loss: \n",
      " 0.0005664994011690961\n",
      "\n",
      "\n",
      "Epoch: 452\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87967   ]\n",
      " [0.85438193]\n",
      " [0.89603016]]\n",
      "Loss: \n",
      " 0.0005648114130945155\n",
      "\n",
      "\n",
      "Epoch: 453\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87973223]\n",
      " [0.85444486]\n",
      " [0.89608819]]\n",
      "Loss: \n",
      " 0.0005631396604739079\n",
      "\n",
      "\n",
      "Epoch: 454\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87979413]\n",
      " [0.85450746]\n",
      " [0.89614591]]\n",
      "Loss: \n",
      " 0.0005614839687612414\n",
      "\n",
      "\n",
      "Epoch: 455\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87985572]\n",
      " [0.85456974]\n",
      " [0.89620333]]\n",
      "Loss: \n",
      " 0.0005598441655267024\n",
      "\n",
      "\n",
      "Epoch: 456\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87991698]\n",
      " [0.8546317 ]\n",
      " [0.89626043]]\n",
      "Loss: \n",
      " 0.0005582200804275339\n",
      "\n",
      "\n",
      "Epoch: 457\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87997793]\n",
      " [0.85469333]\n",
      " [0.89631724]]\n",
      "Loss: \n",
      " 0.0005566115451793274\n",
      "\n",
      "\n",
      "Epoch: 458\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88003856]\n",
      " [0.85475466]\n",
      " [0.89637374]]\n",
      "Loss: \n",
      " 0.0005550183935277745\n",
      "\n",
      "\n",
      "Epoch: 459\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88009887]\n",
      " [0.85481566]\n",
      " [0.89642993]]\n",
      "Loss: \n",
      " 0.0005534404612208446\n",
      "\n",
      "\n",
      "Epoch: 460\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88015888]\n",
      " [0.85487635]\n",
      " [0.89648584]]\n",
      "Loss: \n",
      " 0.0005518775859813892\n",
      "\n",
      "\n",
      "Epoch: 461\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88021858]\n",
      " [0.85493674]\n",
      " [0.89654144]]\n",
      "Loss: \n",
      " 0.0005503296074802049\n",
      "\n",
      "\n",
      "Epoch: 462\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88027796]\n",
      " [0.85499681]\n",
      " [0.89659675]]\n",
      "Loss: \n",
      " 0.0005487963673094691\n",
      "\n",
      "\n",
      "Epoch: 463\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88033705]\n",
      " [0.85505657]\n",
      " [0.89665176]]\n",
      "Loss: \n",
      " 0.00054727770895661\n",
      "\n",
      "\n",
      "Epoch: 464\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88039583]\n",
      " [0.85511603]\n",
      " [0.89670649]]\n",
      "Loss: \n",
      " 0.0005457734777785936\n",
      "\n",
      "\n",
      "Epoch: 465\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88045431]\n",
      " [0.85517519]\n",
      " [0.89676092]]\n",
      "Loss: \n",
      " 0.000544283520976563\n",
      "\n",
      "\n",
      "Epoch: 466\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88051249]\n",
      " [0.85523405]\n",
      " [0.89681507]]\n",
      "Loss: \n",
      " 0.000542807687570917\n",
      "\n",
      "\n",
      "Epoch: 467\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88057037]\n",
      " [0.8552926 ]\n",
      " [0.89686893]]\n",
      "Loss: \n",
      " 0.0005413458283767357\n",
      "\n",
      "\n",
      "Epoch: 468\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88062796]\n",
      " [0.85535086]\n",
      " [0.89692251]]\n",
      "Loss: \n",
      " 0.0005398977959796015\n",
      "\n",
      "\n",
      "Epoch: 469\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88068525]\n",
      " [0.85540882]\n",
      " [0.89697581]]\n",
      "Loss: \n",
      " 0.0005384634447117598\n",
      "\n",
      "\n",
      "Epoch: 470\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88074225]\n",
      " [0.85546649]\n",
      " [0.89702883]]\n",
      "Loss: \n",
      " 0.0005370426306287026\n",
      "\n",
      "\n",
      "Epoch: 471\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88079896]\n",
      " [0.85552387]\n",
      " [0.89708157]]\n",
      "Loss: \n",
      " 0.0005356352114860289\n",
      "\n",
      "\n",
      "Epoch: 472\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88085539]\n",
      " [0.85558095]\n",
      " [0.89713403]]\n",
      "Loss: \n",
      " 0.0005342410467167262\n",
      "\n",
      "\n",
      "Epoch: 473\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88091152]\n",
      " [0.85563775]\n",
      " [0.89718622]]\n",
      "Loss: \n",
      " 0.0005328599974087673\n",
      "\n",
      "\n",
      "Epoch: 474\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88096738]\n",
      " [0.85569426]\n",
      " [0.89723814]]\n",
      "Loss: \n",
      " 0.0005314919262830215\n",
      "\n",
      "\n",
      "Epoch: 475\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88102295]\n",
      " [0.85575049]\n",
      " [0.89728979]]\n",
      "Loss: \n",
      " 0.0005301366976715508\n",
      "\n",
      "\n",
      "Epoch: 476\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88107823]\n",
      " [0.85580643]\n",
      " [0.89734116]]\n",
      "Loss: \n",
      " 0.000528794177496195\n",
      "\n",
      "\n",
      "Epoch: 477\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88113324]\n",
      " [0.85586209]\n",
      " [0.89739227]]\n",
      "Loss: \n",
      " 0.0005274642332474944\n",
      "\n",
      "\n",
      "Epoch: 478\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88118798]\n",
      " [0.85591747]\n",
      " [0.89744312]]\n",
      "Loss: \n",
      " 0.0005261467339639158\n",
      "\n",
      "\n",
      "Epoch: 479\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88124243]\n",
      " [0.85597258]\n",
      " [0.89749369]]\n",
      "Loss: \n",
      " 0.000524841550211411\n",
      "\n",
      "\n",
      "Epoch: 480\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88129661]\n",
      " [0.85602741]\n",
      " [0.89754401]]\n",
      "Loss: \n",
      " 0.0005235485540632542\n",
      "\n",
      "\n",
      "Epoch: 481\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88135052]\n",
      " [0.85608196]\n",
      " [0.89759407]]\n",
      "Loss: \n",
      " 0.0005222676190802029\n",
      "\n",
      "\n",
      "Epoch: 482\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88140416]\n",
      " [0.85613624]\n",
      " [0.89764387]]\n",
      "Loss: \n",
      " 0.000520998620290949\n",
      "\n",
      "\n",
      "Epoch: 483\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88145753]\n",
      " [0.85619025]\n",
      " [0.89769341]]\n",
      "Loss: \n",
      " 0.0005197414341728606\n",
      "\n",
      "\n",
      "Epoch: 484\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88151064]\n",
      " [0.85624399]\n",
      " [0.89774269]]\n",
      "Loss: \n",
      " 0.0005184959386329835\n",
      "\n",
      "\n",
      "Epoch: 485\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88156348]\n",
      " [0.85629746]\n",
      " [0.89779172]]\n",
      "Loss: \n",
      " 0.000517262012989365\n",
      "\n",
      "\n",
      "Epoch: 486\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88161605]\n",
      " [0.85635067]\n",
      " [0.8978405 ]]\n",
      "Loss: \n",
      " 0.0005160395379526406\n",
      "\n",
      "\n",
      "Epoch: 487\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88166836]\n",
      " [0.85640361]\n",
      " [0.89788902]]\n",
      "Loss: \n",
      " 0.0005148283956078801\n",
      "\n",
      "\n",
      "Epoch: 488\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88172041]\n",
      " [0.85645629]\n",
      " [0.8979373 ]]\n",
      "Loss: \n",
      " 0.0005136284693966959\n",
      "\n",
      "\n",
      "Epoch: 489\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88177221]\n",
      " [0.85650871]\n",
      " [0.89798533]]\n",
      "Loss: \n",
      " 0.0005124396440996575\n",
      "\n",
      "\n",
      "Epoch: 490\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88182374]\n",
      " [0.85656086]\n",
      " [0.89803311]]\n",
      "Loss: \n",
      " 0.0005112618058189035\n",
      "\n",
      "\n",
      "Epoch: 491\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88187502]\n",
      " [0.85661276]\n",
      " [0.89808065]]\n",
      "Loss: \n",
      " 0.0005100948419610479\n",
      "\n",
      "\n",
      "Epoch: 492\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88192604]\n",
      " [0.8566644 ]\n",
      " [0.89812795]]\n",
      "Loss: \n",
      " 0.0005089386412203355\n",
      "\n",
      "\n",
      "Epoch: 493\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88197681]\n",
      " [0.85671579]\n",
      " [0.898175  ]]\n",
      "Loss: \n",
      " 0.0005077930935620242\n",
      "\n",
      "\n",
      "Epoch: 494\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88202734]\n",
      " [0.85676693]\n",
      " [0.89822181]]\n",
      "Loss: \n",
      " 0.0005066580902060265\n",
      "\n",
      "\n",
      "Epoch: 495\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88207761]\n",
      " [0.85681781]\n",
      " [0.89826839]]\n",
      "Loss: \n",
      " 0.0005055335236107743\n",
      "\n",
      "\n",
      "Epoch: 496\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88212763]\n",
      " [0.85686844]\n",
      " [0.89831473]]\n",
      "Loss: \n",
      " 0.0005044192874573331\n",
      "\n",
      "\n",
      "Epoch: 497\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8821774 ]\n",
      " [0.85691882]\n",
      " [0.89836083]]\n",
      "Loss: \n",
      " 0.0005033152766337223\n",
      "\n",
      "\n",
      "Epoch: 498\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88222694]\n",
      " [0.85696896]\n",
      " [0.89840669]]\n",
      "Loss: \n",
      " 0.0005022213872195113\n",
      "\n",
      "\n",
      "Epoch: 499\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88227622]\n",
      " [0.85701885]\n",
      " [0.89845233]]\n",
      "Loss: \n",
      " 0.00050113751647057\n",
      "\n",
      "\n",
      "Epoch: 500\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88232527]\n",
      " [0.85706849]\n",
      " [0.89849773]]\n",
      "Loss: \n",
      " 0.0005000635628040983\n",
      "\n",
      "\n",
      "Epoch: 501\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88237407]\n",
      " [0.85711789]\n",
      " [0.89854291]]\n",
      "Loss: \n",
      " 0.0004989994257838333\n",
      "\n",
      "\n",
      "Epoch: 502\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88242264]\n",
      " [0.85716705]\n",
      " [0.89858785]]\n",
      "Loss: \n",
      " 0.0004979450061054837\n",
      "\n",
      "\n",
      "Epoch: 503\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88247096]\n",
      " [0.85721597]\n",
      " [0.89863257]]\n",
      "Loss: \n",
      " 0.0004969002055823828\n",
      "\n",
      "\n",
      "Epoch: 504\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88251905]\n",
      " [0.85726465]\n",
      " [0.89867706]]\n",
      "Loss: \n",
      " 0.0004958649271313227\n",
      "\n",
      "\n",
      "Epoch: 505\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88256691]\n",
      " [0.85731309]\n",
      " [0.89872132]]\n",
      "Loss: \n",
      " 0.0004948390747586182\n",
      "\n",
      "\n",
      "Epoch: 506\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88261453]\n",
      " [0.8573613 ]\n",
      " [0.89876537]]\n",
      "Loss: \n",
      " 0.000493822553546339\n",
      "\n",
      "\n",
      "Epoch: 507\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88266192]\n",
      " [0.85740927]\n",
      " [0.89880919]]\n",
      "Loss: \n",
      " 0.0004928152696387553\n",
      "\n",
      "\n",
      "Epoch: 508\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88270908]\n",
      " [0.85745701]\n",
      " [0.89885279]]\n",
      "Loss: \n",
      " 0.0004918171302289987\n",
      "\n",
      "\n",
      "Epoch: 509\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88275601]\n",
      " [0.85750452]\n",
      " [0.89889618]]\n",
      "Loss: \n",
      " 0.0004908280435458498\n",
      "\n",
      "\n",
      "Epoch: 510\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88280271]\n",
      " [0.8575518 ]\n",
      " [0.89893934]]\n",
      "Loss: \n",
      " 0.0004898479188407823\n",
      "\n",
      "\n",
      "Epoch: 511\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88284919]\n",
      " [0.85759884]\n",
      " [0.89898229]]\n",
      "Loss: \n",
      " 0.0004888766663751504\n",
      "\n",
      "\n",
      "Epoch: 512\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88289544]\n",
      " [0.85764566]\n",
      " [0.89902502]]\n",
      "Loss: \n",
      " 0.0004879141974075527\n",
      "\n",
      "\n",
      "Epoch: 513\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88294146]\n",
      " [0.85769226]\n",
      " [0.89906754]]\n",
      "Loss: \n",
      " 0.0004869604241814021\n",
      "\n",
      "\n",
      "Epoch: 514\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88298726]\n",
      " [0.85773863]\n",
      " [0.89910985]]\n",
      "Loss: \n",
      " 0.00048601525991265473\n",
      "\n",
      "\n",
      "Epoch: 515\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88303285]\n",
      " [0.85778477]\n",
      " [0.89915195]]\n",
      "Loss: \n",
      " 0.00048507861877769885\n",
      "\n",
      "\n",
      "Epoch: 516\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88307821]\n",
      " [0.85783069]\n",
      " [0.89919383]]\n",
      "Loss: \n",
      " 0.0004841504159014452\n",
      "\n",
      "\n",
      "Epoch: 517\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88312335]\n",
      " [0.85787639]\n",
      " [0.89923551]]\n",
      "Loss: \n",
      " 0.00048323056734553456\n",
      "\n",
      "\n",
      "Epoch: 518\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88316827]\n",
      " [0.85792187]\n",
      " [0.89927698]]\n",
      "Loss: \n",
      " 0.00048231899009677873\n",
      "\n",
      "\n",
      "Epoch: 519\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88321298]\n",
      " [0.85796713]\n",
      " [0.89931824]]\n",
      "Loss: \n",
      " 0.00048141560205569974\n",
      "\n",
      "\n",
      "Epoch: 520\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88325748]\n",
      " [0.85801218]\n",
      " [0.8993593 ]]\n",
      "Loss: \n",
      " 0.00048052032202525424\n",
      "\n",
      "\n",
      "Epoch: 521\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88330176]\n",
      " [0.85805701]\n",
      " [0.89940016]]\n",
      "Loss: \n",
      " 0.000479633069699713\n",
      "\n",
      "\n",
      "Epoch: 522\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88334582]\n",
      " [0.85810162]\n",
      " [0.89944081]]\n",
      "Loss: \n",
      " 0.0004787537656537075\n",
      "\n",
      "\n",
      "Epoch: 523\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88338968]\n",
      " [0.85814602]\n",
      " [0.89948126]]\n",
      "Loss: \n",
      " 0.00047788233133140177\n",
      "\n",
      "\n",
      "Epoch: 524\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88343333]\n",
      " [0.85819021]\n",
      " [0.89952151]]\n",
      "Loss: \n",
      " 0.0004770186890358307\n",
      "\n",
      "\n",
      "Epoch: 525\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88347676]\n",
      " [0.85823418]\n",
      " [0.89956156]]\n",
      "Loss: \n",
      " 0.000476162761918385\n",
      "\n",
      "\n",
      "Epoch: 526\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88351999]\n",
      " [0.85827795]\n",
      " [0.89960142]]\n",
      "Loss: \n",
      " 0.0004753144739684343\n",
      "\n",
      "\n",
      "Epoch: 527\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88356302]\n",
      " [0.8583215 ]\n",
      " [0.89964107]]\n",
      "Loss: \n",
      " 0.0004744737500031036\n",
      "\n",
      "\n",
      "Epoch: 528\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88360584]\n",
      " [0.85836485]\n",
      " [0.89968053]]\n",
      "Loss: \n",
      " 0.0004736405156571682\n",
      "\n",
      "\n",
      "Epoch: 529\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88364845]\n",
      " [0.858408  ]\n",
      " [0.8997198 ]]\n",
      "Loss: \n",
      " 0.0004728146973731208\n",
      "\n",
      "\n",
      "Epoch: 530\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88369086]\n",
      " [0.85845093]\n",
      " [0.89975888]]\n",
      "Loss: \n",
      " 0.0004719962223913448\n",
      "\n",
      "\n",
      "Epoch: 531\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88373307]\n",
      " [0.85849367]\n",
      " [0.89979776]]\n",
      "Loss: \n",
      " 0.00047118501874043135\n",
      "\n",
      "\n",
      "Epoch: 532\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88377508]\n",
      " [0.8585362 ]\n",
      " [0.89983645]]\n",
      "Loss: \n",
      " 0.0004703810152276344\n",
      "\n",
      "\n",
      "Epoch: 533\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88381689]\n",
      " [0.85857853]\n",
      " [0.89987495]]\n",
      "Loss: \n",
      " 0.0004695841414294498\n",
      "\n",
      "\n",
      "Epoch: 534\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88385851]\n",
      " [0.85862065]\n",
      " [0.89991326]]\n",
      "Loss: \n",
      " 0.00046879432768232786\n",
      "\n",
      "\n",
      "Epoch: 535\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88389992]\n",
      " [0.85866258]\n",
      " [0.89995139]]\n",
      "Loss: \n",
      " 0.000468011505073493\n",
      "\n",
      "\n",
      "Epoch: 536\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88394114]\n",
      " [0.85870431]\n",
      " [0.89998933]]\n",
      "Loss: \n",
      " 0.00046723560543192777\n",
      "\n",
      "\n",
      "Epoch: 537\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88398216]\n",
      " [0.85874584]\n",
      " [0.90002708]]\n",
      "Loss: \n",
      " 0.000466466561319418\n",
      "\n",
      "\n",
      "Epoch: 538\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.884023  ]\n",
      " [0.85878718]\n",
      " [0.90006465]]\n",
      "Loss: \n",
      " 0.00046570430602179704\n",
      "\n",
      "\n",
      "Epoch: 539\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88406363]\n",
      " [0.85882832]\n",
      " [0.90010203]]\n",
      "Loss: \n",
      " 0.0004649487735402234\n",
      "\n",
      "\n",
      "Epoch: 540\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88410408]\n",
      " [0.85886927]\n",
      " [0.90013924]]\n",
      "Loss: \n",
      " 0.0004641998985826452\n",
      "\n",
      "\n",
      "Epoch: 541\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88414434]\n",
      " [0.85891002]\n",
      " [0.90017626]]\n",
      "Loss: \n",
      " 0.0004634576165553497\n",
      "\n",
      "\n",
      "Epoch: 542\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8841844 ]\n",
      " [0.85895059]\n",
      " [0.9002131 ]]\n",
      "Loss: \n",
      " 0.00046272186355460963\n",
      "\n",
      "\n",
      "Epoch: 543\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88422428]\n",
      " [0.85899096]\n",
      " [0.90024976]]\n",
      "Loss: \n",
      " 0.00046199257635847054\n",
      "\n",
      "\n",
      "Epoch: 544\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88426397]\n",
      " [0.85903114]\n",
      " [0.90028625]]\n",
      "Loss: \n",
      " 0.00046126969241865593\n",
      "\n",
      "\n",
      "Epoch: 545\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88430348]\n",
      " [0.85907113]\n",
      " [0.90032255]]\n",
      "Loss: \n",
      " 0.00046055314985252237\n",
      "\n",
      "\n",
      "Epoch: 546\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8843428 ]\n",
      " [0.85911094]\n",
      " [0.90035868]]\n",
      "Loss: \n",
      " 0.0004598428874351957\n",
      "\n",
      "\n",
      "Epoch: 547\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88438194]\n",
      " [0.85915056]\n",
      " [0.90039464]]\n",
      "Loss: \n",
      " 0.00045913884459176875\n",
      "\n",
      "\n",
      "Epoch: 548\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88442089]\n",
      " [0.85918999]\n",
      " [0.90043042]]\n",
      "Loss: \n",
      " 0.0004584409613895888\n",
      "\n",
      "\n",
      "Epoch: 549\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88445966]\n",
      " [0.85922924]\n",
      " [0.90046603]]\n",
      "Loss: \n",
      " 0.000457749178530706\n",
      "\n",
      "\n",
      "Epoch: 550\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88449825]\n",
      " [0.85926831]\n",
      " [0.90050147]]\n",
      "Loss: \n",
      " 0.00045706343734436397\n",
      "\n",
      "\n",
      "Epoch: 551\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88453666]\n",
      " [0.85930719]\n",
      " [0.90053673]]\n",
      "Loss: \n",
      " 0.00045638367977960623\n",
      "\n",
      "\n",
      "Epoch: 552\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88457489]\n",
      " [0.85934589]\n",
      " [0.90057183]]\n",
      "Loss: \n",
      " 0.00045570984839799394\n",
      "\n",
      "\n",
      "Epoch: 553\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88461295]\n",
      " [0.85938441]\n",
      " [0.90060676]]\n",
      "Loss: \n",
      " 0.0004550418863664284\n",
      "\n",
      "\n",
      "Epoch: 554\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88465082]\n",
      " [0.85942276]\n",
      " [0.90064151]]\n",
      "Loss: \n",
      " 0.00045437973745001054\n",
      "\n",
      "\n",
      "Epoch: 555\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88468853]\n",
      " [0.85946092]\n",
      " [0.9006761 ]]\n",
      "Loss: \n",
      " 0.00045372334600506293\n",
      "\n",
      "\n",
      "Epoch: 556\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88472605]\n",
      " [0.8594989 ]\n",
      " [0.90071053]]\n",
      "Loss: \n",
      " 0.0004530726569722103\n",
      "\n",
      "\n",
      "Epoch: 557\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8847634 ]\n",
      " [0.85953671]\n",
      " [0.90074479]]\n",
      "Loss: \n",
      " 0.0004524276158695596\n",
      "\n",
      "\n",
      "Epoch: 558\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88480058]\n",
      " [0.85957435]\n",
      " [0.90077888]]\n",
      "Loss: \n",
      " 0.0004517881687859464\n",
      "\n",
      "\n",
      "Epoch: 559\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88483759]\n",
      " [0.85961181]\n",
      " [0.90081281]]\n",
      "Loss: \n",
      " 0.00045115426237429205\n",
      "\n",
      "\n",
      "Epoch: 560\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88487442]\n",
      " [0.85964909]\n",
      " [0.90084658]]\n",
      "Loss: \n",
      " 0.00045052584384506627\n",
      "\n",
      "\n",
      "Epoch: 561\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88491109]\n",
      " [0.85968621]\n",
      " [0.90088019]]\n",
      "Loss: \n",
      " 0.00044990286095978336\n",
      "\n",
      "\n",
      "Epoch: 562\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88494759]\n",
      " [0.85972315]\n",
      " [0.90091363]]\n",
      "Loss: \n",
      " 0.0004492852620246156\n",
      "\n",
      "\n",
      "Epoch: 563\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88498391]\n",
      " [0.85975992]\n",
      " [0.90094692]]\n",
      "Loss: \n",
      " 0.00044867299588411\n",
      "\n",
      "\n",
      "Epoch: 564\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88502007]\n",
      " [0.85979652]\n",
      " [0.90098005]]\n",
      "Loss: \n",
      " 0.0004480660119149194\n",
      "\n",
      "\n",
      "Epoch: 565\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88505607]\n",
      " [0.85983295]\n",
      " [0.90101302]]\n",
      "Loss: \n",
      " 0.0004474642600196959\n",
      "\n",
      "\n",
      "Epoch: 566\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8850919 ]\n",
      " [0.85986922]\n",
      " [0.90104583]]\n",
      "Loss: \n",
      " 0.00044686769062100097\n",
      "\n",
      "\n",
      "Epoch: 567\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88512756]\n",
      " [0.85990531]\n",
      " [0.90107848]]\n",
      "Loss: \n",
      " 0.0004462762546553229\n",
      "\n",
      "\n",
      "Epoch: 568\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88516306]\n",
      " [0.85994124]\n",
      " [0.90111098]]\n",
      "Loss: \n",
      " 0.0004456899035671635\n",
      "\n",
      "\n",
      "Epoch: 569\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8851984 ]\n",
      " [0.85997701]\n",
      " [0.90114333]]\n",
      "Loss: \n",
      " 0.0004451085893032083\n",
      "\n",
      "\n",
      "Epoch: 570\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88523357]\n",
      " [0.86001261]\n",
      " [0.90117552]]\n",
      "Loss: \n",
      " 0.00044453226430655356\n",
      "\n",
      "\n",
      "Epoch: 571\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88526859]\n",
      " [0.86004805]\n",
      " [0.90120756]]\n",
      "Loss: \n",
      " 0.00044396088151103753\n",
      "\n",
      "\n",
      "Epoch: 572\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88530344]\n",
      " [0.86008332]\n",
      " [0.90123945]]\n",
      "Loss: \n",
      " 0.0004433943943356147\n",
      "\n",
      "\n",
      "Epoch: 573\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88533814]\n",
      " [0.86011843]\n",
      " [0.90127118]]\n",
      "Loss: \n",
      " 0.0004428327566788085\n",
      "\n",
      "\n",
      "Epoch: 574\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88537267]\n",
      " [0.86015339]\n",
      " [0.90130277]]\n",
      "Loss: \n",
      " 0.0004422759229132536\n",
      "\n",
      "\n",
      "Epoch: 575\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88540705]\n",
      " [0.86018818]\n",
      " [0.9013342 ]]\n",
      "Loss: \n",
      " 0.0004417238478802772\n",
      "\n",
      "\n",
      "Epoch: 576\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88544127]\n",
      " [0.86022281]\n",
      " [0.90136549]]\n",
      "Loss: \n",
      " 0.00044117648688457963\n",
      "\n",
      "\n",
      "Epoch: 577\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88547534]\n",
      " [0.86025728]\n",
      " [0.90139663]]\n",
      "Loss: \n",
      " 0.0004406337956889795\n",
      "\n",
      "\n",
      "Epoch: 578\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88550925]\n",
      " [0.8602916 ]\n",
      " [0.90142762]]\n",
      "Loss: \n",
      " 0.00044009573050917376\n",
      "\n",
      "\n",
      "Epoch: 579\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88554301]\n",
      " [0.86032576]\n",
      " [0.90145846]]\n",
      "Loss: \n",
      " 0.0004395622480086461\n",
      "\n",
      "\n",
      "Epoch: 580\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88557661]\n",
      " [0.86035976]\n",
      " [0.90148916]]\n",
      "Loss: \n",
      " 0.00043903330529357435\n",
      "\n",
      "\n",
      "Epoch: 581\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88561006]\n",
      " [0.86039361]\n",
      " [0.90151972]]\n",
      "Loss: \n",
      " 0.0004385088599078494\n",
      "\n",
      "\n",
      "Epoch: 582\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88564336]\n",
      " [0.86042731]\n",
      " [0.90155013]]\n",
      "Loss: \n",
      " 0.0004379888698281016\n",
      "\n",
      "\n",
      "Epoch: 583\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88567651]\n",
      " [0.86046085]\n",
      " [0.90158039]]\n",
      "Loss: \n",
      " 0.00043747329345885944\n",
      "\n",
      "\n",
      "Epoch: 584\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88570951]\n",
      " [0.86049424]\n",
      " [0.90161052]]\n",
      "Loss: \n",
      " 0.00043696208962770174\n",
      "\n",
      "\n",
      "Epoch: 585\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88574236]\n",
      " [0.86052748]\n",
      " [0.9016405 ]]\n",
      "Loss: \n",
      " 0.00043645521758050584\n",
      "\n",
      "\n",
      "Epoch: 586\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88577506]\n",
      " [0.86056056]\n",
      " [0.90167034]]\n",
      "Loss: \n",
      " 0.00043595263697677935\n",
      "\n",
      "\n",
      "Epoch: 587\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88580761]\n",
      " [0.8605935 ]\n",
      " [0.90170005]]\n",
      "Loss: \n",
      " 0.0004354543078849693\n",
      "\n",
      "\n",
      "Epoch: 588\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88584001]\n",
      " [0.86062629]\n",
      " [0.90172961]]\n",
      "Loss: \n",
      " 0.0004349601907779343\n",
      "\n",
      "\n",
      "Epoch: 589\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88587227]\n",
      " [0.86065892]\n",
      " [0.90175903]]\n",
      "Loss: \n",
      " 0.00043447024652838614\n",
      "\n",
      "\n",
      "Epoch: 590\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88590439]\n",
      " [0.86069142]\n",
      " [0.90178832]]\n",
      "Loss: \n",
      " 0.00043398443640443136\n",
      "\n",
      "\n",
      "Epoch: 591\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88593636]\n",
      " [0.86072376]\n",
      " [0.90181747]]\n",
      "Loss: \n",
      " 0.0004335027220651749\n",
      "\n",
      "\n",
      "Epoch: 592\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88596818]\n",
      " [0.86075596]\n",
      " [0.90184648]]\n",
      "Loss: \n",
      " 0.0004330250655563359\n",
      "\n",
      "\n",
      "Epoch: 593\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88599987]\n",
      " [0.86078801]\n",
      " [0.90187536]]\n",
      "Loss: \n",
      " 0.000432551429305959\n",
      "\n",
      "\n",
      "Epoch: 594\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88603141]\n",
      " [0.86081991]\n",
      " [0.9019041 ]]\n",
      "Loss: \n",
      " 0.00043208177612018777\n",
      "\n",
      "\n",
      "Epoch: 595\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88606281]\n",
      " [0.86085168]\n",
      " [0.90193271]]\n",
      "Loss: \n",
      " 0.00043161606917901913\n",
      "\n",
      "\n",
      "Epoch: 596\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88609406]\n",
      " [0.8608833 ]\n",
      " [0.90196119]]\n",
      "Loss: \n",
      " 0.0004311542720321976\n",
      "\n",
      "\n",
      "Epoch: 597\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88612518]\n",
      " [0.86091478]\n",
      " [0.90198953]]\n",
      "Loss: \n",
      " 0.00043069634859509934\n",
      "\n",
      "\n",
      "Epoch: 598\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88615616]\n",
      " [0.86094611]\n",
      " [0.90201774]]\n",
      "Loss: \n",
      " 0.0004302422631447147\n",
      "\n",
      "\n",
      "Epoch: 599\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.886187  ]\n",
      " [0.86097731]\n",
      " [0.90204582]]\n",
      "Loss: \n",
      " 0.0004297919803156194\n",
      "\n",
      "\n",
      "Epoch: 600\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8862177 ]\n",
      " [0.86100836]\n",
      " [0.90207377]]\n",
      "Loss: \n",
      " 0.00042934546509605935\n",
      "\n",
      "\n",
      "Epoch: 601\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88624827]\n",
      " [0.86103928]\n",
      " [0.90210159]]\n",
      "Loss: \n",
      " 0.00042890268282403423\n",
      "\n",
      "\n",
      "Epoch: 602\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88627869]\n",
      " [0.86107005]\n",
      " [0.90212928]]\n",
      "Loss: \n",
      " 0.0004284635991834657\n",
      "\n",
      "\n",
      "Epoch: 603\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88630899]\n",
      " [0.86110069]\n",
      " [0.90215684]]\n",
      "Loss: \n",
      " 0.00042802818020038456\n",
      "\n",
      "\n",
      "Epoch: 604\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88633915]\n",
      " [0.86113119]\n",
      " [0.90218427]]\n",
      "Loss: \n",
      " 0.0004275963922391712\n",
      "\n",
      "\n",
      "Epoch: 605\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88636917]\n",
      " [0.86116155]\n",
      " [0.90221158]]\n",
      "Loss: \n",
      " 0.0004271682019988653\n",
      "\n",
      "\n",
      "Epoch: 606\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88639906]\n",
      " [0.86119178]\n",
      " [0.90223876]]\n",
      "Loss: \n",
      " 0.00042674357650948077\n",
      "\n",
      "\n",
      "Epoch: 607\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88642882]\n",
      " [0.86122188]\n",
      " [0.90226581]]\n",
      "Loss: \n",
      " 0.0004263224831284049\n",
      "\n",
      "\n",
      "Epoch: 608\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88645844]\n",
      " [0.86125183]\n",
      " [0.90229274]]\n",
      "Loss: \n",
      " 0.00042590488953680447\n",
      "\n",
      "\n",
      "Epoch: 609\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88648793]\n",
      " [0.86128166]\n",
      " [0.90231954]]\n",
      "Loss: \n",
      " 0.000425490763736103\n",
      "\n",
      "\n",
      "Epoch: 610\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8865173 ]\n",
      " [0.86131135]\n",
      " [0.90234622]]\n",
      "Loss: \n",
      " 0.00042508007404449535\n",
      "\n",
      "\n",
      "Epoch: 611\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88654653]\n",
      " [0.86134091]\n",
      " [0.90237278]]\n",
      "Loss: \n",
      " 0.0004246727890934962\n",
      "\n",
      "\n",
      "Epoch: 612\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88657563]\n",
      " [0.86137034]\n",
      " [0.90239921]]\n",
      "Loss: \n",
      " 0.0004242688778245277\n",
      "\n",
      "\n",
      "Epoch: 613\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88660461]\n",
      " [0.86139963]\n",
      " [0.90242552]]\n",
      "Loss: \n",
      " 0.00042386830948556217\n",
      "\n",
      "\n",
      "Epoch: 614\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88663345]\n",
      " [0.8614288 ]\n",
      " [0.90245171]]\n",
      "Loss: \n",
      " 0.0004234710536278026\n",
      "\n",
      "\n",
      "Epoch: 615\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88666217]\n",
      " [0.86145783]\n",
      " [0.90247778]]\n",
      "Loss: \n",
      " 0.0004230770801023894\n",
      "\n",
      "\n",
      "Epoch: 616\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88669076]\n",
      " [0.86148674]\n",
      " [0.90250373]]\n",
      "Loss: \n",
      " 0.00042268635905715084\n",
      "\n",
      "\n",
      "Epoch: 617\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88671923]\n",
      " [0.86151552]\n",
      " [0.90252956]]\n",
      "Loss: \n",
      " 0.00042229886093342344\n",
      "\n",
      "\n",
      "Epoch: 618\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88674757]\n",
      " [0.86154417]\n",
      " [0.90255527]]\n",
      "Loss: \n",
      " 0.0004219145564628533\n",
      "\n",
      "\n",
      "Epoch: 619\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88677578]\n",
      " [0.86157269]\n",
      " [0.90258087]]\n",
      "Loss: \n",
      " 0.00042153341666428747\n",
      "\n",
      "\n",
      "Epoch: 620\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88680387]\n",
      " [0.86160109]\n",
      " [0.90260634]]\n",
      "Loss: \n",
      " 0.0004211554128406662\n",
      "\n",
      "\n",
      "Epoch: 621\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88683184]\n",
      " [0.86162936]\n",
      " [0.9026317 ]]\n",
      "Loss: \n",
      " 0.0004207805165759872\n",
      "\n",
      "\n",
      "Epoch: 622\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88685968]\n",
      " [0.86165751]\n",
      " [0.90265695]]\n",
      "Loss: \n",
      " 0.0004204086997322647\n",
      "\n",
      "\n",
      "Epoch: 623\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88688741]\n",
      " [0.86168553]\n",
      " [0.90268207]]\n",
      "Loss: \n",
      " 0.00042003993444657213\n",
      "\n",
      "\n",
      "Epoch: 624\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88691501]\n",
      " [0.86171342]\n",
      " [0.90270708]]\n",
      "Loss: \n",
      " 0.0004196741931280668\n",
      "\n",
      "\n",
      "Epoch: 625\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88694249]\n",
      " [0.8617412 ]\n",
      " [0.90273198]]\n",
      "Loss: \n",
      " 0.00041931144845509853\n",
      "\n",
      "\n",
      "Epoch: 626\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88696985]\n",
      " [0.86176885]\n",
      " [0.90275677]]\n",
      "Loss: \n",
      " 0.00041895167337232896\n",
      "\n",
      "\n",
      "Epoch: 627\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88699708]\n",
      " [0.86179638]\n",
      " [0.90278144]]\n",
      "Loss: \n",
      " 0.0004185948410878754\n",
      "\n",
      "\n",
      "Epoch: 628\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8870242 ]\n",
      " [0.86182378]\n",
      " [0.90280599]]\n",
      "Loss: \n",
      " 0.0004182409250705083\n",
      "\n",
      "\n",
      "Epoch: 629\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8870512 ]\n",
      " [0.86185107]\n",
      " [0.90283044]]\n",
      "Loss: \n",
      " 0.00041788989904688757\n",
      "\n",
      "\n",
      "Epoch: 630\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88707809]\n",
      " [0.86187824]\n",
      " [0.90285477]]\n",
      "Loss: \n",
      " 0.00041754173699878346\n",
      "\n",
      "\n",
      "Epoch: 631\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88710485]\n",
      " [0.86190528]\n",
      " [0.90287899]]\n",
      "Loss: \n",
      " 0.0004171964131604122\n",
      "\n",
      "\n",
      "Epoch: 632\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8871315 ]\n",
      " [0.86193221]\n",
      " [0.90290311]]\n",
      "Loss: \n",
      " 0.00041685390201570894\n",
      "\n",
      "\n",
      "Epoch: 633\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88715804]\n",
      " [0.86195902]\n",
      " [0.90292711]]\n",
      "Loss: \n",
      " 0.0004165141782957074\n",
      "\n",
      "\n",
      "Epoch: 634\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88718445]\n",
      " [0.86198571]\n",
      " [0.902951  ]]\n",
      "Loss: \n",
      " 0.000416177216975922\n",
      "\n",
      "\n",
      "Epoch: 635\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88721075]\n",
      " [0.86201229]\n",
      " [0.90297478]]\n",
      "Loss: \n",
      " 0.0004158429932737525\n",
      "\n",
      "\n",
      "Epoch: 636\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88723694]\n",
      " [0.86203874]\n",
      " [0.90299846]]\n",
      "Loss: \n",
      " 0.0004155114826459204\n",
      "\n",
      "\n",
      "Epoch: 637\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88726301]\n",
      " [0.86206508]\n",
      " [0.90302203]]\n",
      "Loss: \n",
      " 0.0004151826607859577\n",
      "\n",
      "\n",
      "Epoch: 638\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88728898]\n",
      " [0.86209131]\n",
      " [0.90304549]]\n",
      "Loss: \n",
      " 0.00041485650362170116\n",
      "\n",
      "\n",
      "Epoch: 639\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88731482]\n",
      " [0.86211742]\n",
      " [0.90306884]]\n",
      "Loss: \n",
      " 0.00041453298731283637\n",
      "\n",
      "\n",
      "Epoch: 640\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88734056]\n",
      " [0.86214342]\n",
      " [0.90309209]]\n",
      "Loss: \n",
      " 0.0004142120882484216\n",
      "\n",
      "\n",
      "Epoch: 641\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88736618]\n",
      " [0.8621693 ]\n",
      " [0.90311523]]\n",
      "Loss: \n",
      " 0.0004138937830445323\n",
      "\n",
      "\n",
      "Epoch: 642\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88739169]\n",
      " [0.86219507]\n",
      " [0.90313827]]\n",
      "Loss: \n",
      " 0.0004135780485418355\n",
      "\n",
      "\n",
      "Epoch: 643\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8874171 ]\n",
      " [0.86222072]\n",
      " [0.90316121]]\n",
      "Loss: \n",
      " 0.00041326486180324047\n",
      "\n",
      "\n",
      "Epoch: 644\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88744239]\n",
      " [0.86224627]\n",
      " [0.90318404]]\n",
      "Loss: \n",
      " 0.0004129542001115954\n",
      "\n",
      "\n",
      "Epoch: 645\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88746757]\n",
      " [0.8622717 ]\n",
      " [0.90320676]]\n",
      "Loss: \n",
      " 0.0004126460409673441\n",
      "\n",
      "\n",
      "Epoch: 646\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88749264]\n",
      " [0.86229702]\n",
      " [0.90322939]]\n",
      "Loss: \n",
      " 0.00041234036208629733\n",
      "\n",
      "\n",
      "Epoch: 647\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88751761]\n",
      " [0.86232223]\n",
      " [0.90325191]]\n",
      "Loss: \n",
      " 0.00041203714139735576\n",
      "\n",
      "\n",
      "Epoch: 648\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88754247]\n",
      " [0.86234734]\n",
      " [0.90327433]]\n",
      "Loss: \n",
      " 0.0004117363570402868\n",
      "\n",
      "\n",
      "Epoch: 649\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88756722]\n",
      " [0.86237233]\n",
      " [0.90329664]]\n",
      "Loss: \n",
      " 0.0004114379873635424\n",
      "\n",
      "\n",
      "Epoch: 650\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88759186]\n",
      " [0.86239721]\n",
      " [0.90331886]]\n",
      "Loss: \n",
      " 0.0004111420109220751\n",
      "\n",
      "\n",
      "Epoch: 651\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8876164 ]\n",
      " [0.86242199]\n",
      " [0.90334098]]\n",
      "Loss: \n",
      " 0.0004108484064751978\n",
      "\n",
      "\n",
      "Epoch: 652\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88764083]\n",
      " [0.86244665]\n",
      " [0.90336299]]\n",
      "Loss: \n",
      " 0.0004105571529844567\n",
      "\n",
      "\n",
      "Epoch: 653\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88766516]\n",
      " [0.86247121]\n",
      " [0.90338491]]\n",
      "Loss: \n",
      " 0.00041026822961153994\n",
      "\n",
      "\n",
      "Epoch: 654\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88768938]\n",
      " [0.86249567]\n",
      " [0.90340673]]\n",
      "Loss: \n",
      " 0.00040998161571620086\n",
      "\n",
      "\n",
      "Epoch: 655\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8877135 ]\n",
      " [0.86252001]\n",
      " [0.90342845]]\n",
      "Loss: \n",
      " 0.0004096972908541969\n",
      "\n",
      "\n",
      "Epoch: 656\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88773751]\n",
      " [0.86254425]\n",
      " [0.90345007]]\n",
      "Loss: \n",
      " 0.0004094152347752799\n",
      "\n",
      "\n",
      "Epoch: 657\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88776143]\n",
      " [0.86256839]\n",
      " [0.9034716 ]]\n",
      "Loss: \n",
      " 0.0004091354274211817\n",
      "\n",
      "\n",
      "Epoch: 658\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88778524]\n",
      " [0.86259242]\n",
      " [0.90349303]]\n",
      "Loss: \n",
      " 0.00040885784892364204\n",
      "\n",
      "\n",
      "Epoch: 659\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88780894]\n",
      " [0.86261635]\n",
      " [0.90351436]]\n",
      "Loss: \n",
      " 0.00040858247960243074\n",
      "\n",
      "\n",
      "Epoch: 660\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88783255]\n",
      " [0.86264017]\n",
      " [0.9035356 ]]\n",
      "Loss: \n",
      " 0.0004083092999634403\n",
      "\n",
      "\n",
      "Epoch: 661\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88785605]\n",
      " [0.86266389]\n",
      " [0.90355674]]\n",
      "Loss: \n",
      " 0.0004080382906967441\n",
      "\n",
      "\n",
      "Epoch: 662\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88787946]\n",
      " [0.86268751]\n",
      " [0.90357779]]\n",
      "Loss: \n",
      " 0.00040776943267472823\n",
      "\n",
      "\n",
      "Epoch: 663\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88790276]\n",
      " [0.86271103]\n",
      " [0.90359874]]\n",
      "Loss: \n",
      " 0.00040750270695019187\n",
      "\n",
      "\n",
      "Epoch: 664\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88792596]\n",
      " [0.86273444]\n",
      " [0.90361959]]\n",
      "Loss: \n",
      " 0.0004072380947545148\n",
      "\n",
      "\n",
      "Epoch: 665\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88794907]\n",
      " [0.86275776]\n",
      " [0.90364036]]\n",
      "Loss: \n",
      " 0.00040697557749584147\n",
      "\n",
      "\n",
      "Epoch: 666\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88797208]\n",
      " [0.86278097]\n",
      " [0.90366103]]\n",
      "Loss: \n",
      " 0.00040671513675724554\n",
      "\n",
      "\n",
      "Epoch: 667\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88799499]\n",
      " [0.86280408]\n",
      " [0.90368161]]\n",
      "Loss: \n",
      " 0.0004064567542949465\n",
      "\n",
      "\n",
      "Epoch: 668\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8880178 ]\n",
      " [0.86282709]\n",
      " [0.9037021 ]]\n",
      "Loss: \n",
      " 0.0004062004120365648\n",
      "\n",
      "\n",
      "Epoch: 669\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88804051]\n",
      " [0.86285001]\n",
      " [0.90372249]]\n",
      "Loss: \n",
      " 0.00040594609207934433\n",
      "\n",
      "\n",
      "Epoch: 670\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88806313]\n",
      " [0.86287282]\n",
      " [0.90374279]]\n",
      "Loss: \n",
      " 0.0004056937766884379\n",
      "\n",
      "\n",
      "Epoch: 671\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88808565]\n",
      " [0.86289554]\n",
      " [0.90376301]]\n",
      "Loss: \n",
      " 0.0004054434482951941\n",
      "\n",
      "\n",
      "Epoch: 672\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88810807]\n",
      " [0.86291816]\n",
      " [0.90378313]]\n",
      "Loss: \n",
      " 0.00040519508949547035\n",
      "\n",
      "\n",
      "Epoch: 673\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8881304 ]\n",
      " [0.86294068]\n",
      " [0.90380316]]\n",
      "Loss: \n",
      " 0.00040494868304797297\n",
      "\n",
      "\n",
      "Epoch: 674\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88815264]\n",
      " [0.8629631 ]\n",
      " [0.90382311]]\n",
      "Loss: \n",
      " 0.00040470421187256987\n",
      "\n",
      "\n",
      "Epoch: 675\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88817478]\n",
      " [0.86298543]\n",
      " [0.90384296]]\n",
      "Loss: \n",
      " 0.00040446165904868737\n",
      "\n",
      "\n",
      "Epoch: 676\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88819683]\n",
      " [0.86300767]\n",
      " [0.90386273]]\n",
      "Loss: \n",
      " 0.00040422100781368364\n",
      "\n",
      "\n",
      "Epoch: 677\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88821878]\n",
      " [0.8630298 ]\n",
      " [0.9038824 ]]\n",
      "Loss: \n",
      " 0.00040398224156125943\n",
      "\n",
      "\n",
      "Epoch: 678\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88824064]\n",
      " [0.86305185]\n",
      " [0.903902  ]]\n",
      "Loss: \n",
      " 0.0004037453438398506\n",
      "\n",
      "\n",
      "Epoch: 679\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88826241]\n",
      " [0.86307379]\n",
      " [0.9039215 ]]\n",
      "Loss: \n",
      " 0.00040351029835110895\n",
      "\n",
      "\n",
      "Epoch: 680\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88828409]\n",
      " [0.86309565]\n",
      " [0.90394091]]\n",
      "Loss: \n",
      " 0.00040327708894830815\n",
      "\n",
      "\n",
      "Epoch: 681\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88830567]\n",
      " [0.86311741]\n",
      " [0.90396024]]\n",
      "Loss: \n",
      " 0.00040304569963485053\n",
      "\n",
      "\n",
      "Epoch: 682\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88832716]\n",
      " [0.86313907]\n",
      " [0.90397949]]\n",
      "Loss: \n",
      " 0.00040281611456274407\n",
      "\n",
      "\n",
      "Epoch: 683\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88834857]\n",
      " [0.86316065]\n",
      " [0.90399865]]\n",
      "Loss: \n",
      " 0.0004025883180311096\n",
      "\n",
      "\n",
      "Epoch: 684\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88836988]\n",
      " [0.86318213]\n",
      " [0.90401772]]\n",
      "Loss: \n",
      " 0.00040236229448469273\n",
      "\n",
      "\n",
      "Epoch: 685\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8883911 ]\n",
      " [0.86320352]\n",
      " [0.90403671]]\n",
      "Loss: \n",
      " 0.0004021380285124129\n",
      "\n",
      "\n",
      "Epoch: 686\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88841224]\n",
      " [0.86322482]\n",
      " [0.90405561]]\n",
      "Loss: \n",
      " 0.0004019155048459179\n",
      "\n",
      "\n",
      "Epoch: 687\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88843328]\n",
      " [0.86324603]\n",
      " [0.90407443]]\n",
      "Loss: \n",
      " 0.000401694708358139\n",
      "\n",
      "\n",
      "Epoch: 688\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88845423]\n",
      " [0.86326714]\n",
      " [0.90409317]]\n",
      "Loss: \n",
      " 0.00040147562406190083\n",
      "\n",
      "\n",
      "Epoch: 689\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8884751 ]\n",
      " [0.86328817]\n",
      " [0.90411182]]\n",
      "Loss: \n",
      " 0.0004012582371084971\n",
      "\n",
      "\n",
      "Epoch: 690\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88849588]\n",
      " [0.86330911]\n",
      " [0.90413039]]\n",
      "Loss: \n",
      " 0.00040104253278632206\n",
      "\n",
      "\n",
      "Epoch: 691\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88851657]\n",
      " [0.86332996]\n",
      " [0.90414888]]\n",
      "Loss: \n",
      " 0.00040082849651950655\n",
      "\n",
      "\n",
      "Epoch: 692\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88853718]\n",
      " [0.86335072]\n",
      " [0.90416729]]\n",
      "Loss: \n",
      " 0.00040061611386654094\n",
      "\n",
      "\n",
      "Epoch: 693\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8885577 ]\n",
      " [0.86337139]\n",
      " [0.90418561]]\n",
      "Loss: \n",
      " 0.0004004053705189668\n",
      "\n",
      "\n",
      "Epoch: 694\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88857813]\n",
      " [0.86339197]\n",
      " [0.90420385]]\n",
      "Loss: \n",
      " 0.00040019625230002827\n",
      "\n",
      "\n",
      "Epoch: 695\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88859848]\n",
      " [0.86341247]\n",
      " [0.90422202]]\n",
      "Loss: \n",
      " 0.00039998874516337853\n",
      "\n",
      "\n",
      "Epoch: 696\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88861874]\n",
      " [0.86343288]\n",
      " [0.9042401 ]]\n",
      "Loss: \n",
      " 0.00039978283519177365\n",
      "\n",
      "\n",
      "Epoch: 697\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88863892]\n",
      " [0.8634532 ]\n",
      " [0.9042581 ]]\n",
      "Loss: \n",
      " 0.0003995785085958011\n",
      "\n",
      "\n",
      "Epoch: 698\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88865901]\n",
      " [0.86347343]\n",
      " [0.90427603]]\n",
      "Loss: \n",
      " 0.0003993757517125975\n",
      "\n",
      "\n",
      "Epoch: 699\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88867902]\n",
      " [0.86349358]\n",
      " [0.90429387]]\n",
      "Loss: \n",
      " 0.0003991745510046145\n",
      "\n",
      "\n",
      "Epoch: 700\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88869894]\n",
      " [0.86351365]\n",
      " [0.90431164]]\n",
      "Loss: \n",
      " 0.0003989748930583571\n",
      "\n",
      "\n",
      "Epoch: 701\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88871879]\n",
      " [0.86353363]\n",
      " [0.90432932]]\n",
      "Loss: \n",
      " 0.00039877676458317584\n",
      "\n",
      "\n",
      "Epoch: 702\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88873855]\n",
      " [0.86355352]\n",
      " [0.90434693]]\n",
      "Loss: \n",
      " 0.0003985801524100453\n",
      "\n",
      "\n",
      "Epoch: 703\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88875822]\n",
      " [0.86357333]\n",
      " [0.90436446]]\n",
      "Loss: \n",
      " 0.0003983850434903657\n",
      "\n",
      "\n",
      "Epoch: 704\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88877782]\n",
      " [0.86359306]\n",
      " [0.90438192]]\n",
      "Loss: \n",
      " 0.0003981914248947633\n",
      "\n",
      "\n",
      "Epoch: 705\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88879733]\n",
      " [0.8636127 ]\n",
      " [0.90439929]]\n",
      "Loss: \n",
      " 0.00039799928381193517\n",
      "\n",
      "\n",
      "Epoch: 706\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88881676]\n",
      " [0.86363226]\n",
      " [0.90441659]]\n",
      "Loss: \n",
      " 0.0003978086075474823\n",
      "\n",
      "\n",
      "Epoch: 707\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88883611]\n",
      " [0.86365174]\n",
      " [0.90443382]]\n",
      "Loss: \n",
      " 0.00039761938352274556\n",
      "\n",
      "\n",
      "Epoch: 708\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88885538]\n",
      " [0.86367113]\n",
      " [0.90445097]]\n",
      "Loss: \n",
      " 0.0003974315992736799\n",
      "\n",
      "\n",
      "Epoch: 709\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88887457]\n",
      " [0.86369044]\n",
      " [0.90446804]]\n",
      "Loss: \n",
      " 0.0003972452424497411\n",
      "\n",
      "\n",
      "Epoch: 710\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88889368]\n",
      " [0.86370968]\n",
      " [0.90448504]]\n",
      "Loss: \n",
      " 0.0003970603008127507\n",
      "\n",
      "\n",
      "Epoch: 711\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88891271]\n",
      " [0.86372883]\n",
      " [0.90450196]]\n",
      "Loss: \n",
      " 0.0003968767622357936\n",
      "\n",
      "\n",
      "Epoch: 712\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88893167]\n",
      " [0.86374789]\n",
      " [0.90451881]]\n",
      "Loss: \n",
      " 0.0003966946147021645\n",
      "\n",
      "\n",
      "Epoch: 713\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88895054]\n",
      " [0.86376688]\n",
      " [0.90453558]]\n",
      "Loss: \n",
      " 0.00039651384630424693\n",
      "\n",
      "\n",
      "Epoch: 714\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88896934]\n",
      " [0.86378579]\n",
      " [0.90455228]]\n",
      "Loss: \n",
      " 0.0003963344452424711\n",
      "\n",
      "\n",
      "Epoch: 715\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88898805]\n",
      " [0.86380462]\n",
      " [0.90456891]]\n",
      "Loss: \n",
      " 0.0003961563998242593\n",
      "\n",
      "\n",
      "Epoch: 716\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88900669]\n",
      " [0.86382337]\n",
      " [0.90458547]]\n",
      "Loss: \n",
      " 0.00039597969846296593\n",
      "\n",
      "\n",
      "Epoch: 717\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88902525]\n",
      " [0.86384204]\n",
      " [0.90460195]]\n",
      "Loss: \n",
      " 0.00039580432967686267\n",
      "\n",
      "\n",
      "Epoch: 718\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88904374]\n",
      " [0.86386063]\n",
      " [0.90461836]]\n",
      "Loss: \n",
      " 0.0003956302820881129\n",
      "\n",
      "\n",
      "Epoch: 719\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88906215]\n",
      " [0.86387915]\n",
      " [0.90463469]]\n",
      "Loss: \n",
      " 0.0003954575444217545\n",
      "\n",
      "\n",
      "Epoch: 720\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88908048]\n",
      " [0.86389758]\n",
      " [0.90465096]]\n",
      "Loss: \n",
      " 0.0003952861055046979\n",
      "\n",
      "\n",
      "Epoch: 721\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88909874]\n",
      " [0.86391594]\n",
      " [0.90466715]]\n",
      "Loss: \n",
      " 0.00039511595426475915\n",
      "\n",
      "\n",
      "Epoch: 722\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88911692]\n",
      " [0.86393422]\n",
      " [0.90468328]]\n",
      "Loss: \n",
      " 0.00039494707972965396\n",
      "\n",
      "\n",
      "Epoch: 723\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88913503]\n",
      " [0.86395243]\n",
      " [0.90469933]]\n",
      "Loss: \n",
      " 0.0003947794710260376\n",
      "\n",
      "\n",
      "Epoch: 724\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88915306]\n",
      " [0.86397055]\n",
      " [0.90471531]]\n",
      "Loss: \n",
      " 0.0003946131173785546\n",
      "\n",
      "\n",
      "Epoch: 725\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88917102]\n",
      " [0.86398861]\n",
      " [0.90473123]]\n",
      "Loss: \n",
      " 0.0003944480081088833\n",
      "\n",
      "\n",
      "Epoch: 726\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8891889 ]\n",
      " [0.86400658]\n",
      " [0.90474707]]\n",
      "Loss: \n",
      " 0.00039428413263480224\n",
      "\n",
      "\n",
      "Epoch: 727\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88920671]\n",
      " [0.86402448]\n",
      " [0.90476284]]\n",
      "Loss: \n",
      " 0.00039412148046924717\n",
      "\n",
      "\n",
      "Epoch: 728\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88922445]\n",
      " [0.86404231]\n",
      " [0.90477855]]\n",
      "Loss: \n",
      " 0.00039396004121941916\n",
      "\n",
      "\n",
      "Epoch: 729\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88924212]\n",
      " [0.86406006]\n",
      " [0.90479419]]\n",
      "Loss: \n",
      " 0.00039379980458585797\n",
      "\n",
      "\n",
      "Epoch: 730\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88925971]\n",
      " [0.86407774]\n",
      " [0.90480975]]\n",
      "Loss: \n",
      " 0.00039364076036153367\n",
      "\n",
      "\n",
      "Epoch: 731\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88927723]\n",
      " [0.86409534]\n",
      " [0.90482525]]\n",
      "Loss: \n",
      " 0.0003934828984309886\n",
      "\n",
      "\n",
      "Epoch: 732\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88929467]\n",
      " [0.86411287]\n",
      " [0.90484069]]\n",
      "Loss: \n",
      " 0.00039332620876940394\n",
      "\n",
      "\n",
      "Epoch: 733\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88931205]\n",
      " [0.86413033]\n",
      " [0.90485605]]\n",
      "Loss: \n",
      " 0.00039317068144180005\n",
      "\n",
      "\n",
      "Epoch: 734\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88932936]\n",
      " [0.86414771]\n",
      " [0.90487135]]\n",
      "Loss: \n",
      " 0.0003930163066021056\n",
      "\n",
      "\n",
      "Epoch: 735\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88934659]\n",
      " [0.86416502]\n",
      " [0.90488658]]\n",
      "Loss: \n",
      " 0.00039286307449234954\n",
      "\n",
      "\n",
      "Epoch: 736\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88936375]\n",
      " [0.86418226]\n",
      " [0.90490174]]\n",
      "Loss: \n",
      " 0.00039271097544179147\n",
      "\n",
      "\n",
      "Epoch: 737\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88938084]\n",
      " [0.86419942]\n",
      " [0.90491684]]\n",
      "Loss: \n",
      " 0.0003925599998661024\n",
      "\n",
      "\n",
      "Epoch: 738\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88939787]\n",
      " [0.86421652]\n",
      " [0.90493187]]\n",
      "Loss: \n",
      " 0.0003924101382665243\n",
      "\n",
      "\n",
      "Epoch: 739\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88941482]\n",
      " [0.86423354]\n",
      " [0.90494684]]\n",
      "Loss: \n",
      " 0.0003922613812290592\n",
      "\n",
      "\n",
      "Epoch: 740\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8894317 ]\n",
      " [0.86425049]\n",
      " [0.90496174]]\n",
      "Loss: \n",
      " 0.0003921137194236577\n",
      "\n",
      "\n",
      "Epoch: 741\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88944852]\n",
      " [0.86426737]\n",
      " [0.90497658]]\n",
      "Loss: \n",
      " 0.000391967143603426\n",
      "\n",
      "\n",
      "Epoch: 742\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88946527]\n",
      " [0.86428418]\n",
      " [0.90499135]]\n",
      "Loss: \n",
      " 0.0003918216446038138\n",
      "\n",
      "\n",
      "Epoch: 743\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88948194]\n",
      " [0.86430093]\n",
      " [0.90500606]]\n",
      "Loss: \n",
      " 0.00039167721334184\n",
      "\n",
      "\n",
      "Epoch: 744\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88949855]\n",
      " [0.8643176 ]\n",
      " [0.9050207 ]]\n",
      "Loss: \n",
      " 0.00039153384081532785\n",
      "\n",
      "\n",
      "Epoch: 745\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88951509]\n",
      " [0.8643342 ]\n",
      " [0.90503529]]\n",
      "Loss: \n",
      " 0.0003913915181021072\n",
      "\n",
      "\n",
      "Epoch: 746\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88953157]\n",
      " [0.86435073]\n",
      " [0.9050498 ]]\n",
      "Loss: \n",
      " 0.00039125023635929184\n",
      "\n",
      "\n",
      "Epoch: 747\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88954798]\n",
      " [0.8643672 ]\n",
      " [0.90506426]]\n",
      "Loss: \n",
      " 0.0003911099868224879\n",
      "\n",
      "\n",
      "Epoch: 748\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88956432]\n",
      " [0.86438359]\n",
      " [0.90507865]]\n",
      "Loss: \n",
      " 0.000390970760805064\n",
      "\n",
      "\n",
      "Epoch: 749\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88958059]\n",
      " [0.86439992]\n",
      " [0.90509297]]\n",
      "Loss: \n",
      " 0.0003908325496974393\n",
      "\n",
      "\n",
      "Epoch: 750\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8895968 ]\n",
      " [0.86441618]\n",
      " [0.90510724]]\n",
      "Loss: \n",
      " 0.0003906953449662981\n",
      "\n",
      "\n",
      "Epoch: 751\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88961294]\n",
      " [0.86443237]\n",
      " [0.90512145]]\n",
      "Loss: \n",
      " 0.00039055913815392733\n",
      "\n",
      "\n",
      "Epoch: 752\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88962902]\n",
      " [0.8644485 ]\n",
      " [0.90513559]]\n",
      "Loss: \n",
      " 0.000390423920877455\n",
      "\n",
      "\n",
      "Epoch: 753\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88964503]\n",
      " [0.86446455]\n",
      " [0.90514967]]\n",
      "Loss: \n",
      " 0.00039028968482816313\n",
      "\n",
      "\n",
      "Epoch: 754\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88966097]\n",
      " [0.86448055]\n",
      " [0.90516369]]\n",
      "Loss: \n",
      " 0.0003901564217707912\n",
      "\n",
      "\n",
      "Epoch: 755\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88967685]\n",
      " [0.86449647]\n",
      " [0.90517765]]\n",
      "Loss: \n",
      " 0.0003900241235428317\n",
      "\n",
      "\n",
      "Epoch: 756\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88969267]\n",
      " [0.86451233]\n",
      " [0.90519155]]\n",
      "Loss: \n",
      " 0.00038989278205385177\n",
      "\n",
      "\n",
      "Epoch: 757\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88970842]\n",
      " [0.86452812]\n",
      " [0.90520538]]\n",
      "Loss: \n",
      " 0.0003897623892848074\n",
      "\n",
      "\n",
      "Epoch: 758\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88972411]\n",
      " [0.86454385]\n",
      " [0.90521916]]\n",
      "Loss: \n",
      " 0.00038963293728737266\n",
      "\n",
      "\n",
      "Epoch: 759\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88973974]\n",
      " [0.86455952]\n",
      " [0.90523288]]\n",
      "Loss: \n",
      " 0.00038950441818327554\n",
      "\n",
      "\n",
      "Epoch: 760\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8897553 ]\n",
      " [0.86457511]\n",
      " [0.90524654]]\n",
      "Loss: \n",
      " 0.00038937682416365164\n",
      "\n",
      "\n",
      "Epoch: 761\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8897708 ]\n",
      " [0.86459065]\n",
      " [0.90526014]]\n",
      "Loss: \n",
      " 0.00038925014748836126\n",
      "\n",
      "\n",
      "Epoch: 762\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88978624]\n",
      " [0.86460612]\n",
      " [0.90527368]]\n",
      "Loss: \n",
      " 0.0003891243804853774\n",
      "\n",
      "\n",
      "Epoch: 763\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88980161]\n",
      " [0.86462152]\n",
      " [0.90528716]]\n",
      "Loss: \n",
      " 0.00038899951555012376\n",
      "\n",
      "\n",
      "Epoch: 764\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88981692]\n",
      " [0.86463686]\n",
      " [0.90530059]]\n",
      "Loss: \n",
      " 0.0003888755451448541\n",
      "\n",
      "\n",
      "Epoch: 765\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88983217]\n",
      " [0.86465214]\n",
      " [0.90531395]]\n",
      "Loss: \n",
      " 0.00038875246179802497\n",
      "\n",
      "\n",
      "Epoch: 766\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88984736]\n",
      " [0.86466736]\n",
      " [0.90532726]]\n",
      "Loss: \n",
      " 0.00038863025810366615\n",
      "\n",
      "\n",
      "Epoch: 767\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88986249]\n",
      " [0.86468251]\n",
      " [0.90534051]]\n",
      "Loss: \n",
      " 0.000388508926720793\n",
      "\n",
      "\n",
      "Epoch: 768\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88987755]\n",
      " [0.8646976 ]\n",
      " [0.9053537 ]]\n",
      "Loss: \n",
      " 0.0003883884603727549\n",
      "\n",
      "\n",
      "Epoch: 769\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88989256]\n",
      " [0.86471263]\n",
      " [0.90536684]]\n",
      "Loss: \n",
      " 0.0003882688518466883\n",
      "\n",
      "\n",
      "Epoch: 770\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88990751]\n",
      " [0.86472759]\n",
      " [0.90537992]]\n",
      "Loss: \n",
      " 0.0003881500939928772\n",
      "\n",
      "\n",
      "Epoch: 771\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88992239]\n",
      " [0.8647425 ]\n",
      " [0.90539294]]\n",
      "Loss: \n",
      " 0.0003880321797241879\n",
      "\n",
      "\n",
      "Epoch: 772\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88993722]\n",
      " [0.86475734]\n",
      " [0.90540591]]\n",
      "Loss: \n",
      " 0.00038791510201547464\n",
      "\n",
      "\n",
      "Epoch: 773\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88995198]\n",
      " [0.86477212]\n",
      " [0.90541882]]\n",
      "Loss: \n",
      " 0.0003877988539030168\n",
      "\n",
      "\n",
      "Epoch: 774\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88996669]\n",
      " [0.86478684]\n",
      " [0.90543167]]\n",
      "Loss: \n",
      " 0.00038768342848392585\n",
      "\n",
      "\n",
      "Epoch: 775\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88998133]\n",
      " [0.8648015 ]\n",
      " [0.90544447]]\n",
      "Loss: \n",
      " 0.0003875688189156064\n",
      "\n",
      "\n",
      "Epoch: 776\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88999592]\n",
      " [0.8648161 ]\n",
      " [0.90545721]]\n",
      "Loss: \n",
      " 0.0003874550184151647\n",
      "\n",
      "\n",
      "Epoch: 777\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89001045]\n",
      " [0.86483064]\n",
      " [0.9054699 ]]\n",
      "Loss: \n",
      " 0.00038734202025888376\n",
      "\n",
      "\n",
      "Epoch: 778\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89002492]\n",
      " [0.86484512]\n",
      " [0.90548254]]\n",
      "Loss: \n",
      " 0.0003872298177816612\n",
      "\n",
      "\n",
      "Epoch: 779\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89003934]\n",
      " [0.86485954]\n",
      " [0.90549512]]\n",
      "Loss: \n",
      " 0.00038711840437646053\n",
      "\n",
      "\n",
      "Epoch: 780\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89005369]\n",
      " [0.8648739 ]\n",
      " [0.90550764]]\n",
      "Loss: \n",
      " 0.00038700777349378555\n",
      "\n",
      "\n",
      "Epoch: 781\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89006799]\n",
      " [0.86488821]\n",
      " [0.90552011]]\n",
      "Loss: \n",
      " 0.0003868979186411405\n",
      "\n",
      "\n",
      "Epoch: 782\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89008223]\n",
      " [0.86490245]\n",
      " [0.90553253]]\n",
      "Loss: \n",
      " 0.0003867888333825057\n",
      "\n",
      "\n",
      "Epoch: 783\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89009641]\n",
      " [0.86491663]\n",
      " [0.90554489]]\n",
      "Loss: \n",
      " 0.0003866805113378049\n",
      "\n",
      "\n",
      "Epoch: 784\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89011054]\n",
      " [0.86493076]\n",
      " [0.9055572 ]]\n",
      "Loss: \n",
      " 0.00038657294618241433\n",
      "\n",
      "\n",
      "Epoch: 785\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89012461]\n",
      " [0.86494483]\n",
      " [0.90556946]]\n",
      "Loss: \n",
      " 0.0003864661316466209\n",
      "\n",
      "\n",
      "Epoch: 786\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89013862]\n",
      " [0.86495884]\n",
      " [0.90558166]]\n",
      "Loss: \n",
      " 0.000386360061515134\n",
      "\n",
      "\n",
      "Epoch: 787\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89015258]\n",
      " [0.8649728 ]\n",
      " [0.90559382]]\n",
      "Loss: \n",
      " 0.0003862547296265834\n",
      "\n",
      "\n",
      "Epoch: 788\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89016648]\n",
      " [0.86498669]\n",
      " [0.90560592]]\n",
      "Loss: \n",
      " 0.00038615012987300903\n",
      "\n",
      "\n",
      "Epoch: 789\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89018033]\n",
      " [0.86500053]\n",
      " [0.90561796]]\n",
      "Loss: \n",
      " 0.0003860462561993896\n",
      "\n",
      "\n",
      "Epoch: 790\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89019412]\n",
      " [0.86501431]\n",
      " [0.90562996]]\n",
      "Loss: \n",
      " 0.0003859431026031392\n",
      "\n",
      "\n",
      "Epoch: 791\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89020786]\n",
      " [0.86502804]\n",
      " [0.9056419 ]]\n",
      "Loss: \n",
      " 0.0003858406631336376\n",
      "\n",
      "\n",
      "Epoch: 792\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89022154]\n",
      " [0.86504171]\n",
      " [0.90565379]]\n",
      "Loss: \n",
      " 0.00038573893189173934\n",
      "\n",
      "\n",
      "Epoch: 793\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89023517]\n",
      " [0.86505533]\n",
      " [0.90566564]]\n",
      "Loss: \n",
      " 0.0003856379030293125\n",
      "\n",
      "\n",
      "Epoch: 794\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89024874]\n",
      " [0.86506888]\n",
      " [0.90567743]]\n",
      "Loss: \n",
      " 0.00038553757074877385\n",
      "\n",
      "\n",
      "Epoch: 795\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89026226]\n",
      " [0.86508239]\n",
      " [0.90568917]]\n",
      "Loss: \n",
      " 0.00038543792930260137\n",
      "\n",
      "\n",
      "Epoch: 796\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89027572]\n",
      " [0.86509584]\n",
      " [0.90570085]]\n",
      "Loss: \n",
      " 0.0003853389729929172\n",
      "\n",
      "\n",
      "Epoch: 797\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89028914]\n",
      " [0.86510923]\n",
      " [0.90571249]]\n",
      "Loss: \n",
      " 0.0003852406961709959\n",
      "\n",
      "\n",
      "Epoch: 798\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89030249]\n",
      " [0.86512257]\n",
      " [0.90572408]]\n",
      "Loss: \n",
      " 0.00038514309323683205\n",
      "\n",
      "\n",
      "Epoch: 799\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8903158 ]\n",
      " [0.86513585]\n",
      " [0.90573562]]\n",
      "Loss: \n",
      " 0.00038504615863869447\n",
      "\n",
      "\n",
      "Epoch: 800\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89032905]\n",
      " [0.86514908]\n",
      " [0.90574711]]\n",
      "Loss: \n",
      " 0.0003849498868726744\n",
      "\n",
      "\n",
      "Epoch: 801\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89034225]\n",
      " [0.86516226]\n",
      " [0.90575855]]\n",
      "Loss: \n",
      " 0.0003848542724822703\n",
      "\n",
      "\n",
      "Epoch: 802\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8903554 ]\n",
      " [0.86517538]\n",
      " [0.90576994]]\n",
      "Loss: \n",
      " 0.00038475931005793525\n",
      "\n",
      "\n",
      "Epoch: 803\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89036849]\n",
      " [0.86518845]\n",
      " [0.90578128]]\n",
      "Loss: \n",
      " 0.00038466499423665514\n",
      "\n",
      "\n",
      "Epoch: 804\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89038154]\n",
      " [0.86520146]\n",
      " [0.90579257]]\n",
      "Loss: \n",
      " 0.0003845713197015328\n",
      "\n",
      "\n",
      "Epoch: 805\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89039453]\n",
      " [0.86521442]\n",
      " [0.90580382]]\n",
      "Loss: \n",
      " 0.0003844782811813579\n",
      "\n",
      "\n",
      "Epoch: 806\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89040747]\n",
      " [0.86522733]\n",
      " [0.90581501]]\n",
      "Loss: \n",
      " 0.0003843858734501943\n",
      "\n",
      "\n",
      "Epoch: 807\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89042036]\n",
      " [0.86524019]\n",
      " [0.90582616]]\n",
      "Loss: \n",
      " 0.0003842940913269778\n",
      "\n",
      "\n",
      "Epoch: 808\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89043319]\n",
      " [0.86525299]\n",
      " [0.90583726]]\n",
      "Loss: \n",
      " 0.00038420292967508994\n",
      "\n",
      "\n",
      "Epoch: 809\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89044598]\n",
      " [0.86526575]\n",
      " [0.90584831]]\n",
      "Loss: \n",
      " 0.00038411238340197\n",
      "\n",
      "\n",
      "Epoch: 810\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89045872]\n",
      " [0.86527845]\n",
      " [0.90585932]]\n",
      "Loss: \n",
      " 0.0003840224474587135\n",
      "\n",
      "\n",
      "Epoch: 811\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8904714 ]\n",
      " [0.86529109]\n",
      " [0.90587028]]\n",
      "Loss: \n",
      " 0.00038393311683966824\n",
      "\n",
      "\n",
      "Epoch: 812\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89048404]\n",
      " [0.86530369]\n",
      " [0.90588119]]\n",
      "Loss: \n",
      " 0.00038384438658205596\n",
      "\n",
      "\n",
      "Epoch: 813\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89049663]\n",
      " [0.86531624]\n",
      " [0.90589205]]\n",
      "Loss: \n",
      " 0.00038375625176556555\n",
      "\n",
      "\n",
      "Epoch: 814\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89050916]\n",
      " [0.86532873]\n",
      " [0.90590287]]\n",
      "Loss: \n",
      " 0.00038366870751198323\n",
      "\n",
      "\n",
      "Epoch: 815\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89052165]\n",
      " [0.86534118]\n",
      " [0.90591364]]\n",
      "Loss: \n",
      " 0.00038358174898481706\n",
      "\n",
      "\n",
      "Epoch: 816\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89053409]\n",
      " [0.86535357]\n",
      " [0.90592436]]\n",
      "Loss: \n",
      " 0.0003834953713888988\n",
      "\n",
      "\n",
      "Epoch: 817\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89054647]\n",
      " [0.86536591]\n",
      " [0.90593504]]\n",
      "Loss: \n",
      " 0.00038340956997002574\n",
      "\n",
      "\n",
      "Epoch: 818\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89055881]\n",
      " [0.86537821]\n",
      " [0.90594567]]\n",
      "Loss: \n",
      " 0.000383324340014603\n",
      "\n",
      "\n",
      "Epoch: 819\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89057111]\n",
      " [0.86539045]\n",
      " [0.90595626]]\n",
      "Loss: \n",
      " 0.00038323967684923704\n",
      "\n",
      "\n",
      "Epoch: 820\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89058335]\n",
      " [0.86540264]\n",
      " [0.9059668 ]]\n",
      "Loss: \n",
      " 0.00038315557584042486\n",
      "\n",
      "\n",
      "Epoch: 821\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89059554]\n",
      " [0.86541479]\n",
      " [0.9059773 ]]\n",
      "Loss: \n",
      " 0.0003830720323941522\n",
      "\n",
      "\n",
      "Epoch: 822\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89060769]\n",
      " [0.86542688]\n",
      " [0.90598775]]\n",
      "Loss: \n",
      " 0.0003829890419555626\n",
      "\n",
      "\n",
      "Epoch: 823\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89061979]\n",
      " [0.86543893]\n",
      " [0.90599816]]\n",
      "Loss: \n",
      " 0.0003829066000085968\n",
      "\n",
      "\n",
      "Epoch: 824\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89063184]\n",
      " [0.86545092]\n",
      " [0.90600852]]\n",
      "Loss: \n",
      " 0.00038282470207564256\n",
      "\n",
      "\n",
      "Epoch: 825\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89064384]\n",
      " [0.86546287]\n",
      " [0.90601884]]\n",
      "Loss: \n",
      " 0.0003827433437171961\n",
      "\n",
      "\n",
      "Epoch: 826\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8906558 ]\n",
      " [0.86547477]\n",
      " [0.90602911]]\n",
      "Loss: \n",
      " 0.00038266252053151083\n",
      "\n",
      "\n",
      "Epoch: 827\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89066771]\n",
      " [0.86548663]\n",
      " [0.90603934]]\n",
      "Loss: \n",
      " 0.0003825822281542667\n",
      "\n",
      "\n",
      "Epoch: 828\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89067957]\n",
      " [0.86549843]\n",
      " [0.90604952]]\n",
      "Loss: \n",
      " 0.0003825024622582283\n",
      "\n",
      "\n",
      "Epoch: 829\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89069139]\n",
      " [0.86551018]\n",
      " [0.90605967]]\n",
      "Loss: \n",
      " 0.00038242321855292766\n",
      "\n",
      "\n",
      "Epoch: 830\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89070316]\n",
      " [0.86552189]\n",
      " [0.90606976]]\n",
      "Loss: \n",
      " 0.0003823444927843047\n",
      "\n",
      "\n",
      "Epoch: 831\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89071488]\n",
      " [0.86553355]\n",
      " [0.90607982]]\n",
      "Loss: \n",
      " 0.00038226628073440987\n",
      "\n",
      "\n",
      "Epoch: 832\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89072656]\n",
      " [0.86554517]\n",
      " [0.90608983]]\n",
      "Loss: \n",
      " 0.00038218857822107247\n",
      "\n",
      "\n",
      "Epoch: 833\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89073819]\n",
      " [0.86555674]\n",
      " [0.9060998 ]]\n",
      "Loss: \n",
      " 0.00038211138109757524\n",
      "\n",
      "\n",
      "Epoch: 834\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89074978]\n",
      " [0.86556826]\n",
      " [0.90610973]]\n",
      "Loss: \n",
      " 0.00038203468525235145\n",
      "\n",
      "\n",
      "Epoch: 835\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89076132]\n",
      " [0.86557973]\n",
      " [0.90611961]]\n",
      "Loss: \n",
      " 0.0003819584866086452\n",
      "\n",
      "\n",
      "Epoch: 836\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89077282]\n",
      " [0.86559116]\n",
      " [0.90612945]]\n",
      "Loss: \n",
      " 0.00038188278112423094\n",
      "\n",
      "\n",
      "Epoch: 837\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89078427]\n",
      " [0.86560254]\n",
      " [0.90613925]]\n",
      "Loss: \n",
      " 0.0003818075647910907\n",
      "\n",
      "\n",
      "Epoch: 838\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89079568]\n",
      " [0.86561387]\n",
      " [0.90614901]]\n",
      "Loss: \n",
      " 0.000381732833635104\n",
      "\n",
      "\n",
      "Epoch: 839\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89080704]\n",
      " [0.86562516]\n",
      " [0.90615872]]\n",
      "Loss: \n",
      " 0.0003816585837157609\n",
      "\n",
      "\n",
      "Epoch: 840\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89081836]\n",
      " [0.86563641]\n",
      " [0.9061684 ]]\n",
      "Loss: \n",
      " 0.0003815848111258484\n",
      "\n",
      "\n",
      "Epoch: 841\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89082963]\n",
      " [0.8656476 ]\n",
      " [0.90617803]]\n",
      "Loss: \n",
      " 0.00038151151199116324\n",
      "\n",
      "\n",
      "Epoch: 842\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89084086]\n",
      " [0.86565876]\n",
      " [0.90618762]]\n",
      "Loss: \n",
      " 0.00038143868247021386\n",
      "\n",
      "\n",
      "Epoch: 843\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89085205]\n",
      " [0.86566987]\n",
      " [0.90619717]]\n",
      "Loss: \n",
      " 0.0003813663187539356\n",
      "\n",
      "\n",
      "Epoch: 844\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89086319]\n",
      " [0.86568093]\n",
      " [0.90620668]]\n",
      "Loss: \n",
      " 0.0003812944170653975\n",
      "\n",
      "\n",
      "Epoch: 845\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89087429]\n",
      " [0.86569195]\n",
      " [0.90621615]]\n",
      "Loss: \n",
      " 0.00038122297365951837\n",
      "\n",
      "\n",
      "Epoch: 846\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89088534]\n",
      " [0.86570292]\n",
      " [0.90622558]]\n",
      "Loss: \n",
      " 0.0003811519848227836\n",
      "\n",
      "\n",
      "Epoch: 847\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89089636]\n",
      " [0.86571385]\n",
      " [0.90623497]]\n",
      "Loss: \n",
      " 0.0003810814468729698\n",
      "\n",
      "\n",
      "Epoch: 848\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89090733]\n",
      " [0.86572474]\n",
      " [0.90624431]]\n",
      "Loss: \n",
      " 0.0003810113561588581\n",
      "\n",
      "\n",
      "Epoch: 849\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89091825]\n",
      " [0.86573558]\n",
      " [0.90625362]]\n",
      "Loss: \n",
      " 0.0003809417090599755\n",
      "\n",
      "\n",
      "Epoch: 850\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89092914]\n",
      " [0.86574638]\n",
      " [0.90626289]]\n",
      "Loss: \n",
      " 0.0003808725019863065\n",
      "\n",
      "\n",
      "Epoch: 851\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89093998]\n",
      " [0.86575714]\n",
      " [0.90627212]]\n",
      "Loss: \n",
      " 0.0003808037313780305\n",
      "\n",
      "\n",
      "Epoch: 852\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89095078]\n",
      " [0.86576785]\n",
      " [0.90628131]]\n",
      "Loss: \n",
      " 0.0003807353937052614\n",
      "\n",
      "\n",
      "Epoch: 853\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89096154]\n",
      " [0.86577852]\n",
      " [0.90629046]]\n",
      "Loss: \n",
      " 0.00038066748546776896\n",
      "\n",
      "\n",
      "Epoch: 854\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89097226]\n",
      " [0.86578914]\n",
      " [0.90629957]]\n",
      "Loss: \n",
      " 0.0003806000031947304\n",
      "\n",
      "\n",
      "Epoch: 855\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89098293]\n",
      " [0.86579973]\n",
      " [0.90630864]]\n",
      "Loss: \n",
      " 0.0003805329434444663\n",
      "\n",
      "\n",
      "Epoch: 856\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89099356]\n",
      " [0.86581027]\n",
      " [0.90631767]]\n",
      "Loss: \n",
      " 0.00038046630280417695\n",
      "\n",
      "\n",
      "Epoch: 857\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89100416]\n",
      " [0.86582077]\n",
      " [0.90632666]]\n",
      "Loss: \n",
      " 0.00038040007788970226\n",
      "\n",
      "\n",
      "Epoch: 858\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89101471]\n",
      " [0.86583122]\n",
      " [0.90633562]]\n",
      "Loss: \n",
      " 0.000380334265345255\n",
      "\n",
      "\n",
      "Epoch: 859\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89102522]\n",
      " [0.86584164]\n",
      " [0.90634454]]\n",
      "Loss: \n",
      " 0.0003802688618431874\n",
      "\n",
      "\n",
      "Epoch: 860\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89103569]\n",
      " [0.86585201]\n",
      " [0.90635342]]\n",
      "Loss: \n",
      " 0.0003802038640837205\n",
      "\n",
      "\n",
      "Epoch: 861\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89104612]\n",
      " [0.86586234]\n",
      " [0.90636226]]\n",
      "Loss: \n",
      " 0.00038013926879471575\n",
      "\n",
      "\n",
      "Epoch: 862\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89105651]\n",
      " [0.86587263]\n",
      " [0.90637106]]\n",
      "Loss: \n",
      " 0.000380075072731439\n",
      "\n",
      "\n",
      "Epoch: 863\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89106686]\n",
      " [0.86588288]\n",
      " [0.90637983]]\n",
      "Loss: \n",
      " 0.00038001127267629585\n",
      "\n",
      "\n",
      "Epoch: 864\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89107716]\n",
      " [0.86589309]\n",
      " [0.90638855]]\n",
      "Loss: \n",
      " 0.00037994786543861996\n",
      "\n",
      "\n",
      "Epoch: 865\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89108743]\n",
      " [0.86590325]\n",
      " [0.90639724]]\n",
      "Loss: \n",
      " 0.00037988484785441784\n",
      "\n",
      "\n",
      "Epoch: 866\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89109766]\n",
      " [0.86591338]\n",
      " [0.9064059 ]]\n",
      "Loss: \n",
      " 0.00037982221678613845\n",
      "\n",
      "\n",
      "Epoch: 867\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89110785]\n",
      " [0.86592346]\n",
      " [0.90641451]]\n",
      "Loss: \n",
      " 0.00037975996912245147\n",
      "\n",
      "\n",
      "Epoch: 868\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.891118  ]\n",
      " [0.86593351]\n",
      " [0.90642309]]\n",
      "Loss: \n",
      " 0.0003796981017780009\n",
      "\n",
      "\n",
      "Epoch: 869\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89112811]\n",
      " [0.86594351]\n",
      " [0.90643164]]\n",
      "Loss: \n",
      " 0.0003796366116932043\n",
      "\n",
      "\n",
      "Epoch: 870\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89113819]\n",
      " [0.86595348]\n",
      " [0.90644014]]\n",
      "Loss: \n",
      " 0.00037957549583399235\n",
      "\n",
      "\n",
      "Epoch: 871\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89114822]\n",
      " [0.8659634 ]\n",
      " [0.90644861]]\n",
      "Loss: \n",
      " 0.0003795147511916175\n",
      "\n",
      "\n",
      "Epoch: 872\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89115822]\n",
      " [0.86597328]\n",
      " [0.90645705]]\n",
      "Loss: \n",
      " 0.0003794543747824106\n",
      "\n",
      "\n",
      "Epoch: 873\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89116817]\n",
      " [0.86598313]\n",
      " [0.90646545]]\n",
      "Loss: \n",
      " 0.0003793943636475792\n",
      "\n",
      "\n",
      "Epoch: 874\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89117809]\n",
      " [0.86599293]\n",
      " [0.90647381]]\n",
      "Loss: \n",
      " 0.00037933471485297195\n",
      "\n",
      "\n",
      "Epoch: 875\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89118797]\n",
      " [0.8660027 ]\n",
      " [0.90648213]]\n",
      "Loss: \n",
      " 0.00037927542548887687\n",
      "\n",
      "\n",
      "Epoch: 876\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89119781]\n",
      " [0.86601243]\n",
      " [0.90649042]]\n",
      "Loss: \n",
      " 0.00037921649266981676\n",
      "\n",
      "\n",
      "Epoch: 877\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89120762]\n",
      " [0.86602212]\n",
      " [0.90649868]]\n",
      "Loss: \n",
      " 0.00037915791353430986\n",
      "\n",
      "\n",
      "Epoch: 878\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89121738]\n",
      " [0.86603177]\n",
      " [0.9065069 ]]\n",
      "Loss: \n",
      " 0.00037909968524468585\n",
      "\n",
      "\n",
      "Epoch: 879\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89122711]\n",
      " [0.86604138]\n",
      " [0.90651508]]\n",
      "Loss: \n",
      " 0.00037904180498686725\n",
      "\n",
      "\n",
      "Epoch: 880\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8912368 ]\n",
      " [0.86605095]\n",
      " [0.90652323]]\n",
      "Loss: \n",
      " 0.0003789842699701696\n",
      "\n",
      "\n",
      "Epoch: 881\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89124646]\n",
      " [0.86606048]\n",
      " [0.90653135]]\n",
      "Loss: \n",
      " 0.0003789270774270906\n",
      "\n",
      "\n",
      "Epoch: 882\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89125607]\n",
      " [0.86606998]\n",
      " [0.90653943]]\n",
      "Loss: \n",
      " 0.0003788702246131182\n",
      "\n",
      "\n",
      "Epoch: 883\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89126565]\n",
      " [0.86607944]\n",
      " [0.90654747]]\n",
      "Loss: \n",
      " 0.0003788137088065285\n",
      "\n",
      "\n",
      "Epoch: 884\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8912752 ]\n",
      " [0.86608886]\n",
      " [0.90655549]]\n",
      "Loss: \n",
      " 0.00037875752730817685\n",
      "\n",
      "\n",
      "Epoch: 885\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8912847 ]\n",
      " [0.86609824]\n",
      " [0.90656346]]\n",
      "Loss: \n",
      " 0.00037870167744131865\n",
      "\n",
      "\n",
      "Epoch: 886\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89129418]\n",
      " [0.86610759]\n",
      " [0.90657141]]\n",
      "Loss: \n",
      " 0.0003786461565514063\n",
      "\n",
      "\n",
      "Epoch: 887\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89130361]\n",
      " [0.8661169 ]\n",
      " [0.90657931]]\n",
      "Loss: \n",
      " 0.00037859096200589085\n",
      "\n",
      "\n",
      "Epoch: 888\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89131301]\n",
      " [0.86612617]\n",
      " [0.90658719]]\n",
      "Loss: \n",
      " 0.0003785360911940472\n",
      "\n",
      "\n",
      "Epoch: 889\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89132237]\n",
      " [0.8661354 ]\n",
      " [0.90659503]]\n",
      "Loss: \n",
      " 0.00037848154152676886\n",
      "\n",
      "\n",
      "Epoch: 890\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8913317 ]\n",
      " [0.8661446 ]\n",
      " [0.90660284]]\n",
      "Loss: \n",
      " 0.00037842731043639797\n",
      "\n",
      "\n",
      "Epoch: 891\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89134099]\n",
      " [0.86615376]\n",
      " [0.90661061]]\n",
      "Loss: \n",
      " 0.0003783733953765177\n",
      "\n",
      "\n",
      "Epoch: 892\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89135024]\n",
      " [0.86616288]\n",
      " [0.90661835]]\n",
      "Loss: \n",
      " 0.000378319793821788\n",
      "\n",
      "\n",
      "Epoch: 893\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89135946]\n",
      " [0.86617197]\n",
      " [0.90662606]]\n",
      "Loss: \n",
      " 0.00037826650326775656\n",
      "\n",
      "\n",
      "Epoch: 894\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89136865]\n",
      " [0.86618102]\n",
      " [0.90663374]]\n",
      "Loss: \n",
      " 0.00037821352123067756\n",
      "\n",
      "\n",
      "Epoch: 895\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8913778 ]\n",
      " [0.86619004]\n",
      " [0.90664138]]\n",
      "Loss: \n",
      " 0.0003781608452473267\n",
      "\n",
      "\n",
      "Epoch: 896\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89138691]\n",
      " [0.86619902]\n",
      " [0.90664899]]\n",
      "Loss: \n",
      " 0.00037810847287484415\n",
      "\n",
      "\n",
      "Epoch: 897\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89139599]\n",
      " [0.86620796]\n",
      " [0.90665656]]\n",
      "Loss: \n",
      " 0.0003780564016905329\n",
      "\n",
      "\n",
      "Epoch: 898\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89140504]\n",
      " [0.86621687]\n",
      " [0.90666411]]\n",
      "Loss: \n",
      " 0.000378004629291709\n",
      "\n",
      "\n",
      "Epoch: 899\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89141405]\n",
      " [0.86622574]\n",
      " [0.90667162]]\n",
      "Loss: \n",
      " 0.0003779531532955133\n",
      "\n",
      "\n",
      "Epoch: 900\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89142303]\n",
      " [0.86623458]\n",
      " [0.9066791 ]]\n",
      "Loss: \n",
      " 0.00037790197133873914\n",
      "\n",
      "\n",
      "Epoch: 901\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89143197]\n",
      " [0.86624338]\n",
      " [0.90668655]]\n",
      "Loss: \n",
      " 0.0003778510810776834\n",
      "\n",
      "\n",
      "Epoch: 902\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89144088]\n",
      " [0.86625215]\n",
      " [0.90669397]]\n",
      "Loss: \n",
      " 0.00037780048018794834\n",
      "\n",
      "\n",
      "Epoch: 903\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89144975]\n",
      " [0.86626088]\n",
      " [0.90670135]]\n",
      "Loss: \n",
      " 0.0003777501663643067\n",
      "\n",
      "\n",
      "Epoch: 904\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89145859]\n",
      " [0.86626958]\n",
      " [0.9067087 ]]\n",
      "Loss: \n",
      " 0.00037770013732051685\n",
      "\n",
      "\n",
      "Epoch: 905\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8914674 ]\n",
      " [0.86627824]\n",
      " [0.90671602]]\n",
      "Loss: \n",
      " 0.0003776503907891618\n",
      "\n",
      "\n",
      "Epoch: 906\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89147617]\n",
      " [0.86628687]\n",
      " [0.90672331]]\n",
      "Loss: \n",
      " 0.0003776009245214968\n",
      "\n",
      "\n",
      "Epoch: 907\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89148491]\n",
      " [0.86629547]\n",
      " [0.90673057]]\n",
      "Loss: \n",
      " 0.0003775517362872771\n",
      "\n",
      "\n",
      "Epoch: 908\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89149362]\n",
      " [0.86630403]\n",
      " [0.9067378 ]]\n",
      "Loss: \n",
      " 0.0003775028238746148\n",
      "\n",
      "\n",
      "Epoch: 909\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89150229]\n",
      " [0.86631255]\n",
      " [0.906745  ]]\n",
      "Loss: \n",
      " 0.00037745418508980345\n",
      "\n",
      "\n",
      "Epoch: 910\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89151093]\n",
      " [0.86632105]\n",
      " [0.90675216]]\n",
      "Loss: \n",
      " 0.0003774058177571723\n",
      "\n",
      "\n",
      "Epoch: 911\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89151954]\n",
      " [0.8663295 ]\n",
      " [0.9067593 ]]\n",
      "Loss: \n",
      " 0.0003773577197189362\n",
      "\n",
      "\n",
      "Epoch: 912\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89152812]\n",
      " [0.86633793]\n",
      " [0.9067664 ]]\n",
      "Loss: \n",
      " 0.00037730988883503735\n",
      "\n",
      "\n",
      "Epoch: 913\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89153666]\n",
      " [0.86634632]\n",
      " [0.90677348]]\n",
      "Loss: \n",
      " 0.0003772623229829771\n",
      "\n",
      "\n",
      "Epoch: 914\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89154517]\n",
      " [0.86635468]\n",
      " [0.90678052]]\n",
      "Loss: \n",
      " 0.0003772150200577025\n",
      "\n",
      "\n",
      "Epoch: 915\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89155365]\n",
      " [0.86636301]\n",
      " [0.90678754]]\n",
      "Loss: \n",
      " 0.0003771679779714289\n",
      "\n",
      "\n",
      "Epoch: 916\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8915621 ]\n",
      " [0.8663713 ]\n",
      " [0.90679452]]\n",
      "Loss: \n",
      " 0.0003771211946534971\n",
      "\n",
      "\n",
      "Epoch: 917\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89157051]\n",
      " [0.86637956]\n",
      " [0.90680147]]\n",
      "Loss: \n",
      " 0.0003770746680502295\n",
      "\n",
      "\n",
      "Epoch: 918\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89157889]\n",
      " [0.86638778]\n",
      " [0.9068084 ]]\n",
      "Loss: \n",
      " 0.00037702839612479096\n",
      "\n",
      "\n",
      "Epoch: 919\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89158725]\n",
      " [0.86639598]\n",
      " [0.90681529]]\n",
      "Loss: \n",
      " 0.00037698237685703434\n",
      "\n",
      "\n",
      "Epoch: 920\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89159557]\n",
      " [0.86640414]\n",
      " [0.90682216]]\n",
      "Loss: \n",
      " 0.0003769366082433674\n",
      "\n",
      "\n",
      "Epoch: 921\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89160385]\n",
      " [0.86641227]\n",
      " [0.90682899]]\n",
      "Loss: \n",
      " 0.000376891088296607\n",
      "\n",
      "\n",
      "Epoch: 922\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89161211]\n",
      " [0.86642037]\n",
      " [0.9068358 ]]\n",
      "Loss: \n",
      " 0.0003768458150458418\n",
      "\n",
      "\n",
      "Epoch: 923\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89162034]\n",
      " [0.86642843]\n",
      " [0.90684257]]\n",
      "Loss: \n",
      " 0.0003768007865362858\n",
      "\n",
      "\n",
      "Epoch: 924\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89162853]\n",
      " [0.86643646]\n",
      " [0.90684932]]\n",
      "Loss: \n",
      " 0.00037675600082915663\n",
      "\n",
      "\n",
      "Epoch: 925\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89163669]\n",
      " [0.86644446]\n",
      " [0.90685604]]\n",
      "Loss: \n",
      " 0.0003767114560015187\n",
      "\n",
      "\n",
      "Epoch: 926\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89164483]\n",
      " [0.86645243]\n",
      " [0.90686273]]\n",
      "Loss: \n",
      " 0.0003766671501461742\n",
      "\n",
      "\n",
      "Epoch: 927\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89165293]\n",
      " [0.86646037]\n",
      " [0.90686939]]\n",
      "Loss: \n",
      " 0.0003766230813714996\n",
      "\n",
      "\n",
      "Epoch: 928\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.891661  ]\n",
      " [0.86646828]\n",
      " [0.90687603]]\n",
      "Loss: \n",
      " 0.00037657924780134063\n",
      "\n",
      "\n",
      "Epoch: 929\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89166904]\n",
      " [0.86647615]\n",
      " [0.90688263]]\n",
      "Loss: \n",
      " 0.00037653564757486683\n",
      "\n",
      "\n",
      "Epoch: 930\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89167705]\n",
      " [0.866484  ]\n",
      " [0.90688921]]\n",
      "Loss: \n",
      " 0.0003764922788464316\n",
      "\n",
      "\n",
      "Epoch: 931\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89168503]\n",
      " [0.86649181]\n",
      " [0.90689575]]\n",
      "Loss: \n",
      " 0.00037644913978547367\n",
      "\n",
      "\n",
      "Epoch: 932\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89169298]\n",
      " [0.86649959]\n",
      " [0.90690227]]\n",
      "Loss: \n",
      " 0.0003764062285763619\n",
      "\n",
      "\n",
      "Epoch: 933\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89170091]\n",
      " [0.86650734]\n",
      " [0.90690876]]\n",
      "Loss: \n",
      " 0.0003763635434182705\n",
      "\n",
      "\n",
      "Epoch: 934\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8917088 ]\n",
      " [0.86651507]\n",
      " [0.90691523]]\n",
      "Loss: \n",
      " 0.00037632108252507726\n",
      "\n",
      "\n",
      "Epoch: 935\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89171666]\n",
      " [0.86652276]\n",
      " [0.90692166]]\n",
      "Loss: \n",
      " 0.0003762788441252071\n",
      "\n",
      "\n",
      "Epoch: 936\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89172449]\n",
      " [0.86653042]\n",
      " [0.90692807]]\n",
      "Loss: \n",
      " 0.00037623682646152927\n",
      "\n",
      "\n",
      "Epoch: 937\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89173229]\n",
      " [0.86653804]\n",
      " [0.90693445]]\n",
      "Loss: \n",
      " 0.0003761950277912412\n",
      "\n",
      "\n",
      "Epoch: 938\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89174007]\n",
      " [0.86654564]\n",
      " [0.90694081]]\n",
      "Loss: \n",
      " 0.00037615344638570856\n",
      "\n",
      "\n",
      "Epoch: 939\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89174781]\n",
      " [0.86655321]\n",
      " [0.90694713]]\n",
      "Loss: \n",
      " 0.0003761120805304073\n",
      "\n",
      "\n",
      "Epoch: 940\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89175552]\n",
      " [0.86656075]\n",
      " [0.90695343]]\n",
      "Loss: \n",
      " 0.000376070928524746\n",
      "\n",
      "\n",
      "Epoch: 941\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89176321]\n",
      " [0.86656826]\n",
      " [0.90695971]]\n",
      "Loss: \n",
      " 0.00037602998868197527\n",
      "\n",
      "\n",
      "Epoch: 942\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89177087]\n",
      " [0.86657574]\n",
      " [0.90696595]]\n",
      "Loss: \n",
      " 0.0003759892593290846\n",
      "\n",
      "\n",
      "Epoch: 943\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8917785 ]\n",
      " [0.86658319]\n",
      " [0.90697217]]\n",
      "Loss: \n",
      " 0.00037594873880664534\n",
      "\n",
      "\n",
      "Epoch: 944\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8917861 ]\n",
      " [0.86659061]\n",
      " [0.90697836]]\n",
      "Loss: \n",
      " 0.00037590842546873565\n",
      "\n",
      "\n",
      "Epoch: 945\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89179367]\n",
      " [0.86659801]\n",
      " [0.90698452]]\n",
      "Loss: \n",
      " 0.00037586831768281204\n",
      "\n",
      "\n",
      "Epoch: 946\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89180121]\n",
      " [0.86660537]\n",
      " [0.90699066]]\n",
      "Loss: \n",
      " 0.0003758284138295935\n",
      "\n",
      "\n",
      "Epoch: 947\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89180873]\n",
      " [0.8666127 ]\n",
      " [0.90699678]]\n",
      "Loss: \n",
      " 0.0003757887123029477\n",
      "\n",
      "\n",
      "Epoch: 948\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89181621]\n",
      " [0.86662001]\n",
      " [0.90700286]]\n",
      "Loss: \n",
      " 0.0003757492115097818\n",
      "\n",
      "\n",
      "Epoch: 949\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89182367]\n",
      " [0.86662728]\n",
      " [0.90700892]]\n",
      "Loss: \n",
      " 0.0003757099098699531\n",
      "\n",
      "\n",
      "Epoch: 950\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8918311 ]\n",
      " [0.86663453]\n",
      " [0.90701495]]\n",
      "Loss: \n",
      " 0.0003756708058161279\n",
      "\n",
      "\n",
      "Epoch: 951\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89183851]\n",
      " [0.86664175]\n",
      " [0.90702096]]\n",
      "Loss: \n",
      " 0.0003756318977936898\n",
      "\n",
      "\n",
      "Epoch: 952\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89184588]\n",
      " [0.86664894]\n",
      " [0.90702694]]\n",
      "Loss: \n",
      " 0.00037559318426062934\n",
      "\n",
      "\n",
      "Epoch: 953\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89185323]\n",
      " [0.8666561 ]\n",
      " [0.9070329 ]]\n",
      "Loss: \n",
      " 0.0003755546636874522\n",
      "\n",
      "\n",
      "Epoch: 954\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89186055]\n",
      " [0.86666324]\n",
      " [0.90703883]]\n",
      "Loss: \n",
      " 0.000375516334557052\n",
      "\n",
      "\n",
      "Epoch: 955\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89186784]\n",
      " [0.86667034]\n",
      " [0.90704473]]\n",
      "Loss: \n",
      " 0.0003754781953646148\n",
      "\n",
      "\n",
      "Epoch: 956\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89187511]\n",
      " [0.86667742]\n",
      " [0.90705061]]\n",
      "Loss: \n",
      " 0.0003754402446175266\n",
      "\n",
      "\n",
      "Epoch: 957\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89188235]\n",
      " [0.86668447]\n",
      " [0.90705647]]\n",
      "Loss: \n",
      " 0.0003754024808352455\n",
      "\n",
      "\n",
      "Epoch: 958\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89188956]\n",
      " [0.86669149]\n",
      " [0.9070623 ]]\n",
      "Loss: \n",
      " 0.00037536490254923516\n",
      "\n",
      "\n",
      "Epoch: 959\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89189675]\n",
      " [0.86669849]\n",
      " [0.9070681 ]]\n",
      "Loss: \n",
      " 0.0003753275083028364\n",
      "\n",
      "\n",
      "Epoch: 960\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89190391]\n",
      " [0.86670545]\n",
      " [0.90707388]]\n",
      "Loss: \n",
      " 0.00037529029665117576\n",
      "\n",
      "\n",
      "Epoch: 961\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89191104]\n",
      " [0.86671239]\n",
      " [0.90707963]]\n",
      "Loss: \n",
      " 0.00037525326616107005\n",
      "\n",
      "\n",
      "Epoch: 962\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89191814]\n",
      " [0.8667193 ]\n",
      " [0.90708536]]\n",
      "Loss: \n",
      " 0.00037521641541092814\n",
      "\n",
      "\n",
      "Epoch: 963\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89192522]\n",
      " [0.86672619]\n",
      " [0.90709106]]\n",
      "Loss: \n",
      " 0.0003751797429906436\n",
      "\n",
      "\n",
      "Epoch: 964\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89193228]\n",
      " [0.86673305]\n",
      " [0.90709674]]\n",
      "Loss: \n",
      " 0.000375143247501517\n",
      "\n",
      "\n",
      "Epoch: 965\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8919393 ]\n",
      " [0.86673988]\n",
      " [0.9071024 ]]\n",
      "Loss: \n",
      " 0.0003751069275561521\n",
      "\n",
      "\n",
      "Epoch: 966\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8919463 ]\n",
      " [0.86674668]\n",
      " [0.90710803]]\n",
      "Loss: \n",
      " 0.0003750707817783477\n",
      "\n",
      "\n",
      "Epoch: 967\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89195328]\n",
      " [0.86675346]\n",
      " [0.90711364]]\n",
      "Loss: \n",
      " 0.00037503480880302564\n",
      "\n",
      "\n",
      "Epoch: 968\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89196023]\n",
      " [0.86676021]\n",
      " [0.90711922]]\n",
      "Loss: \n",
      " 0.00037499900727612376\n",
      "\n",
      "\n",
      "Epoch: 969\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89196715]\n",
      " [0.86676693]\n",
      " [0.90712478]]\n",
      "Loss: \n",
      " 0.00037496337585450927\n",
      "\n",
      "\n",
      "Epoch: 970\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89197405]\n",
      " [0.86677363]\n",
      " [0.90713031]]\n",
      "Loss: \n",
      " 0.0003749279132058932\n",
      "\n",
      "\n",
      "Epoch: 971\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89198092]\n",
      " [0.8667803 ]\n",
      " [0.90713582]]\n",
      "Loss: \n",
      " 0.0003748926180087277\n",
      "\n",
      "\n",
      "Epoch: 972\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89198776]\n",
      " [0.86678695]\n",
      " [0.90714131]]\n",
      "Loss: \n",
      " 0.000374857488952119\n",
      "\n",
      "\n",
      "Epoch: 973\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89199458]\n",
      " [0.86679357]\n",
      " [0.90714677]]\n",
      "Loss: \n",
      " 0.00037482252473574566\n",
      "\n",
      "\n",
      "Epoch: 974\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89200138]\n",
      " [0.86680016]\n",
      " [0.90715221]]\n",
      "Loss: \n",
      " 0.00037478772406976624\n",
      "\n",
      "\n",
      "Epoch: 975\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89200815]\n",
      " [0.86680673]\n",
      " [0.90715762]]\n",
      "Loss: \n",
      " 0.0003747530856747404\n",
      "\n",
      "\n",
      "Epoch: 976\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8920149 ]\n",
      " [0.86681327]\n",
      " [0.90716302]]\n",
      "Loss: \n",
      " 0.0003747186082815219\n",
      "\n",
      "\n",
      "Epoch: 977\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89202162]\n",
      " [0.86681978]\n",
      " [0.90716839]]\n",
      "Loss: \n",
      " 0.0003746842906311862\n",
      "\n",
      "\n",
      "Epoch: 978\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89202831]\n",
      " [0.86682627]\n",
      " [0.90717373]]\n",
      "Loss: \n",
      " 0.0003746501314749531\n",
      "\n",
      "\n",
      "Epoch: 979\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89203498]\n",
      " [0.86683274]\n",
      " [0.90717905]]\n",
      "Loss: \n",
      " 0.0003746161295740853\n",
      "\n",
      "\n",
      "Epoch: 980\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89204163]\n",
      " [0.86683918]\n",
      " [0.90718435]]\n",
      "Loss: \n",
      " 0.00037458228369981954\n",
      "\n",
      "\n",
      "Epoch: 981\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89204825]\n",
      " [0.86684559]\n",
      " [0.90718963]]\n",
      "Loss: \n",
      " 0.0003745485926332742\n",
      "\n",
      "\n",
      "Epoch: 982\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89205485]\n",
      " [0.86685198]\n",
      " [0.90719488]]\n",
      "Loss: \n",
      " 0.00037451505516536876\n",
      "\n",
      "\n",
      "Epoch: 983\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89206142]\n",
      " [0.86685834]\n",
      " [0.90720011]]\n",
      "Loss: \n",
      " 0.00037448167009675095\n",
      "\n",
      "\n",
      "Epoch: 984\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89206797]\n",
      " [0.86686468]\n",
      " [0.90720532]]\n",
      "Loss: \n",
      " 0.0003744484362376999\n",
      "\n",
      "\n",
      "Epoch: 985\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89207449]\n",
      " [0.866871  ]\n",
      " [0.90721051]]\n",
      "Loss: \n",
      " 0.0003744153524080634\n",
      "\n",
      "\n",
      "Epoch: 986\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89208099]\n",
      " [0.86687729]\n",
      " [0.90721567]]\n",
      "Loss: \n",
      " 0.00037438241743716327\n",
      "\n",
      "\n",
      "Epoch: 987\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89208747]\n",
      " [0.86688355]\n",
      " [0.90722081]]\n",
      "Loss: \n",
      " 0.0003743496301637272\n",
      "\n",
      "\n",
      "Epoch: 988\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89209392]\n",
      " [0.86688979]\n",
      " [0.90722593]]\n",
      "Loss: \n",
      " 0.00037431698943581456\n",
      "\n",
      "\n",
      "Epoch: 989\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89210035]\n",
      " [0.86689601]\n",
      " [0.90723103]]\n",
      "Loss: \n",
      " 0.00037428449411071996\n",
      "\n",
      "\n",
      "Epoch: 990\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89210676]\n",
      " [0.8669022 ]\n",
      " [0.9072361 ]]\n",
      "Loss: \n",
      " 0.00037425214305491453\n",
      "\n",
      "\n",
      "Epoch: 991\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89211314]\n",
      " [0.86690837]\n",
      " [0.90724115]]\n",
      "Loss: \n",
      " 0.0003742199351439729\n",
      "\n",
      "\n",
      "Epoch: 992\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8921195 ]\n",
      " [0.86691451]\n",
      " [0.90724618]]\n",
      "Loss: \n",
      " 0.00037418786926246604\n",
      "\n",
      "\n",
      "Epoch: 993\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89212583]\n",
      " [0.86692063]\n",
      " [0.90725119]]\n",
      "Loss: \n",
      " 0.00037415594430393554\n",
      "\n",
      "\n",
      "Epoch: 994\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89213215]\n",
      " [0.86692672]\n",
      " [0.90725618]]\n",
      "Loss: \n",
      " 0.00037412415917077854\n",
      "\n",
      "\n",
      "Epoch: 995\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89213843]\n",
      " [0.86693279]\n",
      " [0.90726114]]\n",
      "Loss: \n",
      " 0.0003740925127741937\n",
      "\n",
      "\n",
      "Epoch: 996\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8921447 ]\n",
      " [0.86693884]\n",
      " [0.90726609]]\n",
      "Loss: \n",
      " 0.00037406100403410917\n",
      "\n",
      "\n",
      "Epoch: 997\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89215094]\n",
      " [0.86694486]\n",
      " [0.90727101]]\n",
      "Loss: \n",
      " 0.00037402963187909755\n",
      "\n",
      "\n",
      "Epoch: 998\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89215716]\n",
      " [0.86695086]\n",
      " [0.90727591]]\n",
      "Loss: \n",
      " 0.00037399839524631523\n",
      "\n",
      "\n",
      "Epoch: 999\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89216336]\n",
      " [0.86695684]\n",
      " [0.90728079]]\n",
      "Loss: \n",
      " 0.0003739672930814354\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "X = np.array(([2, 9], [1, 5], [3, 6]), dtype=float)\n",
    "print(np.amax(X, axis=0))\n",
    "y = np.array(([92], [86], [89]), dtype=float)\n",
    "X = X/np.amax(X, axis=0)\n",
    "y = y/100\n",
    "\n",
    "class Neural_Network(object):\n",
    "    def __init__(self):\n",
    "        self.inputSize = 2\n",
    "        self.outputSize = 1\n",
    "        self.hiddenSize = 3\n",
    "        self.W1 = np.random.randn(self.inputSize, self.hiddenSize)\n",
    "        self.W2 = np.random.randn(self.hiddenSize, self.outputSize)\n",
    "\n",
    "    def forward(self, X):\n",
    "        self.z = np.dot(X, self.W1)\n",
    "        self.z2 = self.sigmoid(self.z)\n",
    "        self.z3 = np.dot(self.z2, self.W2)\n",
    "        o = self.sigmoid(self.z3) \n",
    "        return o \n",
    "\n",
    "    def sigmoid(self, s):\n",
    "        return 1/(1+np.exp(-s))\n",
    "\n",
    "    def sigmoidPrime(self, s):\n",
    "        return s * (1 - s)\n",
    "    \n",
    "    def backward(self, X, y, o):\n",
    "        self.o_error = y - o\n",
    "        self.o_delta = self.o_error*self.sigmoidPrime(o)\n",
    "        self.z2_error = self.o_delta.dot(self.W2.T)\n",
    "        self.z2_delta = self.z2_error*self.sigmoidPrime(self.z2)\n",
    "        self.W1 += l_rate*X.T.dot(self.z2_delta)\n",
    "        self.W2 += l_rate*self.z2.T.dot(self.o_delta)\n",
    "\n",
    "    def train (self, X, y):\n",
    "        o = self.forward(X)\n",
    "        self.backward(X, y, o)\n",
    "\n",
    "NN = Neural_Network()\n",
    "l_rate = 0.1 \n",
    "for i in range(1000):\n",
    "    print(\"Epoch:\",i)\n",
    "    print(\"l_rate\",l_rate)\n",
    "    print (\"Input: \\n\",str(X))\n",
    "    print (\"Actual Output: \\n\",str(y))\n",
    "    print (\"Predicted Output: \\n\",str(NN.forward(X)) )\n",
    "    print (\"Loss: \\n\",str(np.mean(np.square(y - NN.forward(X)))))\n",
    "    print(\"\\n\")\n",
    "    NN.train(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5eb8be3-179c-4a13-be73-3734502cd50a",
   "metadata": {},
   "source": [
    "# Program 6 Source Code\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9dd9f23-7123-41ff-89ab-6e3dc5b84c9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first 5 values of data is:\n",
      "     Outlook Temperature Humidity  Windy PlayTennis\n",
      "0     Sunny         Hot     High  False         No\n",
      "1     Sunny         Hot     High   True         No\n",
      "2  Overcast         Hot     High  False        Yes\n",
      "3     Rainy        Mild     High  False        Yes\n",
      "4     Rainy        Cool   Normal  False        Yes\n",
      "\n",
      "The First 5 values of train data is\n",
      "     Outlook Temperature Humidity  Windy\n",
      "0     Sunny         Hot     High  False\n",
      "1     Sunny         Hot     High   True\n",
      "2  Overcast         Hot     High  False\n",
      "3     Rainy        Mild     High  False\n",
      "4     Rainy        Cool   Normal  False\n",
      "\n",
      "The First 5 values of train output is\n",
      " 0     No\n",
      "1     No\n",
      "2    Yes\n",
      "3    Yes\n",
      "4    Yes\n",
      "Name: PlayTennis, dtype: object\n",
      "\n",
      "Now the train data is:\n",
      "    Outlook  Temperature  Humidity  Windy\n",
      "0        2            1         0      0\n",
      "1        2            1         0      1\n",
      "2        0            1         0      0\n",
      "3        1            2         0      0\n",
      "4        1            0         1      0\n",
      "\n",
      "Now the train output is\n",
      " [0 0 1 1 1 0 1 0 1 1 1 1 1 0]\n",
      "Accuracy is: 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "pro6.csv\n",
    "Outlook,Temperature,Humidity,Windy,PlayTennis\n",
    "Sunny,Hot,High,False,No\n",
    "Sunny,Hot,High,True,No\n",
    "Overcast,Hot,High,False,Yes\n",
    "Rainy,Mild,High,False,Yes\n",
    "Rainy,Cool,Normal,False,Yes\n",
    "Rainy,Cool,Normal,True,No\n",
    "Overcast,Cool,Normal,True,Yes\n",
    "Sunny,Mild,High,False,No\n",
    "Sunny,Cool,Normal,False,Yes\n",
    "Rainy,Mild,Normal,False,Yes\n",
    "Sunny,Mild,Normal,True,Yes\n",
    "Overcast,Mild,High,True,Yes\n",
    "Overcast,Hot,Normal,False,Yes\n",
    "Rainy,Mild,High,True,No\n",
    "\n",
    "'''\n",
    "import pandas as pd\n",
    "from sklearn import tree\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "data = pd.read_csv('pro6.csv') \n",
    "print(\"The first 5 values of data is:\\n\",data.head())\n",
    "\n",
    "X = data.iloc[:,:-1]\n",
    "print(\"\\nThe First 5 values of train data is\\n\",X.head())\n",
    "y = data.iloc[:,-1]\n",
    "print(\"\\nThe First 5 values of train output is\\n\",y.head())\n",
    "\n",
    "le_outlook = LabelEncoder()\n",
    "X.Outlook = le_outlook.fit_transform(X.Outlook) \n",
    "le_Temperature = LabelEncoder() \n",
    "X.Temperature = le_Temperature.fit_transform(X.Temperature)\n",
    "le_Humidity = LabelEncoder()\n",
    "X.Humidity = le_Humidity.fit_transform(X.Humidity)\n",
    "le_Windy = LabelEncoder()\n",
    "X.Windy = le_Windy.fit_transform(X.Windy)\n",
    "\n",
    "print(\"\\nNow the train data is:\\n\", X.head())\n",
    "le_PlayTennis = LabelEncoder()\n",
    "y = le_PlayTennis.fit_transform(y)\n",
    "print(\"\\nNow the train output is\\n\",y)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.20)\n",
    "classifier=GaussianNB()\n",
    "classifier.fit(X_train,y_train)\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Accuracy is:\",accuracy_score(classifier.predict(X_test),y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aeb90ef",
   "metadata": {},
   "source": [
    "# Program 7 Source Code ðŸ‘‡\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "619c2467",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\91966\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\91966\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "c:\\Users\\91966\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation: The GMM using EM algorithm based clustering matched the true labels more closely than the Kmeans.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x700 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "from sklearn import datasets \n",
    "from sklearn.cluster import KMeans \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# import some data to play with \n",
    "iris = datasets.load_iris()\n",
    "X = pd.DataFrame(iris.data)\n",
    "X.columns = ['Sepal_Length','Sepal_Width','Petal_Length','Petal_Width'] \n",
    "y = pd.DataFrame(iris.target)\n",
    "y.columns = ['Targets']\n",
    "\n",
    "# Build the K Means Model\n",
    "model = KMeans(n_clusters=3)\n",
    "model.fit(X) # model.labels_ : Gives cluster no for which samples belongs to\n",
    "\n",
    "# # Visualise the clustering results\n",
    "plt.figure(figsize=(14,7))\n",
    "colormap = np.array(['red', 'lime', 'black'])\n",
    "\n",
    "# Plot the Original Classifications using Petal features\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.scatter(X.Petal_Length, X.Petal_Width, c=colormap[y.Targets], s=40) \n",
    "plt.title('Real Clusters')\n",
    "plt.xlabel('Petal Length') \n",
    "plt.ylabel('Petal Width')\n",
    "\n",
    "# Plot the Models Classifications\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.scatter(X.Petal_Length, X.Petal_Width, c=colormap[model.labels_], s=40) \n",
    "plt.title('K-Means Clustering')\n",
    "plt.xlabel('Petal Length') \n",
    "plt.ylabel('Petal Width')\n",
    "\n",
    "# General EM for GMM\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# transform your data such that its distribution will have a # mean value 0 and standard deviation of 1.\n",
    "scaler = preprocessing.StandardScaler() \n",
    "scaler.fit(X)\n",
    "xsa = scaler.transform(X)\n",
    "xs = pd.DataFrame(xsa, columns = X.columns)\n",
    "from sklearn.mixture import GaussianMixture \n",
    "gmm = GaussianMixture(n_components=40) \n",
    "gmm.fit(xs)\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.scatter(X.Petal_Length, X.Petal_Width, c=colormap[0], s=40) \n",
    "plt.title('GMM Clustering')\n",
    "plt.xlabel('Petal Length') \n",
    "plt.ylabel('Petal Width')\n",
    "\n",
    "print('Observation: The GMM using EM algorithm based clustering matched the true labels more closely than the Kmeans.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7358d802",
   "metadata": {},
   "source": [
    "# Program 8 Source Code ðŸ‘‡\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7363b625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iris Data set Loaded...\n",
      "Label 0 - setosa\n",
      "Label 1 - versicolor\n",
      "Label 2 - virginica\n",
      "Results of Classification using k-nn with k=1\n",
      "Sample [6.3 3.3 6.  2.5] Actual-label: 2 Predicted-label: 2\n",
      "Classification Accuracy : 0.9333333333333333\n",
      "Sample [6.  2.7 5.1 1.6] Actual-label: 1 Predicted-label: 2\n",
      "Classification Accuracy : 0.9333333333333333\n",
      "Sample [5.1 3.8 1.9 0.4] Actual-label: 0 Predicted-label: 0\n",
      "Classification Accuracy : 0.9333333333333333\n",
      "Sample [7.4 2.8 6.1 1.9] Actual-label: 2 Predicted-label: 2\n",
      "Classification Accuracy : 0.9333333333333333\n",
      "Sample [5.4 3.4 1.5 0.4] Actual-label: 0 Predicted-label: 0\n",
      "Classification Accuracy : 0.9333333333333333\n",
      "Sample [5.8 2.7 4.1 1. ] Actual-label: 1 Predicted-label: 1\n",
      "Classification Accuracy : 0.9333333333333333\n",
      "Sample [5.7 3.8 1.7 0.3] Actual-label: 0 Predicted-label: 0\n",
      "Classification Accuracy : 0.9333333333333333\n",
      "Sample [5.  3.4 1.5 0.2] Actual-label: 0 Predicted-label: 0\n",
      "Classification Accuracy : 0.9333333333333333\n",
      "Sample [6.7 3.  5.  1.7] Actual-label: 1 Predicted-label: 1\n",
      "Classification Accuracy : 0.9333333333333333\n",
      "Sample [6.  2.9 4.5 1.5] Actual-label: 1 Predicted-label: 1\n",
      "Classification Accuracy : 0.9333333333333333\n",
      "Sample [5.5 3.5 1.3 0.2] Actual-label: 0 Predicted-label: 0\n",
      "Classification Accuracy : 0.9333333333333333\n",
      "Sample [4.8 3.4 1.6 0.2] Actual-label: 0 Predicted-label: 0\n",
      "Classification Accuracy : 0.9333333333333333\n",
      "Sample [6.7 3.3 5.7 2.5] Actual-label: 2 Predicted-label: 2\n",
      "Classification Accuracy : 0.9333333333333333\n",
      "Sample [6.7 3.1 4.7 1.5] Actual-label: 1 Predicted-label: 1\n",
      "Classification Accuracy : 0.9333333333333333\n",
      "Sample [5.5 4.2 1.4 0.2] Actual-label: 0 Predicted-label: 0\n",
      "Classification Accuracy : 0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import datasets\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "print(\"Iris Data set Loaded...\")\n",
    "\n",
    "X_train, X_test, y_train,y_test = train_test_split(iris.data,iris.target,test_size=0.1)\n",
    "\n",
    "#random_state=0\n",
    "\n",
    "for i in range(len(iris.target_names)):\n",
    "    print(\"Label\", i, \"-\",str(iris.target_names[i]))\n",
    "\n",
    "classifier = KNeighborsClassifier(n_neighbors=2)\n",
    "classifier.fit(X_train,y_train)\n",
    "y_pred=classifier.predict(X_test)\n",
    "\n",
    "print(\"Results of Classification using k-nn with k=1\")\n",
    "\n",
    "for r in range(0,len(X_test)):\n",
    "    print(\"Sample\", str(X_test[r]), \"Actual-label:\", str(y_test[r]), \"Predicted-label:\", str(y_pred[r]))\n",
    "\n",
    "    print(\"Classification Accuracy :\", classifier.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689ec4f0",
   "metadata": {},
   "source": [
    "# Program 9 Source Code ðŸ‘‡\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cae28ac9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD4CAYAAADvsV2wAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAAsTAAALEwEAmpwYAAAvDklEQVR4nO2de5hcVZW335XuXDtgQhM13VwiDoN0UFEjAwMjSge5iAQvH4IdIGJM6BaMCiqCiqIIqCNGpAOZgEFTCDiiIAJKGhxgEKWRi3QAuYwIDUgSEiCBEJPs7491dmXXSfW1TtepOrXe56knVbV36uzqqvqdfX577bXEOYdhGIaRfUalPQDDMAyjPJjgG4Zh1Agm+IZhGDWCCb5hGEaNYIJvGIZRI9SnPYC+2HHHHd20adPSHoZhGEZVcc8996xyzk0p1laxgj9t2jS6u7vTHoZhGEZVISJP9tVmlo5hGEaNYIJvGIZRI5jgG4Zh1Agm+IZhGDWCCb5hGEaNkDnBz+VyTJs2jVGjRjFt2jRyuVzaQzIMwxgUI61fUqnZMmfMmOGGGpaZy+U4/vjj2bJlS8Hzra2tLF++PMnhGYZhJMr06dNZsWJFwXNjxozhsssuo62tbdCvIyL3OOdmFGvL1Ax//vz5sGUL5wO7BM93dXUxc+bMtIZlGIbRL83NzXmxnwV4ed+4cSMLFixI7DiZEvz169ezG/Ap4Fa2Ff2Ojo50BmYYhtEH06dP55lnngHgKODnQDtbxXn16tWJHStTgg/wGHAwsAPbiv6iRYtspm8YRsUQzuyPAq4GuoHDgS19/7dhkynBHzVK3849wEyKi35XVxfTp08v/+AMwzACJk+enJ/Zf4itYn8o8FLQr7GxMbFjZkrw58+fn7/fn+ivWLHCZvqGYaRGc3Mza9euBVTsr0LF/hAKxR5g4cKFiR03U4Lf2dlJS0tL/vFAM33z9A3DKDehZ/9hVOzvRsX+5Vjf9vb2IUXoDESmBB+gp6dnG9E3T98wjEog9Ow/DFyJiv2hFBf7zs7ORI+fOcGHbUW/m75F3zx9wzDKQXNzc0E0zpXAnyif2EMCgi8iO4vIrSKyQkR6RGSboFFRfigij4nIAyLyzlKPOxA9PT20trbmH4eifwswNehrnr5hGCNJaOMcwlbP/jC2Fftly5aNiNhDMjP8TcCpzrkWYF/g0yLSEutzGLB7dJsHLErguAOyfPnybUT/EOD1wM3AjkFf8/QNwxgJwh20BwK/BB6kb7FP0rOPU7LgO+eedc79Obr/MvAQ0BzrNgv4iVPuAiaJyFTKwPLlywvsnT8BHwR2A34LvC7ou2jRIhN9wzASIxT7fwOuB54A3g+8GOub9AJtMRL18EVkGvAO4I+xpmbgqeDx02x7UkBE5olIt4h0r1y5MrFxxT39/0EXTPYCbgAagr6LFi2yhGuGYZTMzJkz82L/duBG4Dk0cjC+d3akPPs4iQm+iEwEfgF81jkXDyUdFM65xc65Gc65GVOmFK3BO2zinv5NwLHoWfdaYGzQd/bs2Yke2zCM2qKjo4Ouri4A9kQt5JeBVlT0Q8ol9pCQ4IvIaFTsc865a4p06QV2Dh7vFD1XVuKe/jXAHPRD+DmFFd0nT55c1rEZhpENOjo6WLRIlyl3A5ajC52twN9jfcsp9pBMlI4AlwIPOee+30e364Djo2idfYEXnXPPlnrs4RD39JehiYo+CPwUkOj5tWvXmugbhjEkQrF/A/A71D04GM3zFVJusYfCSe1w2R84DviLiNwXPXcGUbi7c+5i1Co/HH3PrwCfSOC4w6anp6dgMeViYDvgO8DzgI8r9aK/Zs2adAZqGEbVkMvl8mK/PerZvxE4COiJ9U1D7CFjBVCGSrgRAuB7wKnAl4Hzgn5NTU309pbdgTIMo4oYNWoUzjnGomJ/AHAEOssPGemCTDVTAGWo9Pb2MmnSpPzjL6AWz7kUXoI888wzthvXMIw+mTx5Ms45RqEa8j50fTAu9i0tLalW36tpwQdYs2ZNXvQdcCIan78YPTt7VqxYYaJvGMY2TJ48OZ/58kfAR4HPAlfE+rW0tNDTEzd3ykvNCz4Uiv4/gY8Af0bzU+8X9LMUDIZhhIRpjs9CA0DOBeIJjStB7MEEP8+aNWvQgCNYD3wA3Sl2PRpH67EUDIZhQGF+nHnA14HL0IiVkKampooQezDBL+CnP/1p/v4qNO/Oa+gmrTAPhKVgMIzaJozyOwzoRCeH82L9Jk2aVFEBHyb4AW1tbbS3t+cf/w39MHcAfg1MCPpaCgbDqE3iKROuAu4HjgE2B/0mTZpUcSHdJvgxOjs7C0T/fuBjwN7oIkz4BzvuuOPKOjbDMNIll8vlUyY0A78B1qABHutjfStN7MEEvyidnZ0FKRhuAD6Dpvz8XtDPOUdz8zY54AzDyCh+kjcRtXC2Q9f74mkDli1bVt6BDRIT/D6Ip2DoBH4AfA4I3XuL0TeM2sDH2tehEXx7oSGYD8b6lSPN8XAxwe+HeFrlU9GkQD9EvX2PhWsaRrYJwy8vRH//7WgWzJC0UiYMFhP8AQhFfwvwceA+dKHm7UG/rq4uW8Q1jAwyc+bMfPjlAlTozwOWxPpVuthDjefSGQr19fVs3qxr8FPZWuFlBppwzVOpf0/DMIZOmP3yYDRHzq+A/4fuzPdUysYqsFw6iXD55Zfn7z+LLuA2okUARgf9LKWyYWSDUOx3R6/qHwROoFDsJ02aVDFiPxAm+IMkHqN/L5pg7QA0f4Zn7dq1FrljGFVOPNXxdWgRk1kUhl9WYqx9f5jgD4F4jP7VwLfR3XXtQT+L3DGM6uaEE04AVCB/BrwZzbH1ZKxfNYk9mOAPmc7OzoLIna+gu3AXAgcG/VasWGHpFwyjCpk+fXp+ve5ctHLTycDtsX7h5K9asEXbYRKmRN0euAuYArwbTcngqdS/r2EY2xL69rPRsqcXoYIfUkmLtHFs0XYECFMqvwQcCdQB11KYc8cWcQ2jOgjFfm+0JsataG77kEoW+4EwwS+BNWvWUFdXB2ix3mPQ3XeLgz62iGsYlU+4SDsZjb5bhebR2hT0q2axBxP8kgnDNX8HfA1oY9tFXNuJaxiVy5w5cwAQ1MbZCU2bsDLoIyJVLfZggl8ybW1tBYnWvo0mVfoBsE/Qz3biGkZlMnPmTDZt0nn8V9BkaJ8F/hTrF9bLqFZs0TYhmpub89uvJ6ElEuuBd6KXhqAzhC1btqQyPsMwtiX07Q9BM+MuQzdXhbS2tqZafHwo2KJtGejt7c0v4q5FY3anADm2/pEtnbJhVA6hb78rWu/iL8BJsX4tLS1VI/YDYYKfIOEmjHuBTwPvR2tdemxTlmFUBn5z1Rjgv1Ex/AjwatCnrq6u6n37EBP8hAk3Y1wGXAp8FTg06GObsgwjXcLNVd9FkyCeADwe6xcGZWQBE/yEie/EPRktk/gTti2EbhhG+cnlcvmatLPQanYXoPlyQiq5kMlwSUTwReQyEXleROLFX3z7e0XkRRG5L7p9LYnjVio9PT00NTUBsAGNz5+AhnuFf3Czdgyj/HgrZ2f0Kvwe4PRYn9bW1orPbT8ckprhL6XQtSjG7c65vaPb2Qkdt2Lp7e3Nb8p6GDgFaKXwi2WVsgyjvDQ3N7N582bq0EXaenRz1cagT5YWaeMkIvjOuduAF5J4rSwR+n8/Rr9g3wD+Pehj8fmGUR7CylXfQFObz6fQt8/C5qr+KKeHv5+I3C8iN4pIUS9DROaJSLeIdK9cubJYl6oivinrJDS96hVorL7nuOOOK+/ADKPGyOVydHV1AXql/WW0ROGVsX5Z2FzVH4ltvBKRacD1zrm9irRtD2xxzq0TkcOBhc653ft7vWrbeNUfo0ePzu/kmwHciS4QfTToU00bOwyj2vC/wSnAA6gdMYPCEMys/AZT33jlnHvJObcuun8DMFpEdizHsSuBpUuX5u93oz7+R9DLSY9ZO4YxMoSpEy5Fr64/RqHYNzU1ZULsB6Isgi8ibxQRie7vEx13dTmOXQnEyyNeANwE/CdaK9Nj1o5hJEtHR0feypkLfBCdcMXDCXt7e8s8snRIKizzZ8AfgD1E5GkR+aSInCQifpfyR4EHReR+4IfAMa5Sk/iMEGF8vgNOBF5DQzXroj6WesEwkiNMnfBmdKK1HBWgkGqsXDVcLHlamamvr8/v8DsauArdifutoE97e3smY4ANo5yMHz+eDRs2UAfcAewBvBUI5/LVnt++GKl7+MZWwlDNq9HkamcB7wr62C5cwyiNjo4ONmzYAMAZwL5ojYpQ7LOWJ2cwmOCXmXio5snAc6i1Mz7oZ9aOYQyP0MqZgRYlyqFX0yFZy5MzGEzwU2D58uX51AtrgTnAnsB5QR+rkmUYw8NXrxqP5rZ/Fs1cG9La2pq5PDmDwQQ/JcKogC5gIZrEqTXoY6GahjE0Ojo68iGY30J9+znAi0Gfurq6mgjBLIYJfoqE0QGnA4+gu/8agj4+0ZNhGAPjrZz90DKFi4BbYn1q0crxmOCnSGdnZ0FWzROBXYBzgz6bN2+23PmGMQi8BToOzYL5FPDFWJ9atXI8JvgpE2bVvBO4EM2seUDQx6J2DKN/wg1WXwfeAnwKWBf0yXIWzMFigl8BhJeYZwBPoFvAxwV9LGrHMIoTRuW8GzgNtUZvjvWrtRDMYpjgVwBhqOYr6MzkX9EUrh6L2jGM4vionDFoGvJngVNjfWppN21/mOBXCOGl5i3AYvRLG26Xs6gdwygkjMr5CjAdmAe8FPSpq6uznesRJvgVRDgL+QI6U/kxMDroc+KJJ5Z5VIZRuXgrpwX4ErqB8cZYn1qOyoljgl9BhFE7L6FbwfcCPh/02bhxo83yDYOtUTkCXAy8TOFvBSwqJ44JfoURRu1cD1yDbg2fFvSx2Hyj1gkrWH0C+A/0qnhV0MeicrbFBL8CCS9BPwNsBn4UtG/evNkWcI2axi/UTgG+C9yG2p8hFpWzLSb4FUhbWxvjxmlQZi86w/8A8OGgjy3gGrVKWMHqe8BEtF50iEXlFMcEv0JZsmRJ/v6FwL1o4YaJQR+zdoxaI7RyDgKOB84HHgr6WFRO35jgVyhhbP5mtP7tVOCbQR9Lu2DUGnPnzgVgLJon51Hg27E+FpXTNyb4Fczy5cupr68H4G70C34K8I6gj6VdMGqFXC6XL2pyGro5sQPNQ+WxqJz+McGvcJYuXZq/fyawErgIDUXz2AKuUQv4hdqd0BQkP0dr1HpqOe3xYDHBr3BCa+dFNI3yfkA4h7EFXCPrhAu130UnPKfF+piVMzBWxLxKENE5vQB/AHZGizv4bIB1dXX5H4RhZIlcLsfs2bMBOBD4PVoH+uygz5gxY3jttdfKP7gKxIqYZwAfZubQ2Pwm9LLWYwu4RlY56SQNuqxDI9X+Bnwn1ueyyy4r76CqFJvhVxGjR4/Oz+KXAsegyaIeD/pU6udpGMPFX91+Gt2A+GHgl0F7a2urefcBNsPPCOEC7unARuA/Y33MyzeyhA9IaERDkpdTKPa2UDs0TPCriHAB9zm0SPMs4OCgj23GMrJCuMnqbGA71M4MsYXaoWGWThXiL3HHAA8C/wTehm7QArvENbKBtzD3QL/nF6P7UDy2UFucEbd0ROQyEXleRB7so11E5Ici8piIPCAi70ziuLVKY2MjoJbOF9Fc4GGWfAvTNKqdMAzzfLQS3DdifWyhdugkZeksBQ7tp/0wYPfoNg/dNGoMk4ULF+bv/wq4A/0xNAR9rFCKUa2EVs5/oLbluRSmPh4zZoztqB0GiQi+c+424IV+uswCfuKUu4BJIjI1iWPXIqGXD5oHfCqFdTytUIpRrSxYsADQPSffA54CfhDrY7P74VGuRdtm9HPzPB09V4CIzBORbhHpXrlyZZmGVp2EeXbuQreZfwF4Q9DHZvlGNbJ69WoAPgbsg6YUsXw5yVBRUTrOucXOuRnOuRlTpkxJezgVTximeQaaQfDrQbvN8o1qw4dhjkGzYN4LLAvaLQyzNMol+L1oNgDPTtFzRgmE1s5j6MLIXOAtQR+b5RvVQujdnwy8Cc2XE8YRWhhmaZRL8K8Djo+idfYFXnTOPVumY2eacLbzTWA9usDlsVm+US34FArbozbOjcAtsT5m5ZRGUmGZP0Nzeu0hIk+LyCdF5CQR8ZXHbgCeQCei/4WmsTYSYuJErYO1Cs0keBTw7qDdNmMZlU4ul2PdOk0F+HlgBwpzRYGVLUwC23iVAcJsghOB/wPuoTBOtr293cq+GRXLdtttx7p162hEZ4a/BY4O2i0b7OCxXDoZJ/Ty1wHnAYegMcweq4xlVDJ+dv9FdNJyVqzdvPtkMMHPCKGX3wk8S2H9W7DEakZl4iNz3ogu1i6jsCh5Q0ODefcJYYKfIbzH+SpwDlosojVot4gdo9III3POAEazbQqFSy65pNzDyizm4WeMMLHao8AzaElEz7Jly2y2ZFQM3rvfBf2+/hg4KWi3BGlDxzz8GiJMrHY2sC/wgaDdInaMSiGMzPkqGm//rVgfS6GQLCb4GSNMrHY5Ggcb1v60UohGpTB37lwAdgFOABajOVc8liAteUzwM0YYsbMJ9fLfiaYr9VjEjpE2uVyODRs0Q86X0Nm91akdeczDzyjey69HZ/m9wP5Bu8XlG2kyfvx4NmzYwFR038hSCr37hoaGvN1jDA3z8GsQH7GzCS0g8e/Ae4N2m+UbaRHO7k8D6tDvaIhF5owMNsPPML5E3Fh0FrUCmBm0W8SOkQY+MmcK8DfgauATQbuV6CwNm+HXKD598mtojp1WNGrHY3H5RrkJI3M+B4yjMNkfYGI/gpjgZ5hw9n4JmlztzKDdMmka5cZnxJyM7qq9Cvhr0N7Q0FDkfxlJYYKfcbyX/wpwAXAEsHfQbrN8o1yEs/tPA9uhRU5CzLsfWczDrwF8xM72wN+B3wChc29evlEOdtxxR1avXs044EngT8AHg3aLzEkG8/BrHD/LfwktRnA0utnFM3/+/BRGZdQavlbtccDr0QLlITa7H3lM8GuAMN5+IbrJZUHQvn79+nIPyagx/FqRAKcCdwP/E7RbRszyYIJfI/hZ/tPoQtmngNcF7ZZuwRhJfBqFDwJ7YLP7tDAPv4bwXv7ewL3AFyj84VXqd8GobsKKbLcBOwG7A5uDPvbdSw7z8A1ga+3b+4Au1NYZHbTbLN8YCfzs/t/QKmwXUCj2Vqu2fJjg1xAXX3xx/v730JlWWDfU0i0YSRNPo/ACEE+JZjmdyocJfg3R1tbGuHHjALgJ6EF/hCG2EctIEr/RahrwYeBiIAwRsNl9eTHBrzGWLFmSv/991M9/T9BuG7GMpAg3WnUAW9B6yyE2uy8vJvg1RjjLvwJYjW5x91i6BSMpFizQ4N/xwCeBa9A03R6b3ZcfE/waxM/yNwCXAh8CmoN224hlJIHfaPVxYAfgwli7ze7Ljwl+DdLW1pYP0VyEfglCibeNWEaphFeJJwP3A3cE7b72slFeTPBrFL+Y9jfgemAeMCZoN1vHKAX//ToAXSeKz+7D2stG+UhE8EXkUBF5REQeE5HTi7TPEZGVInJfdJubxHGN4RNeTv8IeAPw0aDdFm+N4RIu1p6ChmJeEetjaRTSoWTBF5E64CK0TnYLcKyItBTpepVzbu/otqRIu1Fm/Eas5cAj2OKtkQx+sbYJDcW8FHg1aLfF2vRIYoa/D/CYc+4J59xG4EpgVgKva4wwfiOWQ8Pl9gPeFbTb4q0xHPxi7adQgbFQzMohCcFvBp4KHj9NYdCH5yMi8oCI/LeI7FzshURknoh0i0j3ypUrExia0R/h4u1SdEPMvKB9/fr1Nss3hoRPzzEKOBH4HbpO5LHF2nQp16Ltr4Fpzrm3ATcDlxfr5Jxb7Jyb4ZybMWXKlDINrbbxi2svocWkjwXCInP+8twwBoPPenkIWnPhv2LttlibLkkIfi8Qzth3onB/Bc651c6516KHSyh0DowUCS+vl6Bl58L8Ov7y3DAGw5YtWwC1c/6BzvQ8lvM+fZIQ/LuB3UXkTSIyBjgGuC7sICJTg4dHAg8lcFwjIfxl9p3ACiAeQlXLtk4ul2Ps2LGIyIC3mTNnpj3cVPF2zhvRvPdLgX8G7ZbzvgJwzpV8Aw5Hi88/DpwZPXc2cGR0/1w0V9f9wK3AWwZ6zXe9613OKA/Lli1z6Nqt+xw4B64legy4xsbGtIdYNlpbW/PvO4lbe3t72m+pbIiIA9zp0XfoX2J/C6M8AN2uD121AigGsLU4yo6oH3cR8PmgvVK/J0nQ0dHRb2ro1wO7op7064Cx6KXxi8BatDD8oxSGHsYZN24cS5Ysyayl4YucCPq3+DtwUNDe2NjIqlWr0hlcjdFfAZREZvgjcbMZfnlpbGzMz8SuArcK3JhgdrZs2bK0h5g47e3tRWflLeC+CO46cM9Gs9XB3B4D92NwnwD3hj5m/HV1dZn8W06cONEB7qDob/Hx2PvO4nuuVOhnhp+6sPd1M8EvL6GtMzP60R4d/GDHjBmT9hATo5jQ7wzua+AeDwS8JxLwU8AdAe7t4HaJxPz1kWXx7ujv9BVw14B7Pvq/m8HdCm4uuAlFhL++vj4zIhh+d64Atxrc2Ix+d6oBE3xjUPhZmoB7AtzvMjZLC4XJ394RCfXm6PbbSKSbhujVh7e9wJ0VnTAcuBfAfaePWX9TU1Paf5aS8VeHrwP3KrgLM/a9qTZM8I1BEQri1yMBDIWvmhdvW1paCkToX1HLxgvyN8HtWoLI93XbH9yV4P4Jbl10nO2L9KvmxV3/Hj4Z/T1nxN6bUV76E3zLlmnkCXfeLkMXJj8etFdrTP6ECRNYsWKF3kdDxv6CVvo6Ey2/91XgyUG8Vnt7e8EPqLW1td/+/4vGKe+Jxip/BXiYwkR1oPWEm5uLbVCvbMKQ3ePR9xaGWtjO2gqjrzNB2jeb4adD6G/fCe7+Kr48j1s4+4D7azQLvRT14enn1tLSMqxj1tXV9fma7wTXHY3hWnBTYu3jx48fgb/EyOHtnGnRe/pyFX9fsgJm6RhDwf9Y26Mf8duCH3BDQ0PawxsUYTy9gDsjslX+Bu49/Yh8klE0fUUB1YH7POp394I7MNYuIlUjlH7MX4m+K7tU4Xcla5jgG0PCz9oawW0E990q82RDv74B3C8iMVrWh38OIxs105fwvxXcw+A2gftCFfr64RXUX8HdYrP7isAE3xgS4Q/5V9EsdFSV/JBDsd8J3H2RoH6mD6Ev52y6mPA3oPseHLjOaPZfLaLvJwb7RuOfU2UTg6xigm8MGf+j/Uj0Yz44+CFXarROKPZvjuybNbGxV4KYxiOGBNy3o7/zr8GNq5BxDoQf30XgXgG3XexEaqRDf4JvUTpGUXw1rOvR9AHHBW2VGK0zffr0fCTOdOB2NCLnfWg+7pDx48fjnEutEEdPTw/Lli3LP3bAGcBJaFKqXwHjgv6LFi3KJyarFHx0Tj2aXfVa4OWg3afdNiqMvs4Ead9shp8uoa2zGNxLsZlnJdk64Yx5d3D/APc0uLcUmdVX2kan8ePHF4xvDrr/4aYKn+l7O+f90ZXJLLNzKgZshm8MlTDJ19VonvxDgvZKKX/Y0dGRn9lPRSssCTqzfzjWt7W1ld7eXiqJV155haampvzjpcAngYOBHIX5yxctWlQxqar9Vd7RaPGcm4I2i72vXEzwjT7xP9xbgVUUFkaplPKHPsvl64DfAo3AoWjGxpDW1laWL19e3sENkt7e3m1E/3NoAfDvxfqecMIJ5RtYH3h7aTTwIdTOeS1ot6pWFUxfU/+0b2bppE9o61wC7uWYzZD24m1TU5MjiiD6DRpCelARG6e1tTXVcQ4W/3787YLILjmlwt7PqFGjHOAOi8b3AbNzKgrM0jGGQ9zWmYjOnj1pLt5Onz6dZ555BtBKO4cDpwC3xPq1t7dX7Mw+Tm9vLy0tLfnHpwK/BC5A00B4urq6Ul3E9WUMj0YX9MNFcbNzKhsTfKNf/A/498BKCm2dtAh9+w+h+XAWA/ECeu3t7alF4gyXnp6evOhvQfPTPApchZYO9KTl5/tjjgGOQk9IG4N2s3MqnL6m/mnfzNKpDEJbZ1ERWyeNaB1/7F2iOPs/UFishQqwPUqlvr4+/15a0Eybv6dwA1waeeZ9dM4RkZ1zqNk5FQdm6RjDpZitc1jQvmDBgrKOxxcKHwX8NPr3WApnmU1NTVVj4/TF0qVL8/dXoDH6BwKnBX02btxY9ll+GJ3zAhD+lc3OqXxM8I0B8T/k24DnKbR1yunjd3R00NXVBcAXUV/7ZOBvQR8RqbjQy+HQ1tZGe3t7/vEy4OfAN4G3Bv2OO+44yoU/uYwGjkTtnE1Bu9k5VUBfU/+0b2bpVA5xW+clyl/vNhzDW8BtQHPQELtV0oawJAizfjaiNXbvAzc6hc1k3s452KJzKhosl45RKv5HfWgR77Yc4Znjxo3L5525Da2bGs8lX+2+fV+Efr73zr+Uwi5cf6wfRWsKlRSia2ylP8E3S8cYFN7WuQXNmTIraBtpWyeXy7FhwwYA5gL/gYYsrgz61NXVVb1v3xehn389cA3wNWDXoI/fgDZShGsFs9BNbhuCdrNzqgMTfGNQ+B/0RvTHfiSawsAzkouHc+fOBXQX7fnozt+lsT6XX375iB0/bdra2gpKKS5AQzZ/GOs3krH5fnH+XcBOaIK3+BiNKqCvqX/aN7N0Kg+iy/fZka3w7jJc0ofe/Q/RqlV71oiVEyfciXtq9BkcViYf3b/+N6PPYAezcyoWRtrSEZFDReQREXlMRE4v0j5WRK6K2v8oItOSOK5RXryt8xs0OuPIoG2kbJ05c+YAsAfQjm6weihob2lpyayVE6e3t5e6ujoAFqIbss6n8DLdh60mSdzOuR0NyfSYnVM9lCz4IlIHXISGZ7cAx4pIS6zbJ4E1zrl/QXeKn1/qcY3y43/Ya4A7KPTxIXlbp6Ojg02bNPDvu8B64KxYn56enkSPWel462oTmkP/rehuXE9XV1fin4O3c3aLjndtrN3snOpB9AqghBcQ2Q/4unPukOjxlwGcc+cGfX4b9fmDiNQDzwFTXD8HnzFjhuvu7i5pbEbyiKhz/1n0zL0b8H9RW2NjI6tWrUr8WPujJ5gvAd8J2hsaGli3bl1ix6sW/N8F4C6gGfhX4NXouaT/Lv54nwO+D7yJrXsfkv7MjdIRkXucczOKtSVh6TQDTwWPn46eK9rHObcJeBFdgzOqDG/rXBc9HqlonXAB8uvAP4ALY30uuSSePac2CDdkfQFdRA2Xa0cqdfURwF8o3Ohmdk51UVFROiIyT0S6RaR75cqVA/8Ho+z4H/gTQA/wgRE6zsUXXwzAAcBM1AN8NWhvbW2tWSuhs7OT+vp6QP305WjKhbAsYlIpL/yJYyL6WdwYa6/Vz6BaSULwe4Gdg8c7Rc8V7RNZOq8DtpkOOucWO+dmOOdmTJkyJYGhGUkT/sBvRGPiG4L2JGaWuVwO7/adhc7uLw7asxxzP1jC2PxvoZk0Twzak7ra8ieOg9AMmXHBN6qLJAT/bmB3EXmTiIwBjmHrFb/nOuCE6P5HgVv68++N6uAmYCxaTtCTxMzSx93vR/HZfZZj7gdLW1tbvtD8/7B1jWN00CeJuHx/4jgM3XD3v0GbJUurPkoW/MiTPxndj/MQcLVzrkdEzhYRH7l3KdAoIo8Bnwe2Cd00qgf/Q78djZxJsihKuKv282hE0OJYH7MRFG97gc7ydwHCVGql7r4Nr9YOQ62jfwbt5t9XIX0F6Kd9s41XlUu4Geo6cI8nmMBs4sSJDnDTwG0Cd27stW2TTyEikv/b3AvugQQ/C58sbc9ok9c8S5ZWFWC5dIwkifv4uwG7B+3DtXVyuVw+nPAUNH3Aj2J9bFZZyEknnZS/fyEaJ39g0H7iiSfG/8ug8Vdr/gou9O/NzqlOTPCNYeF/8DdFj5OwdfyJYjs0SdrPKVz9r+XInL4II3auQCMhTgnakyiSchgakRXGXtuJtzoxwTeGhf/B/x/wCIWCP1z8ieI4YHvgB7H2Wo/M6QsfsbMB+C+01mwYNjd//vwhv6Y/STSghWYsHDMbmOAbw6KtrS2/A/MmNFJnbNA+1FllGFHyKeAeNPzLYxZC34SfhV+mbQ/ah7MRy19tvRf9XG8K2uyzqF5M8I1h46LI2puB8WgYpWeoPr7fNftOYG80rCvELIT+8V7+39Gc+XOAuqB9qJ+Hv9pqRUNi7wja7LOoXkzwjWGz665aguM2NJlXa9A2VB9/y5YtgHr3r6J+tKehocEshAHo7OzM3/8xMBU4JGgfyucRXg0chMbevxa022dRvZjgG8PmnHPOAXRDzt2oOIQM1kbw/cYDHwf+G0225KnVnDlDJUxf/TzwiWG+jr8amAK8Ha1yZmQDE3xj2IQzvVuAfdCcK57B2gh+Z+1H0JwbS/o5jtE33mrZBCxD6xWEbvtgd976q4H3Ro+7gjbz76sbE3yjJMJat/Vobh3PYGyEcGdtG5qU7bYir28MTHhiXIrmvjk2aB/qztuDgJfQBXSP+ffVjQm+URJeAO5EwwJb++29Lf4qYEc0b85Vfby+MTj8CfIvwP3Ax2LtQ4nWOQjN07M5eM6utqobE3yjJLwAbEBFP+7jD4S/CvgweoVwZR+vbwyO8AR5NZrSOCxOMZDN5k8IO6FFVUI7Jyy8YlQnJvhGYtwCvAPYIXiuvxll2HYMmnnvgaA9LPRhDI62tjbGjdPM+D+Pnvto0D6QzRamQ4bCBVsfhmtULyb4RmJ4cRhsumTfNhXN/xKf3YehhsbgWbJEl70fBe4Fjo6193cS9ieEg4CVwINBmw/DNaoXE3yjZLxvfDewDt2K7+lvRunbjkK/iFcXeU1j6IQ22NXAv1OYaqGvk3B4IjgQ9e/DOb0PwzWqFxN8o2TCcMC7UN94KByJ5uN5uMhrGsPDnzC9rfOhoK2vk/CZZ54JqOc/Da13EGLrKdWPCb5RMqEQ3IFu1tkuaC9mIYS1Ut8H/Lqf1zSGjj9hPo6ujQym9vCTTz4JwP7RY6tulT1M8I1E8IJwB5rDZaC8Ov6596PJueI1MY3SCE+Y16ObqMJNccVOwj4KZ3/UmrsvaLMrrmxggm8kgheEu1BrJ7R1ilkI/rkjgRfQkE6PzSaT5Xp0E9bM4Ln4STgsHH8A8Ecs/j6LmOAbieAFYT0aGdKfj+9nl6NQq+E3FIqLzSaTwZ8470RrAx8RtMVPwt6/n4hacv+LkUVM8I3EuQP4N2B08FxoIfjZ5bvRHbbXx/6/zSaTIVxMvwk9uYZbp8LPxPv3+6KWXJgO2a64soMJvpEYoY8/Ad2E5QkthDDXOlhyrpEiPHH+BngjfX8mo0apFOyPXm3dFfSzK67sYIJvJIYXBm8HFPPxw1nlTODPaB3W+GsYyeBPoP6k2lfNAl+P4AB0t/PLQT+74soOJvhGYnhh+Ae6y7OYj++94vHohqCuWLuJS7L4E+hzaCHy/pLb1aGWjvn32cUE3xgRbqe44Huv+AA0HDMsS252TvKEJ9AuNH31mKA9l8vlr7reji7ahv69kS1M8I1E8V7wHWjFpD2Ctlwul4/1nglsxGqlloPQ1pmAzuI9CxYsyHv5tuEq+5jgG4nivWAv5OEsf/78+flY71Y0XPCVoN3snJHBn0h9bvu4j++9/P3RIuhPF/m/RjYoSfBFZAcRuVlEHo3+ndxHv80icl90s02VGcZnVHwUrasaVsBav349oGX33kGhnWOMHP5E+iLQTd8+/gFsa+fYSThblDrDPx3ocs7tjl4xnt5Hv1edc3tHtyNLPKZRwYQZFe+guI//PvSLZ+GY5aeLbWsPgyZLa8YWbLNOqYI/C7g8un85munWqGHa2tryPv3twJvRfPchM9FaqXcHz5l1MLKEPv5oClNYEzy2esLZplTBf4Nz7tno/nPAG/roN05EukXkLhE5qq8XE5F5Ub/ulStXljg0Iy28T+/tgf1j7TOBW7FcLeUk3CPxKnBwrP096H6IniL/x8gOMlDZMhFZjm7Si3MmcLlzblLQd41zbhsfX0SanXO9IrIbWhip1Tn3eH/HnTFjhuvu7h7EWzAqjWnTpvHkk09SD6wFLgX8ns43AU8AJwMXBf/HyueNPP7K67eofbNX0PZXVOzDvPn2mVQnInKPc25GsbYBZ/jOuZnOub2K3K4F/iEiU6ODTEXX6Yq9Rm/07xPA7ync4W1kDO/jFyuI4meWN5d5TMZWbgamA03R46nA7hTaOVawPJuUaulcB5wQ3T8BuDbeQUQmi8jY6P6O6BX+ihKPa1QwxQqi+Mu+g9HQv78G/c0rLi/+ZOvTJfsaxKHg2+w+m5Qq+OcBB4vIo+j35zwAEZkhIkuiPnsC3SJyP2rdnuecM8GvEW5At+wfjqZTOAS4MdbHvOLy4E+sDwC9bI2wOBJdgPtz0NcKlmeT+lL+s3NuNUXCep1z3cDc6P6dwFtLOY5RfTQ2NrJ69WruBp4BjkUXabcDror1tQXb8rBw4UJmz56NQ2vdtgO7oWmTr8AKltcCAy7apoUt2lY3uVyO2bNnA/BV4Gy0CMdz6GLhlqBvpX4Hs4j35vcEHkQ3Y01GF9XuC/rZZ1K9lLRoaxjDIZy1Xwg8AjQAn6VQ7M2/Ly8+19FDwAWo2F9Kodgb2aUkS8cw+mPUqFFs2bKFtainNx7dcBVi/n158bmOAE4DzqWwHgHYSTjL2AzfGDFCcfkn24o9mH9fbuKLsduWl7eTcJYxwTdGjIEiPSzWu/wMZjHWTsLZxQTfGDEGEhdbGCw/Jua1jQm+MWIMJC4W620Y5cUE30gNi/VOh/4WZc1myzYm+EZqmL2QDv0typrNlm1M8I0RpS/bxuyc9Ghra+tzlm+fS7YxwTdGlHPOOYcJEyYUPDdhwgSzc1Jm4cKF9rnUICb4xojS1tbG4sWL2XXXXRERdt11VxYvXmx2TsrY51KbWC4dwzCMDGG5dAzDMAwTfMMwjFrBBN8wDKNGMME3DMOoEUzwDcMwaoSKjdIRkZXAkyW8xI7AqoSGkyZZeR9g76VSycp7ycr7gNLey67OuSnFGipW8EtFRLr7Ck2qJrLyPsDeS6WSlfeSlfcBI/dezNIxDMOoEUzwDcMwaoQsC/7itAeQEFl5H2DvpVLJynvJyvuAEXovmfXwDcMwjEKyPMM3DMMwAkzwDcMwaoTMCr6IfFNEHhCR+0TkdyLSlPaYhouIfFdEHo7ezy9FZFLaYxouIvL/RKRHRLaISNWF0InIoSLyiIg8JiKnpz2eUhCRy0TkeRF5MO2xlIKI7Cwit4rIiui7tSDtMQ0XERknIn8Skfuj9/KNRF8/qx6+iGzvnHspuv8ZoMU5d1LKwxoWIvJ+4Bbn3CYROR/AOfellIc1LERkT2ALcAlwmnOuanJgi0gd8FfgYOBp4G7gWOfcilQHNkxE5D3AOuAnzrm90h7PcBGRqcBU59yfRWQ74B7gqGr8XESLCjc459aJyGjgDmCBc+6uJF4/szN8L/YRDUDVntmcc79zzm2KHt4F7JTmeErBOfeQc+6RtMcxTPYBHnPOPeGc2whcCcxKeUzDxjl3G/BC2uMoFefcs865P0f3XwYeAprTHdXwcMq66OHo6JaYdmVW8AFE5BwReQpoA76W9ngS4kTgxrQHUaM0A08Fj5+mSoUlq4jINOAdwB9THsqwEZE6EbkPeB642TmX2HupasEXkeUi8mCR2ywA59yZzrmdgRxwcrqj7Z+B3kvU50xgE/p+KpbBvBfDSBoRmQj8Avhs7Aq/qnDObXbO7Y1eye8jIonZbfVJvVAaOOdmDrJrDrgBOGsEh1MSA70XEZkDHAG0ugpfeBnC51Jt9AI7B493ip4zUibyu38B5Jxz16Q9niRwzq0VkVuBQ4FEFtareobfHyKye/BwFvBwWmMpFRE5FPgicKRz7pW0x1PD3A3sLiJvEpExwDHAdSmPqeaJFjovBR5yzn0/7fGUgohM8VF4IjIeDRBITLuyHKXzC2APNCLkSeAk51xVzsZE5DFgLLA6euquKo44+hBwITAFWAvc55w7JNVBDQERORz4AVAHXOacOyfdEQ0fEfkZ8F40Fe8/gLOcc5emOqhhICIHALcDf0F/7wBnOOduSG9Uw0NE3gZcjn6/RgFXO+fOTuz1syr4hmEYRiGZtXQMwzCMQkzwDcMwagQTfMMwjBrBBN8wDKNGMME3DMOoEUzwDcMwagQTfMMwjBrh/wNsQiw4QcwL/wAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def local_regression(x0, X,Y,tau):\n",
    "    x0=[1,x0]\n",
    "    X=[[1,i] for i in X ]\n",
    "    X=np.asarray(X)\n",
    "    xw = (X.T) * np.exp(np.sum((X-x0)**2,axis=1)/(-2*tau)) \n",
    "    beta = np.linalg.pinv(xw @ X) @ xw @ Y @x0\n",
    "    return beta\n",
    "\n",
    "def draw(tau):\n",
    "    prediction=[local_regression(x0,X,Y,tau) for x0 in domain]\n",
    "    plt.plot(X,Y,'o',color=\"black\")\n",
    "    plt.plot(domain,prediction,color=\"red\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "X = np.linspace(-3,3,num=1000)\n",
    "domain = X\n",
    "Y = np.log(np.abs(X**2-1)+.5)\n",
    "\n",
    "draw(10)\n",
    "draw(0.1)\n",
    "draw(0.01)\n",
    "draw(0.001)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
