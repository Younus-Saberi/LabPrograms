{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2052c1d-2847-46d6-adea-ee732388352a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Program 1 Source Code ðŸ‘‡\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2fb57d-a71d-405a-b71b-0faf1ef8b654",
   "metadata": {},
   "outputs": [],
   "source": [
    "from heuristicsearch.a_star_search import AStar\n",
    "\n",
    "print(\"Graph-1\")\n",
    "\n",
    "heuristic = {'A':1,'B':1,'C':11,'D':1}\n",
    "adjance_list = {'A':[('B',1),('C',3),('D',7),],'B':[('D',5 )],'C':[('D',12)]}\n",
    "\n",
    "graph=AStar(adjance_list,heuristic)\n",
    "graph.apply_a_star(start='A',stop='D')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deeb8580-f7b2-4100-9f3b-55753a9d90fd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Program 2 Source Code ðŸ‘‡\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac1577d-5ad0-48c3-90ca-571a17c8311a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from heuristicsearch.ao_star import AOStar\n",
    "print(\"Graph-1\")\n",
    "heuristic={'A':1,'B':6,'C':12,'D':10,'E':4,'G':5,'H':7}\n",
    "adjancency_list = {'A':[[('B',1),('C',1)],[('D',1)]],\n",
    "                   'B':[[('G',1)],[('H',1)]],\n",
    "                   'C':[[('J',1)]],\n",
    "                   'D':[[('E',1),('F',1)]],\n",
    "                   'G':[[('I',1)]]\n",
    "                  }\n",
    "graph=AOStar(adjancency_list, heuristic, 'A')\n",
    "graph.applyAOStar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3adbca7-d00a-40d9-b552-8da65dce052b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Program 3 Source CodeðŸ‘‡\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74a3d429-5889-4a1a-b1c9-33fea01bf7bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Steps for candidate elimination algorithm 1\n",
      "['Sunny', 'Warm', '?', 'Strong', 'Warm', 'Same']\n",
      "[['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?']]\n",
      "\n",
      " Steps for candidate elimination algorithm 2\n",
      "['Sunny', 'Warm', '?', 'Strong', 'Warm', 'Same']\n",
      "[['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?']]\n",
      "\n",
      " Steps for candidate elimination algorithm 3\n",
      "['Sunny', 'Warm', '?', 'Strong', 'Warm', 'Same']\n",
      "[['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?']]\n",
      "\n",
      " Steps for candidate elimination algorithm 4\n",
      "['?', 'Warm', '?', 'Strong', '?', '?']\n",
      "[['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?']]\n",
      "\n",
      " Final Specific Hypothesis:\n",
      " ['?', 'Warm', '?', 'Strong', '?', '?']\n",
      "\n",
      " Final General Hypothesis:\n",
      " []\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Copy the CSV File Format as given below\n",
    "\n",
    "Sunny,Warm,Normal,Strong,Warm,Same,Yes\n",
    "Sunny,Warm,High,Strong,Warm,Same,Yes\n",
    "Rainy,Cold,High,Strong,Warm,Change,No \n",
    "Rainy,Warm,High,Strong,Cool,Change,Yes\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "import csv\n",
    "\n",
    "with open('pro3.csv') as f:\n",
    "    csv_file=csv.reader(f)\n",
    "    data=list(csv_file)\n",
    "\n",
    "    s=data[1][:-1]\n",
    "    g=[['?' for i in range(len(s))] for j in range(len(s))] \n",
    "\n",
    "    for i in data:\n",
    "        if i[-1]==\"Yes\":\n",
    "            for j in range(len(s)):\n",
    "                if i[j]!=s[j]:\n",
    "                    s[j]='?'\n",
    "                    g[j][j]='?'\n",
    "        elif i[-1]==\"No\":\n",
    "            for j in range(len(s)):\n",
    "                if i[j]!=s[j]:\n",
    "                    g[j][j]=s[j]\n",
    "                else:\n",
    "                    g[j][j]=\"?\"\n",
    "        print(\"\\n Steps for candidate elimination algorithm\",data.index(i)+1)\n",
    "        print(s)\n",
    "        print(g)\n",
    "\n",
    "    gh=[]\n",
    "\n",
    "    for i in g:\n",
    "        for j in i:\n",
    "            if j!=\"?\":\n",
    "                gh.append(i)\n",
    "                break\n",
    "\n",
    "    print(\"\\n Final Specific Hypothesis:\\n\",s)\n",
    "    print(\"\\n Final General Hypothesis:\\n\", gh)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba1bc87-6032-47ba-a9d2-f6396da28418",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Program 4 Source CodeðŸ‘‡\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20246fe6-4b68-4f84-8921-e6005d843b99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "X= [[0,0],[1,1]]\n",
    "Y= [0,1]\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(X,Y)\n",
    "clf.predict([[2.,2.]])\n",
    "clf.predict_proba([[2.,2.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12908f39-d659-45f8-b9e7-c373025bc813",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(167.4, 199.32, 'X[3] <= 0.8\\ngini = 0.667\\nsamples = 150\\nvalue = [50, 50, 50]'),\n",
       " Text(141.64615384615385, 163.07999999999998, 'gini = 0.0\\nsamples = 50\\nvalue = [50, 0, 0]'),\n",
       " Text(193.15384615384616, 163.07999999999998, 'X[3] <= 1.75\\ngini = 0.5\\nsamples = 100\\nvalue = [0, 50, 50]'),\n",
       " Text(103.01538461538462, 126.83999999999999, 'X[2] <= 4.95\\ngini = 0.168\\nsamples = 54\\nvalue = [0, 49, 5]'),\n",
       " Text(51.50769230769231, 90.6, 'X[3] <= 1.65\\ngini = 0.041\\nsamples = 48\\nvalue = [0, 47, 1]'),\n",
       " Text(25.753846153846155, 54.359999999999985, 'gini = 0.0\\nsamples = 47\\nvalue = [0, 47, 0]'),\n",
       " Text(77.26153846153846, 54.359999999999985, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(154.52307692307693, 90.6, 'X[3] <= 1.55\\ngini = 0.444\\nsamples = 6\\nvalue = [0, 2, 4]'),\n",
       " Text(128.76923076923077, 54.359999999999985, 'gini = 0.0\\nsamples = 3\\nvalue = [0, 0, 3]'),\n",
       " Text(180.27692307692308, 54.359999999999985, 'X[2] <= 5.45\\ngini = 0.444\\nsamples = 3\\nvalue = [0, 2, 1]'),\n",
       " Text(154.52307692307693, 18.119999999999976, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 2, 0]'),\n",
       " Text(206.03076923076924, 18.119999999999976, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(283.2923076923077, 126.83999999999999, 'X[2] <= 4.85\\ngini = 0.043\\nsamples = 46\\nvalue = [0, 1, 45]'),\n",
       " Text(257.53846153846155, 90.6, 'X[0] <= 5.95\\ngini = 0.444\\nsamples = 3\\nvalue = [0, 1, 2]'),\n",
       " Text(231.7846153846154, 54.359999999999985, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1, 0]'),\n",
       " Text(283.2923076923077, 54.359999999999985, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 0, 2]'),\n",
       " Text(309.04615384615386, 90.6, 'gini = 0.0\\nsamples = 43\\nvalue = [0, 0, 43]')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn import tree\n",
    "iris= load_iris()\n",
    "X,y = iris.data,iris.target\n",
    "clf=tree.DecisionTreeClassifier()\n",
    "clf=clf.fit(X,y)\n",
    "tree.plot_tree(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65094142-a355-4481-9fe8-36f106cf0a45",
   "metadata": {},
   "source": [
    "# Program 5 Source CodeðŸ‘‡\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e41c50e2-6634-47d8-8df6-d8660230de6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3. 9.]\n",
      "Epoch: 0\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.13133583]\n",
      " [0.11581562]\n",
      " [0.14887947]]\n",
      "Loss: \n",
      " 0.575020400949051\n",
      "\n",
      "\n",
      "Epoch: 1\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.13521395]\n",
      " [0.1185091 ]\n",
      " [0.15298044]]\n",
      "Loss: \n",
      " 0.5696319105106183\n",
      "\n",
      "\n",
      "Epoch: 2\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.13920739]\n",
      " [0.12127803]\n",
      " [0.15718956]]\n",
      "Loss: \n",
      " 0.5641194679592688\n",
      "\n",
      "\n",
      "Epoch: 3\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.14331629]\n",
      " [0.12412318]\n",
      " [0.16150605]]\n",
      "Loss: \n",
      " 0.5584852357832896\n",
      "\n",
      "\n",
      "Epoch: 4\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.1475404 ]\n",
      " [0.12704521]\n",
      " [0.16592878]]\n",
      "Loss: \n",
      " 0.5527318956586796\n",
      "\n",
      "\n",
      "Epoch: 5\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.15187906]\n",
      " [0.1300446 ]\n",
      " [0.17045618]]\n",
      "Loss: \n",
      " 0.5468626574021602\n",
      "\n",
      "\n",
      "Epoch: 6\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.15633119]\n",
      " [0.13312166]\n",
      " [0.17508629]]\n",
      "Loss: \n",
      " 0.5408812621086904\n",
      "\n",
      "\n",
      "Epoch: 7\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.16089528]\n",
      " [0.13627651]\n",
      " [0.17981674]]\n",
      "Loss: \n",
      " 0.5347919789771235\n",
      "\n",
      "\n",
      "Epoch: 8\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.16556936]\n",
      " [0.1395091 ]\n",
      " [0.18464472]]\n",
      "Loss: \n",
      " 0.5285995954486341\n",
      "\n",
      "\n",
      "Epoch: 9\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.17035104]\n",
      " [0.14281918]\n",
      " [0.18956706]]\n",
      "Loss: \n",
      " 0.5223094004278016\n",
      "\n",
      "\n",
      "Epoch: 10\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.17523747]\n",
      " [0.14620628]\n",
      " [0.19458014]]\n",
      "Loss: \n",
      " 0.5159271605217057\n",
      "\n",
      "\n",
      "Epoch: 11\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.18022537]\n",
      " [0.14966975]\n",
      " [0.19968   ]]\n",
      "Loss: \n",
      " 0.50945908941247\n",
      "\n",
      "\n",
      "Epoch: 12\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.18531103]\n",
      " [0.15320873]\n",
      " [0.20486231]]\n",
      "Loss: \n",
      " 0.5029118106664369\n",
      "\n",
      "\n",
      "Epoch: 13\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.19049035]\n",
      " [0.15682214]\n",
      " [0.21012243]]\n",
      "Loss: \n",
      " 0.49629231447062866\n",
      "\n",
      "\n",
      "Epoch: 14\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.19575884]\n",
      " [0.16050873]\n",
      " [0.21545539]]\n",
      "Loss: \n",
      " 0.48960790896583406\n",
      "\n",
      "\n",
      "Epoch: 15\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.20111168]\n",
      " [0.16426702]\n",
      " [0.22085599]]\n",
      "Loss: \n",
      " 0.4828661670071169\n",
      "\n",
      "\n",
      "Epoch: 16\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.20654372]\n",
      " [0.16809537]\n",
      " [0.22631881]]\n",
      "Loss: \n",
      " 0.476074869318825\n",
      "\n",
      "\n",
      "Epoch: 17\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.21204955]\n",
      " [0.17199195]\n",
      " [0.23183823]]\n",
      "Loss: \n",
      " 0.4692419451155811\n",
      "\n",
      "\n",
      "Epoch: 18\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.21762354]\n",
      " [0.17595474]\n",
      " [0.23740853]]\n",
      "Loss: \n",
      " 0.46237541132815396\n",
      "\n",
      "\n",
      "Epoch: 19\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.22325986]\n",
      " [0.1799816 ]\n",
      " [0.24302389]]\n",
      "Loss: \n",
      " 0.4554833116004457\n",
      "\n",
      "\n",
      "Epoch: 20\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.22895257]\n",
      " [0.18407022]\n",
      " [0.24867844]]\n",
      "Loss: \n",
      " 0.4485736562102803\n",
      "\n",
      "\n",
      "Epoch: 21\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.23469562]\n",
      " [0.18821817]\n",
      " [0.25436632]]\n",
      "Loss: \n",
      " 0.4416543640136347\n",
      "\n",
      "\n",
      "Epoch: 22\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.24048293]\n",
      " [0.19242292]\n",
      " [0.26008174]]\n",
      "Loss: \n",
      " 0.43473320742297483\n",
      "\n",
      "\n",
      "Epoch: 23\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.24630842]\n",
      " [0.19668183]\n",
      " [0.26581898]]\n",
      "Loss: \n",
      " 0.42781776131080584\n",
      "\n",
      "\n",
      "Epoch: 24\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.2521661 ]\n",
      " [0.20099218]\n",
      " [0.27157245]]\n",
      "Loss: \n",
      " 0.42091535658610385\n",
      "\n",
      "\n",
      "Epoch: 25\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.25805002]\n",
      " [0.20535119]\n",
      " [0.27733673]]\n",
      "Loss: \n",
      " 0.4140330390315816\n",
      "\n",
      "\n",
      "Epoch: 26\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.26395441]\n",
      " [0.20975604]\n",
      " [0.28310661]]\n",
      "Loss: \n",
      " 0.4071775338215917\n",
      "\n",
      "\n",
      "Epoch: 27\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.26987366]\n",
      " [0.21420389]\n",
      " [0.28887708]]\n",
      "Loss: \n",
      " 0.40035521597154444\n",
      "\n",
      "\n",
      "Epoch: 28\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.27580234]\n",
      " [0.21869185]\n",
      " [0.29464339]]\n",
      "Loss: \n",
      " 0.393572086807029\n",
      "\n",
      "\n",
      "Epoch: 29\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.28173528]\n",
      " [0.22321707]\n",
      " [0.30040106]]\n",
      "Loss: \n",
      " 0.3868337563902715\n",
      "\n",
      "\n",
      "Epoch: 30\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.28766753]\n",
      " [0.22777669]\n",
      " [0.30614588]]\n",
      "Loss: \n",
      " 0.38014543170787163\n",
      "\n",
      "\n",
      "Epoch: 31\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.29359445]\n",
      " [0.23236788]\n",
      " [0.31187394]]\n",
      "Loss: \n",
      " 0.373511910310192\n",
      "\n",
      "\n",
      "Epoch: 32\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.29951164]\n",
      " [0.23698786]\n",
      " [0.31758162]]\n",
      "Loss: \n",
      " 0.36693757900125346\n",
      "\n",
      "\n",
      "Epoch: 33\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.30541503]\n",
      " [0.24163388]\n",
      " [0.32326558]]\n",
      "Loss: \n",
      " 0.36042641710910894\n",
      "\n",
      "\n",
      "Epoch: 34\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.3113008 ]\n",
      " [0.24630326]\n",
      " [0.32892282]]\n",
      "Loss: \n",
      " 0.35398200381990885\n",
      "\n",
      "\n",
      "Epoch: 35\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.31716548]\n",
      " [0.25099337]\n",
      " [0.33455058]]\n",
      "Loss: \n",
      " 0.3476075290327871\n",
      "\n",
      "\n",
      "Epoch: 36\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.32300586]\n",
      " [0.25570168]\n",
      " [0.34014642]]\n",
      "Loss: \n",
      " 0.341305807185144\n",
      "\n",
      "\n",
      "Epoch: 37\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.32881904]\n",
      " [0.26042569]\n",
      " [0.34570817]]\n",
      "Loss: \n",
      " 0.3350792935063159\n",
      "\n",
      "\n",
      "Epoch: 38\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.33460239]\n",
      " [0.26516302]\n",
      " [0.3512339 ]]\n",
      "Loss: \n",
      " 0.32893010217915863\n",
      "\n",
      "\n",
      "Epoch: 39\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.34035356]\n",
      " [0.26991135]\n",
      " [0.35672196]]\n",
      "Loss: \n",
      " 0.32286002592088964\n",
      "\n",
      "\n",
      "Epoch: 40\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.34607047]\n",
      " [0.27466844]\n",
      " [0.36217093]]\n",
      "Loss: \n",
      " 0.3168705565338467\n",
      "\n",
      "\n",
      "Epoch: 41\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.35175128]\n",
      " [0.27943216]\n",
      " [0.36757958]]\n",
      "Loss: \n",
      " 0.3109629060211096\n",
      "\n",
      "\n",
      "Epoch: 42\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.35739439]\n",
      " [0.28420043]\n",
      " [0.37294693]]\n",
      "Loss: \n",
      " 0.3051380279089287\n",
      "\n",
      "\n",
      "Epoch: 43\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.36299842]\n",
      " [0.2889713 ]\n",
      " [0.37827216]]\n",
      "Loss: \n",
      " 0.29939663846570297\n",
      "\n",
      "\n",
      "Epoch: 44\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.36856219]\n",
      " [0.29374285]\n",
      " [0.38355464]]\n",
      "Loss: \n",
      " 0.29373923755430226\n",
      "\n",
      "\n",
      "Epoch: 45\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.37408472]\n",
      " [0.29851329]\n",
      " [0.38879389]]\n",
      "Loss: \n",
      " 0.28816612889959975\n",
      "\n",
      "\n",
      "Epoch: 46\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.37956518]\n",
      " [0.30328088]\n",
      " [0.39398956]]\n",
      "Loss: \n",
      " 0.28267743959529307\n",
      "\n",
      "\n",
      "Epoch: 47\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.38500294]\n",
      " [0.30804397]\n",
      " [0.39914146]]\n",
      "Loss: \n",
      " 0.27727313871282505\n",
      "\n",
      "\n",
      "Epoch: 48\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.39039747]\n",
      " [0.31280098]\n",
      " [0.40424949]]\n",
      "Loss: \n",
      " 0.2719530549101176\n",
      "\n",
      "\n",
      "Epoch: 49\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.3957484 ]\n",
      " [0.3175504 ]\n",
      " [0.40931364]]\n",
      "Loss: \n",
      " 0.26671689296873535\n",
      "\n",
      "\n",
      "Epoch: 50\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.40105546]\n",
      " [0.3222908 ]\n",
      " [0.41433402]]\n",
      "Loss: \n",
      " 0.2615642492150124\n",
      "\n",
      "\n",
      "Epoch: 51\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.40631848]\n",
      " [0.32702081]\n",
      " [0.41931077]]\n",
      "Loss: \n",
      " 0.25649462580372756\n",
      "\n",
      "\n",
      "Epoch: 52\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.41153738]\n",
      " [0.3317391 ]\n",
      " [0.42424414]]\n",
      "Loss: \n",
      " 0.2515074438623291\n",
      "\n",
      "\n",
      "Epoch: 53\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.41671216]\n",
      " [0.33644445]\n",
      " [0.4291344 ]]\n",
      "Loss: \n",
      " 0.24660205550975225\n",
      "\n",
      "\n",
      "Epoch: 54\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.4218429 ]\n",
      " [0.34113565]\n",
      " [0.43398186]]\n",
      "Loss: \n",
      " 0.2417777547768767\n",
      "\n",
      "\n",
      "Epoch: 55\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.42692969]\n",
      " [0.34581155]\n",
      " [0.43878688]]\n",
      "Loss: \n",
      " 0.23703378746594414\n",
      "\n",
      "\n",
      "Epoch: 56\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.43197272]\n",
      " [0.35047108]\n",
      " [0.44354985]]\n",
      "Loss: \n",
      " 0.2323693599941493\n",
      "\n",
      "\n",
      "Epoch: 57\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.43697218]\n",
      " [0.3551132 ]\n",
      " [0.44827115]]\n",
      "Loss: \n",
      " 0.22778364727243985\n",
      "\n",
      "\n",
      "Epoch: 58\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.4419283 ]\n",
      " [0.35973689]\n",
      " [0.45295119]]\n",
      "Loss: \n",
      " 0.22327579967461356\n",
      "\n",
      "\n",
      "Epoch: 59\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.44684133]\n",
      " [0.3643412 ]\n",
      " [0.45759038]]\n",
      "Loss: \n",
      " 0.21884494915436994\n",
      "\n",
      "\n",
      "Epoch: 60\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.45171154]\n",
      " [0.36892523]\n",
      " [0.46218914]]\n",
      "Loss: \n",
      " 0.21449021456930195\n",
      "\n",
      "\n",
      "Epoch: 61\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.4565392 ]\n",
      " [0.37348808]\n",
      " [0.46674787]]\n",
      "Loss: \n",
      " 0.21021070627112995\n",
      "\n",
      "\n",
      "Epoch: 62\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.4613246 ]\n",
      " [0.37802892]\n",
      " [0.47126697]]\n",
      "Loss: \n",
      " 0.2060055300209754\n",
      "\n",
      "\n",
      "Epoch: 63\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.46606802]\n",
      " [0.38254694]\n",
      " [0.47574682]]\n",
      "Loss: \n",
      " 0.20187379028732189\n",
      "\n",
      "\n",
      "Epoch: 64\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.47076972]\n",
      " [0.38704135]\n",
      " [0.48018779]]\n",
      "Loss: \n",
      " 0.19781459298265405\n",
      "\n",
      "\n",
      "Epoch: 65\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.47542999]\n",
      " [0.3915114 ]\n",
      " [0.48459023]]\n",
      "Loss: \n",
      " 0.1938270476927242\n",
      "\n",
      "\n",
      "Epoch: 66\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.48004907]\n",
      " [0.39595638]\n",
      " [0.48895448]]\n",
      "Loss: \n",
      " 0.18991026945007702\n",
      "\n",
      "\n",
      "Epoch: 67\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.48462722]\n",
      " [0.40037558]\n",
      " [0.49328085]]\n",
      "Loss: \n",
      " 0.1860633801009404\n",
      "\n",
      "\n",
      "Epoch: 68\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.48916467]\n",
      " [0.40476835]\n",
      " [0.49756963]]\n",
      "Loss: \n",
      " 0.18228550931194235\n",
      "\n",
      "\n",
      "Epoch: 69\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.49366164]\n",
      " [0.40913403]\n",
      " [0.50182109]]\n",
      "Loss: \n",
      " 0.17857579526038458\n",
      "\n",
      "\n",
      "Epoch: 70\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.49811832]\n",
      " [0.41347201]\n",
      " [0.50603547]]\n",
      "Loss: \n",
      " 0.1749333850490452\n",
      "\n",
      "\n",
      "Epoch: 71\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.5025349]\n",
      " [0.4177817]\n",
      " [0.510213 ]]\n",
      "Loss: \n",
      " 0.17135743488372254\n",
      "\n",
      "\n",
      "Epoch: 72\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.50691156]\n",
      " [0.4220625 ]\n",
      " [0.51435386]]\n",
      "Loss: \n",
      " 0.167847110049003\n",
      "\n",
      "\n",
      "Epoch: 73\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.51124843]\n",
      " [0.42631389]\n",
      " [0.51845825]]\n",
      "Loss: \n",
      " 0.1644015847150468\n",
      "\n",
      "\n",
      "Epoch: 74\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.51554567]\n",
      " [0.43053532]\n",
      " [0.52252632]]\n",
      "Loss: \n",
      " 0.1610200416055687\n",
      "\n",
      "\n",
      "Epoch: 75\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.51980337]\n",
      " [0.43472629]\n",
      " [0.5265582 ]]\n",
      "Loss: \n",
      " 0.1577016715546391\n",
      "\n",
      "\n",
      "Epoch: 76\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.52402165]\n",
      " [0.43888631]\n",
      " [0.530554  ]]\n",
      "Loss: \n",
      " 0.15444567297746678\n",
      "\n",
      "\n",
      "Epoch: 77\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.5282006 ]\n",
      " [0.44301491]\n",
      " [0.53451384]]\n",
      "Loss: \n",
      " 0.1512512512779473\n",
      "\n",
      "\n",
      "Epoch: 78\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.53234027]\n",
      " [0.44711165]\n",
      " [0.53843777]]\n",
      "Loss: \n",
      " 0.1481176182134778\n",
      "\n",
      "\n",
      "Epoch: 79\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.53644075]\n",
      " [0.4511761 ]\n",
      " [0.54232588]]\n",
      "Loss: \n",
      " 0.14504399123535036\n",
      "\n",
      "\n",
      "Epoch: 80\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.54050207]\n",
      " [0.45520786]\n",
      " [0.5461782 ]]\n",
      "Loss: \n",
      " 0.14202959282095043\n",
      "\n",
      "\n",
      "Epoch: 81\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.54452428]\n",
      " [0.45920655]\n",
      " [0.54999478]]\n",
      "Loss: \n",
      " 0.13907364981199835\n",
      "\n",
      "\n",
      "Epoch: 82\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.54850741]\n",
      " [0.46317181]\n",
      " [0.55377564]]\n",
      "Loss: \n",
      " 0.13617539277119026\n",
      "\n",
      "\n",
      "Epoch: 83\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.55245148]\n",
      " [0.46710328]\n",
      " [0.5575208 ]]\n",
      "Loss: \n",
      " 0.13333405536781232\n",
      "\n",
      "\n",
      "Epoch: 84\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.55635651]\n",
      " [0.47100065]\n",
      " [0.56123027]]\n",
      "Loss: \n",
      " 0.13054887380123267\n",
      "\n",
      "\n",
      "Epoch: 85\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.56022251]\n",
      " [0.47486362]\n",
      " [0.56490404]]\n",
      "Loss: \n",
      " 0.12781908626960028\n",
      "\n",
      "\n",
      "Epoch: 86\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.56404949]\n",
      " [0.47869191]\n",
      " [0.56854211]]\n",
      "Loss: \n",
      " 0.1251439324896244\n",
      "\n",
      "\n",
      "Epoch: 87\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.56783746]\n",
      " [0.48248527]\n",
      " [0.57214448]]\n",
      "Loss: \n",
      " 0.1225226532719465\n",
      "\n",
      "\n",
      "Epoch: 88\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.57158643]\n",
      " [0.48624344]\n",
      " [0.57571114]]\n",
      "Loss: \n",
      " 0.11995449015537064\n",
      "\n",
      "\n",
      "Epoch: 89\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.5752964 ]\n",
      " [0.48996623]\n",
      " [0.57924207]]\n",
      "Loss: \n",
      " 0.11743868510207202\n",
      "\n",
      "\n",
      "Epoch: 90\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.5789674 ]\n",
      " [0.49365342]\n",
      " [0.58273726]]\n",
      "Loss: \n",
      " 0.11497448025486358\n",
      "\n",
      "\n",
      "Epoch: 91\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.58259943]\n",
      " [0.49730485]\n",
      " [0.58619671]]\n",
      "Loss: \n",
      " 0.11256111775666477\n",
      "\n",
      "\n",
      "Epoch: 92\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.58619251]\n",
      " [0.50092037]\n",
      " [0.58962042]]\n",
      "Loss: \n",
      " 0.11019783963147939\n",
      "\n",
      "\n",
      "Epoch: 93\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.58974667]\n",
      " [0.50449983]\n",
      " [0.59300837]]\n",
      "Loss: \n",
      " 0.10788388772545321\n",
      "\n",
      "\n",
      "Epoch: 94\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.59326193]\n",
      " [0.50804313]\n",
      " [0.59636059]]\n",
      "Loss: \n",
      " 0.10561850370594035\n",
      "\n",
      "\n",
      "Epoch: 95\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.59673835]\n",
      " [0.51155017]\n",
      " [0.59967706]]\n",
      "Loss: \n",
      " 0.10340092911595615\n",
      "\n",
      "\n",
      "Epoch: 96\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.60017596]\n",
      " [0.51502088]\n",
      " [0.60295783]]\n",
      "Loss: \n",
      " 0.10123040548093563\n",
      "\n",
      "\n",
      "Epoch: 97\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.60357483]\n",
      " [0.51845521]\n",
      " [0.60620291]]\n",
      "Loss: \n",
      " 0.09910617446433674\n",
      "\n",
      "\n",
      "Epoch: 98\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.60693502]\n",
      " [0.52185312]\n",
      " [0.60941233]]\n",
      "Loss: \n",
      " 0.0970274780683303\n",
      "\n",
      "\n",
      "Epoch: 99\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.6102566 ]\n",
      " [0.52521461]\n",
      " [0.61258615]]\n",
      "Loss: \n",
      " 0.09499355887559428\n",
      "\n",
      "\n",
      "Epoch: 100\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.61353967]\n",
      " [0.52853968]\n",
      " [0.61572441]]\n",
      "Loss: \n",
      " 0.0930036603280739\n",
      "\n",
      "\n",
      "Epoch: 101\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.61678432]\n",
      " [0.53182835]\n",
      " [0.61882718]]\n",
      "Loss: \n",
      " 0.0910570270384778\n",
      "\n",
      "\n",
      "Epoch: 102\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.61999067]\n",
      " [0.53508066]\n",
      " [0.62189453]]\n",
      "Loss: \n",
      " 0.08915290513024539\n",
      "\n",
      "\n",
      "Epoch: 103\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.62315884]\n",
      " [0.53829669]\n",
      " [0.62492656]]\n",
      "Loss: \n",
      " 0.08729054260173745\n",
      "\n",
      "\n",
      "Epoch: 104\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.62628896]\n",
      " [0.54147649]\n",
      " [0.62792336]]\n",
      "Loss: \n",
      " 0.08546918971046724\n",
      "\n",
      "\n",
      "Epoch: 105\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.62938118]\n",
      " [0.54462018]\n",
      " [0.63088504]]\n",
      "Loss: \n",
      " 0.0836880993732922\n",
      "\n",
      "\n",
      "Epoch: 106\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.63243566]\n",
      " [0.54772785]\n",
      " [0.63381171]]\n",
      "Loss: \n",
      " 0.08194652757862632\n",
      "\n",
      "\n",
      "Epoch: 107\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.63545257]\n",
      " [0.55079965]\n",
      " [0.63670353]]\n",
      "Loss: \n",
      " 0.08024373380690238\n",
      "\n",
      "\n",
      "Epoch: 108\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.6384321 ]\n",
      " [0.5538357 ]\n",
      " [0.63956062]]\n",
      "Loss: \n",
      " 0.07857898145570728\n",
      "\n",
      "\n",
      "Epoch: 109\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.64137445]\n",
      " [0.55683617]\n",
      " [0.64238314]]\n",
      "Loss: \n",
      " 0.07695153826622683\n",
      "\n",
      "\n",
      "Epoch: 110\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.64427981]\n",
      " [0.55980123]\n",
      " [0.64517127]]\n",
      "Loss: \n",
      " 0.07536067674786558\n",
      "\n",
      "\n",
      "Epoch: 111\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.64714842]\n",
      " [0.56273107]\n",
      " [0.64792518]]\n",
      "Loss: \n",
      " 0.07380567459814628\n",
      "\n",
      "\n",
      "Epoch: 112\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.64998049]\n",
      " [0.56562588]\n",
      " [0.65064506]]\n",
      "Loss: \n",
      " 0.07228581511524172\n",
      "\n",
      "\n",
      "Epoch: 113\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.65277628]\n",
      " [0.56848588]\n",
      " [0.65333111]]\n",
      "Loss: \n",
      " 0.07080038760074071\n",
      "\n",
      "\n",
      "Epoch: 114\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.65553604]\n",
      " [0.57131129]\n",
      " [0.65598355]]\n",
      "Loss: \n",
      " 0.06934868775050144\n",
      "\n",
      "\n",
      "Epoch: 115\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.65826002]\n",
      " [0.57410233]\n",
      " [0.65860259]]\n",
      "Loss: \n",
      " 0.06793001803169346\n",
      "\n",
      "\n",
      "Epoch: 116\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.66094851]\n",
      " [0.57685927]\n",
      " [0.66118847]]\n",
      "Loss: \n",
      " 0.066543688044373\n",
      "\n",
      "\n",
      "Epoch: 117\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.66360178]\n",
      " [0.57958235]\n",
      " [0.66374143]]\n",
      "Loss: \n",
      " 0.06518901486617205\n",
      "\n",
      "\n",
      "Epoch: 118\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.66622013]\n",
      " [0.58227184]\n",
      " [0.66626172]]\n",
      "Loss: \n",
      " 0.06386532337890995\n",
      "\n",
      "\n",
      "Epoch: 119\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.66880386]\n",
      " [0.58492801]\n",
      " [0.6687496 ]]\n",
      "Loss: \n",
      " 0.062571946576152\n",
      "\n",
      "\n",
      "Epoch: 120\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.67135328]\n",
      " [0.58755115]\n",
      " [0.67120533]]\n",
      "Loss: \n",
      " 0.061308225850946474\n",
      "\n",
      "\n",
      "Epoch: 121\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.67386869]\n",
      " [0.59014154]\n",
      " [0.67362919]]\n",
      "Loss: \n",
      " 0.060073511263163494\n",
      "\n",
      "\n",
      "Epoch: 122\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.67635044]\n",
      " [0.59269948]\n",
      " [0.67602147]]\n",
      "Loss: \n",
      " 0.058867161786040345\n",
      "\n",
      "\n",
      "Epoch: 123\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.67879884]\n",
      " [0.59522528]\n",
      " [0.67838245]]\n",
      "Loss: \n",
      " 0.057688545531703196\n",
      "\n",
      "\n",
      "Epoch: 124\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.68121423]\n",
      " [0.59771925]\n",
      " [0.68071243]]\n",
      "Loss: \n",
      " 0.05653703995558979\n",
      "\n",
      "\n",
      "Epoch: 125\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.68359696]\n",
      " [0.6001817 ]\n",
      " [0.68301171]]\n",
      "Loss: \n",
      " 0.055412032039835524\n",
      "\n",
      "\n",
      "Epoch: 126\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.68594738]\n",
      " [0.60261295]\n",
      " [0.6852806 ]]\n",
      "Loss: \n",
      " 0.0543129184558124\n",
      "\n",
      "\n",
      "Epoch: 127\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.68826583]\n",
      " [0.60501333]\n",
      " [0.68751941]]\n",
      "Loss: \n",
      " 0.05323910570612119\n",
      "\n",
      "\n",
      "Epoch: 128\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.69055266]\n",
      " [0.60738317]\n",
      " [0.68972846]]\n",
      "Loss: \n",
      " 0.052190010246439315\n",
      "\n",
      "\n",
      "Epoch: 129\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.69280826]\n",
      " [0.60972281]\n",
      " [0.69190807]]\n",
      "Loss: \n",
      " 0.051165058587711094\n",
      "\n",
      "\n",
      "Epoch: 130\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.69503296]\n",
      " [0.61203257]\n",
      " [0.69405856]]\n",
      "Loss: \n",
      " 0.0501636873792449\n",
      "\n",
      "\n",
      "Epoch: 131\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.69722715]\n",
      " [0.6143128 ]\n",
      " [0.69618027]]\n",
      "Loss: \n",
      " 0.04918534347334435\n",
      "\n",
      "\n",
      "Epoch: 132\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.69939119]\n",
      " [0.61656383]\n",
      " [0.69827353]]\n",
      "Loss: \n",
      " 0.04822948397215499\n",
      "\n",
      "\n",
      "Epoch: 133\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.70152546]\n",
      " [0.61878603]\n",
      " [0.70033867]]\n",
      "Loss: \n",
      " 0.047295576257451066\n",
      "\n",
      "\n",
      "Epoch: 134\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.70363031]\n",
      " [0.62097972]\n",
      " [0.70237602]]\n",
      "Loss: \n",
      " 0.046383098004121937\n",
      "\n",
      "\n",
      "Epoch: 135\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.70570614]\n",
      " [0.62314526]\n",
      " [0.70438593]]\n",
      "Loss: \n",
      " 0.04549153717814327\n",
      "\n",
      "\n",
      "Epoch: 136\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.70775331]\n",
      " [0.62528299]\n",
      " [0.70636873]]\n",
      "Loss: \n",
      " 0.044620392019837064\n",
      "\n",
      "\n",
      "Epoch: 137\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.7097722 ]\n",
      " [0.62739326]\n",
      " [0.70832477]]\n",
      "Loss: \n",
      " 0.04376917101323455\n",
      "\n",
      "\n",
      "Epoch: 138\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.71176319]\n",
      " [0.62947641]\n",
      " [0.71025439]]\n",
      "Loss: \n",
      " 0.04293739284236306\n",
      "\n",
      "\n",
      "Epoch: 139\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.71372665]\n",
      " [0.63153281]\n",
      " [0.71215792]]\n",
      "Loss: \n",
      " 0.04212458633527463\n",
      "\n",
      "\n",
      "Epoch: 140\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.71566295]\n",
      " [0.63356278]\n",
      " [0.71403572]]\n",
      "Loss: \n",
      " 0.04133029039663044\n",
      "\n",
      "\n",
      "Epoch: 141\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.71757248]\n",
      " [0.63556669]\n",
      " [0.71588811]]\n",
      "Loss: \n",
      " 0.04055405392964337\n",
      "\n",
      "\n",
      "Epoch: 142\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.71945559]\n",
      " [0.63754487]\n",
      " [0.71771545]]\n",
      "Loss: \n",
      " 0.039795435748167914\n",
      "\n",
      "\n",
      "Epoch: 143\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.72131267]\n",
      " [0.63949768]\n",
      " [0.71951808]]\n",
      "Loss: \n",
      " 0.03905400447970837\n",
      "\n",
      "\n",
      "Epoch: 144\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.72314409]\n",
      " [0.64142544]\n",
      " [0.72129632]]\n",
      "Loss: \n",
      " 0.03832933846009635\n",
      "\n",
      "\n",
      "Epoch: 145\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.72495021]\n",
      " [0.64332851]\n",
      " [0.72305053]]\n",
      "Loss: \n",
      " 0.03762102562056566\n",
      "\n",
      "\n",
      "Epoch: 146\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.7267314 ]\n",
      " [0.64520723]\n",
      " [0.72478104]]\n",
      "Loss: \n",
      " 0.036928663367928306\n",
      "\n",
      "\n",
      "Epoch: 147\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.72848803]\n",
      " [0.64706192]\n",
      " [0.72648818]]\n",
      "Loss: \n",
      " 0.03625185845852855\n",
      "\n",
      "\n",
      "Epoch: 148\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.73022045]\n",
      " [0.64889294]\n",
      " [0.72817228]]\n",
      "Loss: \n",
      " 0.03559022686662525\n",
      "\n",
      "\n",
      "Epoch: 149\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.73192902]\n",
      " [0.6507006 ]\n",
      " [0.72983369]]\n",
      "Loss: \n",
      " 0.034943393647823506\n",
      "\n",
      "\n",
      "Epoch: 150\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.7336141 ]\n",
      " [0.65248524]\n",
      " [0.73147271]]\n",
      "Loss: \n",
      " 0.03431099279814887\n",
      "\n",
      "\n",
      "Epoch: 151\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.73527605]\n",
      " [0.65424719]\n",
      " [0.73308969]]\n",
      "Loss: \n",
      " 0.033692667109326946\n",
      "\n",
      "\n",
      "Epoch: 152\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.73691521]\n",
      " [0.65598677]\n",
      " [0.73468495]]\n",
      "Loss: \n",
      " 0.03308806802080259\n",
      "\n",
      "\n",
      "Epoch: 153\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.73853193]\n",
      " [0.65770431]\n",
      " [0.7362588 ]]\n",
      "Loss: \n",
      " 0.0324968554690037\n",
      "\n",
      "\n",
      "Epoch: 154\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.74012655]\n",
      " [0.65940012]\n",
      " [0.73781156]]\n",
      "Loss: \n",
      " 0.03191869773432497\n",
      "\n",
      "\n",
      "Epoch: 155\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.74169941]\n",
      " [0.66107451]\n",
      " [0.73934356]]\n",
      "Loss: \n",
      " 0.03135327128627943\n",
      "\n",
      "\n",
      "Epoch: 156\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.74325085]\n",
      " [0.66272781]\n",
      " [0.74085509]]\n",
      "Loss: \n",
      " 0.030800260627236564\n",
      "\n",
      "\n",
      "Epoch: 157\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.7447812 ]\n",
      " [0.66436032]\n",
      " [0.74234648]]\n",
      "Loss: \n",
      " 0.030259358135138987\n",
      "\n",
      "\n",
      "Epoch: 158\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.74629079]\n",
      " [0.66597234]\n",
      " [0.74381802]]\n",
      "Loss: \n",
      " 0.029730263905563672\n",
      "\n",
      "\n",
      "Epoch: 159\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.74777995]\n",
      " [0.66756418]\n",
      " [0.74527003]]\n",
      "Loss: \n",
      " 0.029212685593466386\n",
      "\n",
      "\n",
      "Epoch: 160\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.74924898]\n",
      " [0.66913614]\n",
      " [0.74670278]]\n",
      "Loss: \n",
      " 0.028706338254925107\n",
      "\n",
      "\n",
      "Epoch: 161\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.75069822]\n",
      " [0.67068851]\n",
      " [0.74811659]]\n",
      "Loss: \n",
      " 0.02821094418917243\n",
      "\n",
      "\n",
      "Epoch: 162\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.75212797]\n",
      " [0.67222159]\n",
      " [0.74951175]]\n",
      "Loss: \n",
      " 0.0277262327811859\n",
      "\n",
      "\n",
      "Epoch: 163\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.75353855]\n",
      " [0.67373565]\n",
      " [0.75088854]]\n",
      "Loss: \n",
      " 0.02725194034508129\n",
      "\n",
      "\n",
      "Epoch: 164\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.75493025]\n",
      " [0.675231  ]\n",
      " [0.75224724]]\n",
      "Loss: \n",
      " 0.02678780996853465\n",
      "\n",
      "\n",
      "Epoch: 165\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.75630338]\n",
      " [0.6767079 ]\n",
      " [0.75358814]]\n",
      "Loss: \n",
      " 0.026333591358438022\n",
      "\n",
      "\n",
      "Epoch: 166\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.75765823]\n",
      " [0.67816663]\n",
      " [0.75491152]]\n",
      "Loss: \n",
      " 0.025889040687974905\n",
      "\n",
      "\n",
      "Epoch: 167\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.7589951 ]\n",
      " [0.67960747]\n",
      " [0.75621765]]\n",
      "Loss: \n",
      " 0.025453920445284207\n",
      "\n",
      "\n",
      "Epoch: 168\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.76031427]\n",
      " [0.68103069]\n",
      " [0.75750679]]\n",
      "Loss: \n",
      " 0.025027999283863855\n",
      "\n",
      "\n",
      "Epoch: 169\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.76161602]\n",
      " [0.68243655]\n",
      " [0.75877922]]\n",
      "Loss: \n",
      " 0.02461105187484933\n",
      "\n",
      "\n",
      "Epoch: 170\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.76290064]\n",
      " [0.68382531]\n",
      " [0.7600352 ]]\n",
      "Loss: \n",
      " 0.02420285876128819\n",
      "\n",
      "\n",
      "Epoch: 171\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.76416841]\n",
      " [0.68519724]\n",
      " [0.76127498]]\n",
      "Loss: \n",
      " 0.023803206214515968\n",
      "\n",
      "\n",
      "Epoch: 172\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.76541958]\n",
      " [0.68655259]\n",
      " [0.76249883]]\n",
      "Loss: \n",
      " 0.02341188609272779\n",
      "\n",
      "\n",
      "Epoch: 173\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.76665444]\n",
      " [0.6878916 ]\n",
      " [0.76370698]]\n",
      "Loss: \n",
      " 0.02302869570182527\n",
      "\n",
      "\n",
      "Epoch: 174\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.76787324]\n",
      " [0.68921453]\n",
      " [0.7648997 ]]\n",
      "Loss: \n",
      " 0.022653437658608833\n",
      "\n",
      "\n",
      "Epoch: 175\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.76907624]\n",
      " [0.69052162]\n",
      " [0.76607722]]\n",
      "Loss: \n",
      " 0.022285919756373628\n",
      "\n",
      "\n",
      "Epoch: 176\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.77026369]\n",
      " [0.69181311]\n",
      " [0.76723977]]\n",
      "Loss: \n",
      " 0.021925954832957752\n",
      "\n",
      "\n",
      "Epoch: 177\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.77143585]\n",
      " [0.69308924]\n",
      " [0.76838761]]\n",
      "Loss: \n",
      " 0.021573360641281843\n",
      "\n",
      "\n",
      "Epoch: 178\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.77259296]\n",
      " [0.69435023]\n",
      " [0.76952096]]\n",
      "Loss: \n",
      " 0.02122795972241136\n",
      "\n",
      "\n",
      "Epoch: 179\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.77373527]\n",
      " [0.69559632]\n",
      " [0.77064005]]\n",
      "Loss: \n",
      " 0.02088957928116392\n",
      "\n",
      "\n",
      "Epoch: 180\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.77486302]\n",
      " [0.69682773]\n",
      " [0.7717451 ]]\n",
      "Loss: \n",
      " 0.020558051064277588\n",
      "\n",
      "\n",
      "Epoch: 181\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.77597643]\n",
      " [0.69804469]\n",
      " [0.77283635]]\n",
      "Loss: \n",
      " 0.020233211241149112\n",
      "\n",
      "\n",
      "Epoch: 182\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.77707574]\n",
      " [0.69924741]\n",
      " [0.77391399]]\n",
      "Loss: \n",
      " 0.019914900287144918\n",
      "\n",
      "\n",
      "Epoch: 183\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.77816117]\n",
      " [0.70043611]\n",
      " [0.77497826]]\n",
      "Loss: \n",
      " 0.01960296286948208\n",
      "\n",
      "\n",
      "Epoch: 184\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.77923296]\n",
      " [0.701611  ]\n",
      " [0.77602935]]\n",
      "Loss: \n",
      " 0.019297247735671454\n",
      "\n",
      "\n",
      "Epoch: 185\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.78029131]\n",
      " [0.70277229]\n",
      " [0.77706749]]\n",
      "Loss: \n",
      " 0.018997607604510636\n",
      "\n",
      "\n",
      "Epoch: 186\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.78133645]\n",
      " [0.70392018]\n",
      " [0.77809286]]\n",
      "Loss: \n",
      " 0.018703899059610018\n",
      "\n",
      "\n",
      "Epoch: 187\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.78236858]\n",
      " [0.70505488]\n",
      " [0.77910568]]\n",
      "Loss: \n",
      " 0.01841598244543153\n",
      "\n",
      "\n",
      "Epoch: 188\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.78338792]\n",
      " [0.70617658]\n",
      " [0.78010614]]\n",
      "Loss: \n",
      " 0.01813372176581628\n",
      "\n",
      "\n",
      "Epoch: 189\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.78439467]\n",
      " [0.70728547]\n",
      " [0.78109444]]\n",
      "Loss: \n",
      " 0.01785698458497442\n",
      "\n",
      "\n",
      "Epoch: 190\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.78538903]\n",
      " [0.70838176]\n",
      " [0.78207076]]\n",
      "Loss: \n",
      " 0.017585641930907243\n",
      "\n",
      "\n",
      "Epoch: 191\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.78637119]\n",
      " [0.70946563]\n",
      " [0.78303529]]\n",
      "Loss: \n",
      " 0.017319568201230182\n",
      "\n",
      "\n",
      "Epoch: 192\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.78734136]\n",
      " [0.71053726]\n",
      " [0.78398822]]\n",
      "Loss: \n",
      " 0.017058641071362332\n",
      "\n",
      "\n",
      "Epoch: 193\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.78829972]\n",
      " [0.71159683]\n",
      " [0.78492974]]\n",
      "Loss: \n",
      " 0.016802741405046503\n",
      "\n",
      "\n",
      "Epoch: 194\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.78924646]\n",
      " [0.71264454]\n",
      " [0.78586   ]]\n",
      "Loss: \n",
      " 0.016551753167162904\n",
      "\n",
      "\n",
      "Epoch: 195\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.79018176]\n",
      " [0.71368055]\n",
      " [0.78677921]]\n",
      "Loss: \n",
      " 0.016305563338796753\n",
      "\n",
      "\n",
      "Epoch: 196\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.79110581]\n",
      " [0.71470503]\n",
      " [0.78768751]]\n",
      "Loss: \n",
      " 0.016064061834521057\n",
      "\n",
      "\n",
      "Epoch: 197\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.79201879]\n",
      " [0.71571816]\n",
      " [0.78858509]]\n",
      "Loss: \n",
      " 0.01582714142185233\n",
      "\n",
      "\n",
      "Epoch: 198\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.79292086]\n",
      " [0.71672011]\n",
      " [0.78947211]]\n",
      "Loss: \n",
      " 0.015594697642838879\n",
      "\n",
      "\n",
      "Epoch: 199\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.7938122 ]\n",
      " [0.71771103]\n",
      " [0.79034873]]\n",
      "Loss: \n",
      " 0.015366628737738185\n",
      "\n",
      "\n",
      "Epoch: 200\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.79469298]\n",
      " [0.7186911 ]\n",
      " [0.79121512]]\n",
      "Loss: \n",
      " 0.015142835570741649\n",
      "\n",
      "\n",
      "Epoch: 201\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.79556336]\n",
      " [0.71966047]\n",
      " [0.79207143]]\n",
      "Loss: \n",
      " 0.0149232215577029\n",
      "\n",
      "\n",
      "Epoch: 202\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.79642351]\n",
      " [0.7206193 ]\n",
      " [0.79291782]]\n",
      "Loss: \n",
      " 0.014707692595826933\n",
      "\n",
      "\n",
      "Epoch: 203\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.79727358]\n",
      " [0.72156775]\n",
      " [0.79375443]]\n",
      "Loss: \n",
      " 0.014496156995276503\n",
      "\n",
      "\n",
      "Epoch: 204\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.79811374]\n",
      " [0.72250595]\n",
      " [0.79458143]]\n",
      "Loss: \n",
      " 0.014288525412652409\n",
      "\n",
      "\n",
      "Epoch: 205\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.79894414]\n",
      " [0.72343408]\n",
      " [0.79539895]]\n",
      "Loss: \n",
      " 0.014084710786304818\n",
      "\n",
      "\n",
      "Epoch: 206\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.79976492]\n",
      " [0.72435226]\n",
      " [0.79620714]]\n",
      "Loss: \n",
      " 0.013884628273432403\n",
      "\n",
      "\n",
      "Epoch: 207\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.80057624]\n",
      " [0.72526065]\n",
      " [0.79700615]]\n",
      "Loss: \n",
      " 0.013688195188926612\n",
      "\n",
      "\n",
      "Epoch: 208\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.80137824]\n",
      " [0.72615938]\n",
      " [0.7977961 ]]\n",
      "Loss: \n",
      " 0.01349533094591885\n",
      "\n",
      "\n",
      "Epoch: 209\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.80217106]\n",
      " [0.7270486 ]\n",
      " [0.79857715]]\n",
      "Loss: \n",
      " 0.013305956997988711\n",
      "\n",
      "\n",
      "Epoch: 210\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.80295486]\n",
      " [0.72792844]\n",
      " [0.79934942]]\n",
      "Loss: \n",
      " 0.013119996782991389\n",
      "\n",
      "\n",
      "Epoch: 211\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.80372976]\n",
      " [0.72879904]\n",
      " [0.80011304]]\n",
      "Loss: \n",
      " 0.01293737566846416\n",
      "\n",
      "\n",
      "Epoch: 212\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8044959 ]\n",
      " [0.72966053]\n",
      " [0.80086815]]\n",
      "Loss: \n",
      " 0.012758020898570503\n",
      "\n",
      "\n",
      "Epoch: 213\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.80525341]\n",
      " [0.73051303]\n",
      " [0.80161488]]\n",
      "Loss: \n",
      " 0.012581861542542953\n",
      "\n",
      "\n",
      "Epoch: 214\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.80600243]\n",
      " [0.73135669]\n",
      " [0.80235334]]\n",
      "Loss: \n",
      " 0.012408828444584985\n",
      "\n",
      "\n",
      "Epoch: 215\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.80674308]\n",
      " [0.73219161]\n",
      " [0.80308367]]\n",
      "Loss: \n",
      " 0.01223885417519379\n",
      "\n",
      "\n",
      "Epoch: 216\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.80747549]\n",
      " [0.73301794]\n",
      " [0.80380598]]\n",
      "Loss: \n",
      " 0.012071872983865832\n",
      "\n",
      "\n",
      "Epoch: 217\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.80819979]\n",
      " [0.73383578]\n",
      " [0.80452039]]\n",
      "Loss: \n",
      " 0.011907820753148004\n",
      "\n",
      "\n",
      "Epoch: 218\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.80891609]\n",
      " [0.73464526]\n",
      " [0.80522702]]\n",
      "Loss: \n",
      " 0.011746634953998395\n",
      "\n",
      "\n",
      "Epoch: 219\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.80962452]\n",
      " [0.73544649]\n",
      " [0.80592599]]\n",
      "Loss: \n",
      " 0.01158825460242048\n",
      "\n",
      "\n",
      "Epoch: 220\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.81032519]\n",
      " [0.7362396 ]\n",
      " [0.8066174 ]]\n",
      "Loss: \n",
      " 0.011432620217335933\n",
      "\n",
      "\n",
      "Epoch: 221\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.81101822]\n",
      " [0.73702468]\n",
      " [0.80730137]]\n",
      "Loss: \n",
      " 0.011279673779661908\n",
      "\n",
      "\n",
      "Epoch: 222\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.81170372]\n",
      " [0.73780187]\n",
      " [0.80797801]]\n",
      "Loss: \n",
      " 0.01112935869255934\n",
      "\n",
      "\n",
      "Epoch: 223\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8123818 ]\n",
      " [0.73857126]\n",
      " [0.80864742]]\n",
      "Loss: \n",
      " 0.010981619742819243\n",
      "\n",
      "\n",
      "Epoch: 224\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.81305258]\n",
      " [0.73933296]\n",
      " [0.80930971]]\n",
      "Loss: \n",
      " 0.010836403063355336\n",
      "\n",
      "\n",
      "Epoch: 225\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.81371616]\n",
      " [0.74008708]\n",
      " [0.80996498]]\n",
      "Loss: \n",
      " 0.010693656096771698\n",
      "\n",
      "\n",
      "Epoch: 226\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.81437264]\n",
      " [0.74083372]\n",
      " [0.81061333]]\n",
      "Loss: \n",
      " 0.010553327559974644\n",
      "\n",
      "\n",
      "Epoch: 227\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.81502214]\n",
      " [0.741573  ]\n",
      " [0.81125487]]\n",
      "Loss: \n",
      " 0.010415367409799705\n",
      "\n",
      "\n",
      "Epoch: 228\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.81566474]\n",
      " [0.74230499]\n",
      " [0.81188969]]\n",
      "Loss: \n",
      " 0.010279726809623847\n",
      "\n",
      "\n",
      "Epoch: 229\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.81630056]\n",
      " [0.74302982]\n",
      " [0.81251789]]\n",
      "Loss: \n",
      " 0.010146358096935464\n",
      "\n",
      "\n",
      "Epoch: 230\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.81692969]\n",
      " [0.74374757]\n",
      " [0.81313956]]\n",
      "Loss: \n",
      " 0.010015214751833902\n",
      "\n",
      "\n",
      "Epoch: 231\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.81755223]\n",
      " [0.74445833]\n",
      " [0.8137548 ]]\n",
      "Loss: \n",
      " 0.009886251366432142\n",
      "\n",
      "\n",
      "Epoch: 232\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.81816826]\n",
      " [0.74516222]\n",
      " [0.81436369]]\n",
      "Loss: \n",
      " 0.009759423615136114\n",
      "\n",
      "\n",
      "Epoch: 233\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8187779 ]\n",
      " [0.7458593 ]\n",
      " [0.81496633]]\n",
      "Loss: \n",
      " 0.009634688225775298\n",
      "\n",
      "\n",
      "Epoch: 234\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.81938122]\n",
      " [0.74654969]\n",
      " [0.8155628 ]]\n",
      "Loss: \n",
      " 0.009512002951559951\n",
      "\n",
      "\n",
      "Epoch: 235\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.81997831]\n",
      " [0.74723346]\n",
      " [0.8161532 ]]\n",
      "Loss: \n",
      " 0.009391326543840643\n",
      "\n",
      "\n",
      "Epoch: 236\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.82056927]\n",
      " [0.74791071]\n",
      " [0.8167376 ]]\n",
      "Loss: \n",
      " 0.009272618725646548\n",
      "\n",
      "\n",
      "Epoch: 237\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.82115419]\n",
      " [0.74858153]\n",
      " [0.8173161 ]]\n",
      "Loss: \n",
      " 0.009155840165980042\n",
      "\n",
      "\n",
      "Epoch: 238\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.82173314]\n",
      " [0.74924599]\n",
      " [0.81788877]]\n",
      "Loss: \n",
      " 0.009040952454844972\n",
      "\n",
      "\n",
      "Epoch: 239\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.82230621]\n",
      " [0.74990418]\n",
      " [0.81845569]]\n",
      "Loss: \n",
      " 0.008927918078987199\n",
      "\n",
      "\n",
      "Epoch: 240\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.82287349]\n",
      " [0.75055619]\n",
      " [0.81901694]]\n",
      "Loss: \n",
      " 0.008816700398326618\n",
      "\n",
      "\n",
      "Epoch: 241\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.82343505]\n",
      " [0.75120209]\n",
      " [0.81957261]]\n",
      "Loss: \n",
      " 0.008707263623059912\n",
      "\n",
      "\n",
      "Epoch: 242\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.82399098]\n",
      " [0.75184197]\n",
      " [0.82012277]]\n",
      "Loss: \n",
      " 0.008599572791414455\n",
      "\n",
      "\n",
      "Epoch: 243\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.82454135]\n",
      " [0.75247591]\n",
      " [0.82066749]]\n",
      "Loss: \n",
      " 0.008493593748034205\n",
      "\n",
      "\n",
      "Epoch: 244\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.82508624]\n",
      " [0.75310397]\n",
      " [0.82120685]]\n",
      "Loss: \n",
      " 0.008389293122978614\n",
      "\n",
      "\n",
      "Epoch: 245\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.82562573]\n",
      " [0.75372625]\n",
      " [0.82174093]]\n",
      "Loss: \n",
      " 0.00828663831131677\n",
      "\n",
      "\n",
      "Epoch: 246\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.82615989]\n",
      " [0.7543428 ]\n",
      " [0.82226978]]\n",
      "Loss: \n",
      " 0.008185597453298747\n",
      "\n",
      "\n",
      "Epoch: 247\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.82668879]\n",
      " [0.75495372]\n",
      " [0.8227935 ]]\n",
      "Loss: \n",
      " 0.008086139415087484\n",
      "\n",
      "\n",
      "Epoch: 248\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8272125 ]\n",
      " [0.75555906]\n",
      " [0.82331213]]\n",
      "Loss: \n",
      " 0.007988233770034268\n",
      "\n",
      "\n",
      "Epoch: 249\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.82773111]\n",
      " [0.7561589 ]\n",
      " [0.82382576]]\n",
      "Loss: \n",
      " 0.007891850780481874\n",
      "\n",
      "\n",
      "Epoch: 250\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.82824467]\n",
      " [0.75675331]\n",
      " [0.82433445]]\n",
      "Loss: \n",
      " 0.007796961380079619\n",
      "\n",
      "\n",
      "Epoch: 251\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.82875325]\n",
      " [0.75734236]\n",
      " [0.82483827]]\n",
      "Loss: \n",
      " 0.007703537156595237\n",
      "\n",
      "\n",
      "Epoch: 252\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.82925692]\n",
      " [0.75792612]\n",
      " [0.82533727]]\n",
      "Loss: \n",
      " 0.007611550335208883\n",
      "\n",
      "\n",
      "Epoch: 253\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.82975575]\n",
      " [0.75850466]\n",
      " [0.82583153]]\n",
      "Loss: \n",
      " 0.007520973762274753\n",
      "\n",
      "\n",
      "Epoch: 254\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8302498 ]\n",
      " [0.75907803]\n",
      " [0.82632111]]\n",
      "Loss: \n",
      " 0.0074317808895367566\n",
      "\n",
      "\n",
      "Epoch: 255\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.83073914]\n",
      " [0.75964631]\n",
      " [0.82680607]]\n",
      "Loss: \n",
      " 0.007343945758784622\n",
      "\n",
      "\n",
      "Epoch: 256\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.83122382]\n",
      " [0.76020956]\n",
      " [0.82728647]]\n",
      "Loss: \n",
      " 0.007257442986937492\n",
      "\n",
      "\n",
      "Epoch: 257\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.83170392]\n",
      " [0.76076784]\n",
      " [0.82776236]]\n",
      "Loss: \n",
      " 0.0071722477515420505\n",
      "\n",
      "\n",
      "Epoch: 258\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.83217949]\n",
      " [0.76132121]\n",
      " [0.82823382]]\n",
      "Loss: \n",
      " 0.007088335776673574\n",
      "\n",
      "\n",
      "Epoch: 259\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.83265058]\n",
      " [0.76186974]\n",
      " [0.82870089]]\n",
      "Loss: \n",
      " 0.007005683319227186\n",
      "\n",
      "\n",
      "Epoch: 260\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.83311727]\n",
      " [0.76241348]\n",
      " [0.82916364]]\n",
      "Loss: \n",
      " 0.0069242671555884315\n",
      "\n",
      "\n",
      "Epoch: 261\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8335796 ]\n",
      " [0.76295249]\n",
      " [0.82962211]]\n",
      "Loss: \n",
      " 0.006844064568671741\n",
      "\n",
      "\n",
      "Epoch: 262\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.83403764]\n",
      " [0.76348683]\n",
      " [0.83007637]]\n",
      "Loss: \n",
      " 0.006765053335315708\n",
      "\n",
      "\n",
      "Epoch: 263\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.83449143]\n",
      " [0.76401657]\n",
      " [0.83052647]]\n",
      "Loss: \n",
      " 0.006687211714025146\n",
      "\n",
      "\n",
      "Epoch: 264\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.83494105]\n",
      " [0.76454174]\n",
      " [0.83097246]]\n",
      "Loss: \n",
      " 0.0066105184330492684\n",
      "\n",
      "\n",
      "Epoch: 265\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.83538653]\n",
      " [0.76506242]\n",
      " [0.8314144 ]]\n",
      "Loss: \n",
      " 0.006534952678786424\n",
      "\n",
      "\n",
      "Epoch: 266\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.83582793]\n",
      " [0.76557864]\n",
      " [0.83185233]]\n",
      "Loss: \n",
      " 0.006460494084505557\n",
      "\n",
      "\n",
      "Epoch: 267\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8362653 ]\n",
      " [0.76609048]\n",
      " [0.8322863 ]]\n",
      "Loss: \n",
      " 0.0063871227193751925\n",
      "\n",
      "\n",
      "Epoch: 268\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8366987 ]\n",
      " [0.76659798]\n",
      " [0.83271638]]\n",
      "Loss: \n",
      " 0.006314819077791107\n",
      "\n",
      "\n",
      "Epoch: 269\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.83712818]\n",
      " [0.76710119]\n",
      " [0.8331426 ]]\n",
      "Loss: \n",
      " 0.006243564068993508\n",
      "\n",
      "\n",
      "Epoch: 270\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.83755379]\n",
      " [0.76760016]\n",
      " [0.83356501]]\n",
      "Loss: \n",
      " 0.0061733390069657725\n",
      "\n",
      "\n",
      "Epoch: 271\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.83797556]\n",
      " [0.76809494]\n",
      " [0.83398367]]\n",
      "Loss: \n",
      " 0.006104125600606067\n",
      "\n",
      "\n",
      "Epoch: 272\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.83839357]\n",
      " [0.76858559]\n",
      " [0.83439861]]\n",
      "Loss: \n",
      " 0.00603590594416429\n",
      "\n",
      "\n",
      "Epoch: 273\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.83880784]\n",
      " [0.76907216]\n",
      " [0.83480989]]\n",
      "Loss: \n",
      " 0.0059686625079361484\n",
      "\n",
      "\n",
      "Epoch: 274\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.83921843]\n",
      " [0.76955468]\n",
      " [0.83521756]]\n",
      "Loss: \n",
      " 0.005902378129207443\n",
      "\n",
      "\n",
      "Epoch: 275\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.83962538]\n",
      " [0.77003321]\n",
      " [0.83562164]]\n",
      "Loss: \n",
      " 0.0058370360034407974\n",
      "\n",
      "\n",
      "Epoch: 276\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.84002875]\n",
      " [0.7705078 ]\n",
      " [0.8360222 ]]\n",
      "Loss: \n",
      " 0.005772619675698066\n",
      "\n",
      "\n",
      "Epoch: 277\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.84042856]\n",
      " [0.77097848]\n",
      " [0.83641926]]\n",
      "Loss: \n",
      " 0.005709113032291536\n",
      "\n",
      "\n",
      "Epoch: 278\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.84082488]\n",
      " [0.77144532]\n",
      " [0.83681289]]\n",
      "Loss: \n",
      " 0.00564650029265737\n",
      "\n",
      "\n",
      "Epoch: 279\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.84121773]\n",
      " [0.77190834]\n",
      " [0.83720311]]\n",
      "Loss: \n",
      " 0.005584766001444713\n",
      "\n",
      "\n",
      "Epoch: 280\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.84160717]\n",
      " [0.7723676 ]\n",
      " [0.83758996]]\n",
      "Loss: \n",
      " 0.0055238950208143745\n",
      "\n",
      "\n",
      "Epoch: 281\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.84199323]\n",
      " [0.77282314]\n",
      " [0.8379735 ]]\n",
      "Loss: \n",
      " 0.005463872522941097\n",
      "\n",
      "\n",
      "Epoch: 282\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.84237595]\n",
      " [0.773275  ]\n",
      " [0.83835376]]\n",
      "Loss: \n",
      " 0.005404683982713425\n",
      "\n",
      "\n",
      "Epoch: 283\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.84275539]\n",
      " [0.77372323]\n",
      " [0.83873077]]\n",
      "Loss: \n",
      " 0.005346315170625614\n",
      "\n",
      "\n",
      "Epoch: 284\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.84313157]\n",
      " [0.77416786]\n",
      " [0.83910458]]\n",
      "Loss: \n",
      " 0.005288752145856032\n",
      "\n",
      "\n",
      "Epoch: 285\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.84350453]\n",
      " [0.77460893]\n",
      " [0.83947523]]\n",
      "Loss: \n",
      " 0.005231981249526761\n",
      "\n",
      "\n",
      "Epoch: 286\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.84387432]\n",
      " [0.77504649]\n",
      " [0.83984275]]\n",
      "Loss: \n",
      " 0.005175989098139245\n",
      "\n",
      "\n",
      "Epoch: 287\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.84424097]\n",
      " [0.77548058]\n",
      " [0.84020718]]\n",
      "Loss: \n",
      " 0.005120762577180784\n",
      "\n",
      "\n",
      "Epoch: 288\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.84460452]\n",
      " [0.77591123]\n",
      " [0.84056856]]\n",
      "Loss: \n",
      " 0.005066288834897418\n",
      "\n",
      "\n",
      "Epoch: 289\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.84496501]\n",
      " [0.77633848]\n",
      " [0.84092692]]\n",
      "Loss: \n",
      " 0.005012555276228074\n",
      "\n",
      "\n",
      "Epoch: 290\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.84532247]\n",
      " [0.77676238]\n",
      " [0.8412823 ]]\n",
      "Loss: \n",
      " 0.004959549556895552\n",
      "\n",
      "\n",
      "Epoch: 291\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.84567694]\n",
      " [0.77718296]\n",
      " [0.84163473]]\n",
      "Loss: \n",
      " 0.004907259577650109\n",
      "\n",
      "\n",
      "Epoch: 292\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.84602846]\n",
      " [0.77760025]\n",
      " [0.84198425]]\n",
      "Loss: \n",
      " 0.0048556734786609455\n",
      "\n",
      "\n",
      "Epoch: 293\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.84637705]\n",
      " [0.77801429]\n",
      " [0.84233089]]\n",
      "Loss: \n",
      " 0.004804779634051906\n",
      "\n",
      "\n",
      "Epoch: 294\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.84672276]\n",
      " [0.77842512]\n",
      " [0.84267469]]\n",
      "Loss: \n",
      " 0.004754566646576845\n",
      "\n",
      "\n",
      "Epoch: 295\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.84706561]\n",
      " [0.77883278]\n",
      " [0.84301568]]\n",
      "Loss: \n",
      " 0.004705023342431166\n",
      "\n",
      "\n",
      "Epoch: 296\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.84740564]\n",
      " [0.77923729]\n",
      " [0.84335388]]\n",
      "Loss: \n",
      " 0.004656138766195544\n",
      "\n",
      "\n",
      "Epoch: 297\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.84774289]\n",
      " [0.7796387 ]\n",
      " [0.84368934]]\n",
      "Loss: \n",
      " 0.004607902175907968\n",
      "\n",
      "\n",
      "Epoch: 298\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.84807738]\n",
      " [0.78003703]\n",
      " [0.84402208]]\n",
      "Loss: \n",
      " 0.00456030303826096\n",
      "\n",
      "\n",
      "Epoch: 299\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.84840915]\n",
      " [0.78043232]\n",
      " [0.84435214]]\n",
      "Loss: \n",
      " 0.004513331023920023\n",
      "\n",
      "\n",
      "Epoch: 300\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.84873822]\n",
      " [0.78082461]\n",
      " [0.84467954]]\n",
      "Loss: \n",
      " 0.004466976002960288\n",
      "\n",
      "\n",
      "Epoch: 301\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.84906464]\n",
      " [0.78121392]\n",
      " [0.84500431]]\n",
      "Loss: \n",
      " 0.004421228040417918\n",
      "\n",
      "\n",
      "Epoch: 302\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.84938842]\n",
      " [0.78160029]\n",
      " [0.84532649]]\n",
      "Loss: \n",
      " 0.004376077391953188\n",
      "\n",
      "\n",
      "Epoch: 303\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8497096 ]\n",
      " [0.78198375]\n",
      " [0.84564611]]\n",
      "Loss: \n",
      " 0.004331514499622034\n",
      "\n",
      "\n",
      "Epoch: 304\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.85002822]\n",
      " [0.78236432]\n",
      " [0.84596319]]\n",
      "Loss: \n",
      " 0.004287529987753245\n",
      "\n",
      "\n",
      "Epoch: 305\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.85034429]\n",
      " [0.78274205]\n",
      " [0.84627775]]\n",
      "Loss: \n",
      " 0.004244114658928311\n",
      "\n",
      "\n",
      "Epoch: 306\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.85065784]\n",
      " [0.78311696]\n",
      " [0.84658984]]\n",
      "Loss: \n",
      " 0.0042012594900611286\n",
      "\n",
      "\n",
      "Epoch: 307\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.85096891]\n",
      " [0.78348908]\n",
      " [0.84689948]]\n",
      "Loss: \n",
      " 0.004158955628574791\n",
      "\n",
      "\n",
      "Epoch: 308\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.85127752]\n",
      " [0.78385844]\n",
      " [0.84720669]]\n",
      "Loss: \n",
      " 0.004117194388672954\n",
      "\n",
      "\n",
      "Epoch: 309\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.85158371]\n",
      " [0.78422507]\n",
      " [0.8475115 ]]\n",
      "Loss: \n",
      " 0.00407596724770296\n",
      "\n",
      "\n",
      "Epoch: 310\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.85188749]\n",
      " [0.784589  ]\n",
      " [0.84781393]]\n",
      "Loss: \n",
      " 0.00403526584260848\n",
      "\n",
      "\n",
      "Epoch: 311\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.85218889]\n",
      " [0.78495025]\n",
      " [0.84811403]]\n",
      "Loss: \n",
      " 0.003995081966469162\n",
      "\n",
      "\n",
      "Epoch: 312\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.85248794]\n",
      " [0.78530886]\n",
      " [0.84841179]]\n",
      "Loss: \n",
      " 0.003955407565124815\n",
      "\n",
      "\n",
      "Epoch: 313\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.85278467]\n",
      " [0.78566485]\n",
      " [0.84870727]]\n",
      "Loss: \n",
      " 0.003916234733882037\n",
      "\n",
      "\n",
      "Epoch: 314\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8530791 ]\n",
      " [0.78601825]\n",
      " [0.84900047]]\n",
      "Loss: \n",
      " 0.00387755571430091\n",
      "\n",
      "\n",
      "Epoch: 315\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.85337125]\n",
      " [0.78636909]\n",
      " [0.84929143]]\n",
      "Loss: \n",
      " 0.0038393628910597007\n",
      "\n",
      "\n",
      "Epoch: 316\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.85366116]\n",
      " [0.78671739]\n",
      " [0.84958016]]\n",
      "Loss: \n",
      " 0.0038016487888955235\n",
      "\n",
      "\n",
      "Epoch: 317\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.85394884]\n",
      " [0.78706317]\n",
      " [0.8498667 ]]\n",
      "Loss: \n",
      " 0.003764406069618751\n",
      "\n",
      "\n",
      "Epoch: 318\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.85423432]\n",
      " [0.78740647]\n",
      " [0.85015106]]\n",
      "Loss: \n",
      " 0.00372762752919934\n",
      "\n",
      "\n",
      "Epoch: 319\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.85451763]\n",
      " [0.78774731]\n",
      " [0.85043327]]\n",
      "Loss: \n",
      " 0.003691306094923297\n",
      "\n",
      "\n",
      "Epoch: 320\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.85479878]\n",
      " [0.78808571]\n",
      " [0.85071335]]\n",
      "Loss: \n",
      " 0.003655434822616996\n",
      "\n",
      "\n",
      "Epoch: 321\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8550778 ]\n",
      " [0.7884217 ]\n",
      " [0.85099133]]\n",
      "Loss: \n",
      " 0.0036200068939380736\n",
      "\n",
      "\n",
      "Epoch: 322\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.85535472]\n",
      " [0.78875531]\n",
      " [0.85126722]]\n",
      "Loss: \n",
      " 0.003585015613730681\n",
      "\n",
      "\n",
      "Epoch: 323\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.85562954]\n",
      " [0.78908655]\n",
      " [0.85154106]]\n",
      "Loss: \n",
      " 0.0035504544074437777\n",
      "\n",
      "\n",
      "Epoch: 324\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.85590231]\n",
      " [0.78941545]\n",
      " [0.85181285]]\n",
      "Loss: \n",
      " 0.0035163168186105194\n",
      "\n",
      "\n",
      "Epoch: 325\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.85617304]\n",
      " [0.78974204]\n",
      " [0.85208262]]\n",
      "Loss: \n",
      " 0.0034825965063872196\n",
      "\n",
      "\n",
      "Epoch: 326\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.85644174]\n",
      " [0.79006634]\n",
      " [0.8523504 ]]\n",
      "Loss: \n",
      " 0.0034492872431505033\n",
      "\n",
      "\n",
      "Epoch: 327\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.85670845]\n",
      " [0.79038836]\n",
      " [0.8526162 ]]\n",
      "Loss: \n",
      " 0.0034163829121508435\n",
      "\n",
      "\n",
      "Epoch: 328\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.85697318]\n",
      " [0.79070814]\n",
      " [0.85288005]]\n",
      "Loss: \n",
      " 0.0033838775052211986\n",
      "\n",
      "\n",
      "Epoch: 329\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.85723596]\n",
      " [0.79102569]\n",
      " [0.85314196]]\n",
      "Loss: \n",
      " 0.003351765120539299\n",
      "\n",
      "\n",
      "Epoch: 330\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8574968 ]\n",
      " [0.79134104]\n",
      " [0.85340195]]\n",
      "Loss: \n",
      " 0.0033200399604421133\n",
      "\n",
      "\n",
      "Epoch: 331\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.85775572]\n",
      " [0.79165421]\n",
      " [0.85366005]]\n",
      "Loss: \n",
      " 0.0032886963292912113\n",
      "\n",
      "\n",
      "Epoch: 332\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.85801275]\n",
      " [0.79196522]\n",
      " [0.85391627]]\n",
      "Loss: \n",
      " 0.0032577286313877074\n",
      "\n",
      "\n",
      "Epoch: 333\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8582679 ]\n",
      " [0.79227409]\n",
      " [0.85417064]]\n",
      "Loss: \n",
      " 0.003227131368935488\n",
      "\n",
      "\n",
      "Epoch: 334\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.85852119]\n",
      " [0.79258085]\n",
      " [0.85442317]]\n",
      "Loss: \n",
      " 0.0031968991400514227\n",
      "\n",
      "\n",
      "Epoch: 335\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.85877264]\n",
      " [0.7928855 ]\n",
      " [0.85467387]]\n",
      "Loss: \n",
      " 0.003167026636821568\n",
      "\n",
      "\n",
      "Epoch: 336\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.85902228]\n",
      " [0.79318808]\n",
      " [0.85492278]]\n",
      "Loss: \n",
      " 0.003137508643401805\n",
      "\n",
      "\n",
      "Epoch: 337\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.85927012]\n",
      " [0.7934886 ]\n",
      " [0.8551699 ]]\n",
      "Loss: \n",
      " 0.0031083400341622904\n",
      "\n",
      "\n",
      "Epoch: 338\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.85951617]\n",
      " [0.79378709]\n",
      " [0.85541526]]\n",
      "Loss: \n",
      " 0.003079515771874042\n",
      "\n",
      "\n",
      "Epoch: 339\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.85976046]\n",
      " [0.79408355]\n",
      " [0.85565888]]\n",
      "Loss: \n",
      " 0.003051030905937078\n",
      "\n",
      "\n",
      "Epoch: 340\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.860003  ]\n",
      " [0.79437802]\n",
      " [0.85590076]]\n",
      "Loss: \n",
      " 0.00302288057064876\n",
      "\n",
      "\n",
      "Epoch: 341\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86024382]\n",
      " [0.79467051]\n",
      " [0.85614093]]\n",
      "Loss: \n",
      " 0.002995059983511421\n",
      "\n",
      "\n",
      "Epoch: 342\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86048292]\n",
      " [0.79496104]\n",
      " [0.85637941]]\n",
      "Loss: \n",
      " 0.002967564443578287\n",
      "\n",
      "\n",
      "Epoch: 343\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86072033]\n",
      " [0.79524963]\n",
      " [0.8566162 ]]\n",
      "Loss: \n",
      " 0.0029403893298367173\n",
      "\n",
      "\n",
      "Epoch: 344\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86095606]\n",
      " [0.79553629]\n",
      " [0.85685134]]\n",
      "Loss: \n",
      " 0.0029135300996278525\n",
      "\n",
      "\n",
      "Epoch: 345\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86119013]\n",
      " [0.79582105]\n",
      " [0.85708483]]\n",
      "Loss: \n",
      " 0.0028869822871017328\n",
      "\n",
      "\n",
      "Epoch: 346\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86142256]\n",
      " [0.79610392]\n",
      " [0.85731669]]\n",
      "Loss: \n",
      " 0.0028607415017069203\n",
      "\n",
      "\n",
      "Epoch: 347\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86165336]\n",
      " [0.79638492]\n",
      " [0.85754694]]\n",
      "Loss: \n",
      " 0.0028348034267140277\n",
      "\n",
      "\n",
      "Epoch: 348\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86188254]\n",
      " [0.79666407]\n",
      " [0.85777559]]\n",
      "Loss: \n",
      " 0.0028091638177719807\n",
      "\n",
      "\n",
      "Epoch: 349\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86211013]\n",
      " [0.79694138]\n",
      " [0.85800266]]\n",
      "Loss: \n",
      " 0.002783818501496373\n",
      "\n",
      "\n",
      "Epoch: 350\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86233615]\n",
      " [0.79721688]\n",
      " [0.85822816]]\n",
      "Loss: \n",
      " 0.00275876337408924\n",
      "\n",
      "\n",
      "Epoch: 351\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86256059]\n",
      " [0.79749057]\n",
      " [0.85845212]]\n",
      "Loss: \n",
      " 0.0027339943999891056\n",
      "\n",
      "\n",
      "Epoch: 352\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86278349]\n",
      " [0.79776248]\n",
      " [0.85867453]]\n",
      "Loss: \n",
      " 0.0027095076105510415\n",
      "\n",
      "\n",
      "Epoch: 353\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86300485]\n",
      " [0.79803262]\n",
      " [0.85889543]]\n",
      "Loss: \n",
      " 0.0026852991027555453\n",
      "\n",
      "\n",
      "Epoch: 354\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86322469]\n",
      " [0.79830101]\n",
      " [0.85911481]]\n",
      "Loss: \n",
      " 0.0026613650379458745\n",
      "\n",
      "\n",
      "Epoch: 355\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86344303]\n",
      " [0.79856767]\n",
      " [0.85933271]]\n",
      "Loss: \n",
      " 0.0026377016405929074\n",
      "\n",
      "\n",
      "Epoch: 356\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86365988]\n",
      " [0.7988326 ]\n",
      " [0.85954912]]\n",
      "Loss: \n",
      " 0.002614305197087042\n",
      "\n",
      "\n",
      "Epoch: 357\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86387525]\n",
      " [0.79909583]\n",
      " [0.85976408]]\n",
      "Loss: \n",
      " 0.0025911720545563023\n",
      "\n",
      "\n",
      "Epoch: 358\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86408916]\n",
      " [0.79935738]\n",
      " [0.85997758]]\n",
      "Loss: \n",
      " 0.0025682986197101965\n",
      "\n",
      "\n",
      "Epoch: 359\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86430162]\n",
      " [0.79961724]\n",
      " [0.86018965]]\n",
      "Loss: \n",
      " 0.002545681357708471\n",
      "\n",
      "\n",
      "Epoch: 360\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86451265]\n",
      " [0.79987545]\n",
      " [0.86040029]]\n",
      "Loss: \n",
      " 0.0025233167910544718\n",
      "\n",
      "\n",
      "Epoch: 361\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86472225]\n",
      " [0.80013202]\n",
      " [0.86060952]]\n",
      "Loss: \n",
      " 0.002501201498512224\n",
      "\n",
      "\n",
      "Epoch: 362\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86493045]\n",
      " [0.80038696]\n",
      " [0.86081736]]\n",
      "Loss: \n",
      " 0.0024793321140467923\n",
      "\n",
      "\n",
      "Epoch: 363\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86513726]\n",
      " [0.80064028]\n",
      " [0.86102382]]\n",
      "Loss: \n",
      " 0.0024577053257874124\n",
      "\n",
      "\n",
      "Epoch: 364\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86534268]\n",
      " [0.800892  ]\n",
      " [0.8612289 ]]\n",
      "Loss: \n",
      " 0.0024363178750127223\n",
      "\n",
      "\n",
      "Epoch: 365\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86554674]\n",
      " [0.80114214]\n",
      " [0.86143263]]\n",
      "Loss: \n",
      " 0.0024151665551577065\n",
      "\n",
      "\n",
      "Epoch: 366\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86574944]\n",
      " [0.80139071]\n",
      " [0.86163501]]\n",
      "Loss: \n",
      " 0.0023942482108416526\n",
      "\n",
      "\n",
      "Epoch: 367\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8659508 ]\n",
      " [0.80163772]\n",
      " [0.86183606]]\n",
      "Loss: \n",
      " 0.002373559736916874\n",
      "\n",
      "\n",
      "Epoch: 368\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86615083]\n",
      " [0.80188318]\n",
      " [0.86203579]]\n",
      "Loss: \n",
      " 0.0023530980775374436\n",
      "\n",
      "\n",
      "Epoch: 369\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86634955]\n",
      " [0.80212712]\n",
      " [0.86223422]]\n",
      "Loss: \n",
      " 0.0023328602252476374\n",
      "\n",
      "\n",
      "Epoch: 370\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86654695]\n",
      " [0.80236953]\n",
      " [0.86243134]]\n",
      "Loss: \n",
      " 0.0023128432200896173\n",
      "\n",
      "\n",
      "Epoch: 371\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86674307]\n",
      " [0.80261045]\n",
      " [0.86262718]]\n",
      "Loss: \n",
      " 0.0022930441487297075\n",
      "\n",
      "\n",
      "Epoch: 372\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8669379 ]\n",
      " [0.80284987]\n",
      " [0.86282175]]\n",
      "Loss: \n",
      " 0.0022734601436031707\n",
      "\n",
      "\n",
      "Epoch: 373\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86713146]\n",
      " [0.80308782]\n",
      " [0.86301506]]\n",
      "Loss: \n",
      " 0.0022540883820767335\n",
      "\n",
      "\n",
      "Epoch: 374\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86732377]\n",
      " [0.8033243 ]\n",
      " [0.86320712]]\n",
      "Loss: \n",
      " 0.0022349260856285463\n",
      "\n",
      "\n",
      "Epoch: 375\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86751483]\n",
      " [0.80355933]\n",
      " [0.86339794]]\n",
      "Loss: \n",
      " 0.0022159705190453235\n",
      "\n",
      "\n",
      "Epoch: 376\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86770465]\n",
      " [0.80379292]\n",
      " [0.86358754]]\n",
      "Loss: \n",
      " 0.002197218989636023\n",
      "\n",
      "\n",
      "Epoch: 377\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86789325]\n",
      " [0.80402509]\n",
      " [0.86377592]]\n",
      "Loss: \n",
      " 0.0021786688464617886\n",
      "\n",
      "\n",
      "Epoch: 378\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86808064]\n",
      " [0.80425584]\n",
      " [0.86396309]]\n",
      "Loss: \n",
      " 0.0021603174795819116\n",
      "\n",
      "\n",
      "Epoch: 379\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86826682]\n",
      " [0.80448518]\n",
      " [0.86414907]]\n",
      "Loss: \n",
      " 0.002142162319315142\n",
      "\n",
      "\n",
      "Epoch: 380\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86845182]\n",
      " [0.80471314]\n",
      " [0.86433387]]\n",
      "Loss: \n",
      " 0.0021242008355163255\n",
      "\n",
      "\n",
      "Epoch: 381\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86863563]\n",
      " [0.80493972]\n",
      " [0.86451749]]\n",
      "Loss: \n",
      " 0.00210643053686774\n",
      "\n",
      "\n",
      "Epoch: 382\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86881828]\n",
      " [0.80516493]\n",
      " [0.86469995]]\n",
      "Loss: \n",
      " 0.002088848970184987\n",
      "\n",
      "\n",
      "Epoch: 383\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86899976]\n",
      " [0.80538878]\n",
      " [0.86488126]]\n",
      "Loss: \n",
      " 0.0020714537197369896\n",
      "\n",
      "\n",
      "Epoch: 384\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86918009]\n",
      " [0.80561129]\n",
      " [0.86506142]]\n",
      "Loss: \n",
      " 0.0020542424065798483\n",
      "\n",
      "\n",
      "Epoch: 385\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86935929]\n",
      " [0.80583247]\n",
      " [0.86524046]]\n",
      "Loss: \n",
      " 0.002037212687904157\n",
      "\n",
      "\n",
      "Epoch: 386\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86953736]\n",
      " [0.80605232]\n",
      " [0.86541837]]\n",
      "Loss: \n",
      " 0.0020203622563956234\n",
      "\n",
      "\n",
      "Epoch: 387\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86971431]\n",
      " [0.80627087]\n",
      " [0.86559517]]\n",
      "Loss: \n",
      " 0.00200368883960843\n",
      "\n",
      "\n",
      "Epoch: 388\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.86989014]\n",
      " [0.80648811]\n",
      " [0.86577086]]\n",
      "Loss: \n",
      " 0.001987190199351416\n",
      "\n",
      "\n",
      "Epoch: 389\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87006488]\n",
      " [0.80670407]\n",
      " [0.86594547]]\n",
      "Loss: \n",
      " 0.001970864131086404\n",
      "\n",
      "\n",
      "Epoch: 390\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87023853]\n",
      " [0.80691875]\n",
      " [0.86611899]]\n",
      "Loss: \n",
      " 0.001954708463338685\n",
      "\n",
      "\n",
      "Epoch: 391\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8704111 ]\n",
      " [0.80713216]\n",
      " [0.86629143]]\n",
      "Loss: \n",
      " 0.0019387210571192432\n",
      "\n",
      "\n",
      "Epoch: 392\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8705826 ]\n",
      " [0.80734432]\n",
      " [0.86646281]]\n",
      "Loss: \n",
      " 0.0019228998053585336\n",
      "\n",
      "\n",
      "Epoch: 393\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87075304]\n",
      " [0.80755522]\n",
      " [0.86663314]]\n",
      "Loss: \n",
      " 0.0019072426323514748\n",
      "\n",
      "\n",
      "Epoch: 394\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87092242]\n",
      " [0.8077649 ]\n",
      " [0.86680242]]\n",
      "Loss: \n",
      " 0.001891747493213495\n",
      "\n",
      "\n",
      "Epoch: 395\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87109077]\n",
      " [0.80797334]\n",
      " [0.86697066]]\n",
      "Loss: \n",
      " 0.0018764123733473082\n",
      "\n",
      "\n",
      "Epoch: 396\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87125807]\n",
      " [0.80818057]\n",
      " [0.86713787]]\n",
      "Loss: \n",
      " 0.0018612352879202442\n",
      "\n",
      "\n",
      "Epoch: 397\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87142435]\n",
      " [0.80838659]\n",
      " [0.86730406]]\n",
      "Loss: \n",
      " 0.0018462142813518501\n",
      "\n",
      "\n",
      "Epoch: 398\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87158962]\n",
      " [0.80859142]\n",
      " [0.86746924]]\n",
      "Loss: \n",
      " 0.0018313474268116092\n",
      "\n",
      "\n",
      "Epoch: 399\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87175388]\n",
      " [0.80879506]\n",
      " [0.86763341]]\n",
      "Loss: \n",
      " 0.0018166328257264025\n",
      "\n",
      "\n",
      "Epoch: 400\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87191713]\n",
      " [0.80899752]\n",
      " [0.8677966 ]]\n",
      "Loss: \n",
      " 0.0018020686072977305\n",
      "\n",
      "\n",
      "Epoch: 401\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8720794 ]\n",
      " [0.80919882]\n",
      " [0.86795879]]\n",
      "Loss: \n",
      " 0.0017876529280282279\n",
      "\n",
      "\n",
      "Epoch: 402\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87224068]\n",
      " [0.80939895]\n",
      " [0.86812001]]\n",
      "Loss: \n",
      " 0.0017733839712575012\n",
      "\n",
      "\n",
      "Epoch: 403\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87240099]\n",
      " [0.80959794]\n",
      " [0.86828026]]\n",
      "Loss: \n",
      " 0.0017592599467068854\n",
      "\n",
      "\n",
      "Epoch: 404\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87256034]\n",
      " [0.80979579]\n",
      " [0.86843955]]\n",
      "Loss: \n",
      " 0.0017452790900330572\n",
      "\n",
      "\n",
      "Epoch: 405\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87271872]\n",
      " [0.80999251]\n",
      " [0.86859788]]\n",
      "Loss: \n",
      " 0.0017314396623902908\n",
      "\n",
      "\n",
      "Epoch: 406\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87287616]\n",
      " [0.8101881 ]\n",
      " [0.86875527]]\n",
      "Loss: \n",
      " 0.0017177399500011286\n",
      "\n",
      "\n",
      "Epoch: 407\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87303265]\n",
      " [0.81038259]\n",
      " [0.86891172]]\n",
      "Loss: \n",
      " 0.0017041782637352949\n",
      "\n",
      "\n",
      "Epoch: 408\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87318821]\n",
      " [0.81057596]\n",
      " [0.86906724]]\n",
      "Loss: \n",
      " 0.001690752938696686\n",
      "\n",
      "\n",
      "Epoch: 409\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87334285]\n",
      " [0.81076825]\n",
      " [0.86922184]]\n",
      "Loss: \n",
      " 0.0016774623338182953\n",
      "\n",
      "\n",
      "Epoch: 410\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87349656]\n",
      " [0.81095945]\n",
      " [0.86937552]]\n",
      "Loss: \n",
      " 0.0016643048314648622\n",
      "\n",
      "\n",
      "Epoch: 411\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87364937]\n",
      " [0.81114957]\n",
      " [0.8695283 ]]\n",
      "Loss: \n",
      " 0.0016512788370430624\n",
      "\n",
      "\n",
      "Epoch: 412\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87380127]\n",
      " [0.81133862]\n",
      " [0.86968018]]\n",
      "Loss: \n",
      " 0.0016383827786190972\n",
      "\n",
      "\n",
      "Epoch: 413\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87395227]\n",
      " [0.8115266 ]\n",
      " [0.86983116]]\n",
      "Loss: \n",
      " 0.0016256151065435957\n",
      "\n",
      "\n",
      "Epoch: 414\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87410239]\n",
      " [0.81171354]\n",
      " [0.86998126]]\n",
      "Loss: \n",
      " 0.0016129742930835493\n",
      "\n",
      "\n",
      "Epoch: 415\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87425162]\n",
      " [0.81189943]\n",
      " [0.87013048]]\n",
      "Loss: \n",
      " 0.0016004588320611864\n",
      "\n",
      "\n",
      "Epoch: 416\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87439998]\n",
      " [0.81208429]\n",
      " [0.87027883]]\n",
      "Loss: \n",
      " 0.0015880672384997365\n",
      "\n",
      "\n",
      "Epoch: 417\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87454747]\n",
      " [0.81226811]\n",
      " [0.87042632]]\n",
      "Loss: \n",
      " 0.001575798048275689\n",
      "\n",
      "\n",
      "Epoch: 418\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87469411]\n",
      " [0.81245092]\n",
      " [0.87057295]]\n",
      "Loss: \n",
      " 0.0015636498177776942\n",
      "\n",
      "\n",
      "Epoch: 419\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87483989]\n",
      " [0.81263271]\n",
      " [0.87071873]]\n",
      "Loss: \n",
      " 0.001551621123571821\n",
      "\n",
      "\n",
      "Epoch: 420\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87498482]\n",
      " [0.8128135 ]\n",
      " [0.87086367]]\n",
      "Loss: \n",
      " 0.0015397105620729807\n",
      "\n",
      "\n",
      "Epoch: 421\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87512891]\n",
      " [0.81299329]\n",
      " [0.87100777]]\n",
      "Loss: \n",
      " 0.0015279167492225805\n",
      "\n",
      "\n",
      "Epoch: 422\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87527217]\n",
      " [0.81317209]\n",
      " [0.87115104]]\n",
      "Loss: \n",
      " 0.0015162383201720083\n",
      "\n",
      "\n",
      "Epoch: 423\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87541461]\n",
      " [0.81334991]\n",
      " [0.87129348]]\n",
      "Loss: \n",
      " 0.0015046739289721498\n",
      "\n",
      "\n",
      "Epoch: 424\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87555622]\n",
      " [0.81352675]\n",
      " [0.87143512]]\n",
      "Loss: \n",
      " 0.0014932222482685169\n",
      "\n",
      "\n",
      "Epoch: 425\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87569703]\n",
      " [0.81370263]\n",
      " [0.87157594]]\n",
      "Loss: \n",
      " 0.001481881969002023\n",
      "\n",
      "\n",
      "Epoch: 426\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87583702]\n",
      " [0.81387755]\n",
      " [0.87171595]]\n",
      "Loss: \n",
      " 0.001470651800115288\n",
      "\n",
      "\n",
      "Epoch: 427\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87597622]\n",
      " [0.81405151]\n",
      " [0.87185517]]\n",
      "Loss: \n",
      " 0.0014595304682643209\n",
      "\n",
      "\n",
      "Epoch: 428\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87611462]\n",
      " [0.81422453]\n",
      " [0.8719936 ]]\n",
      "Loss: \n",
      " 0.001448516717535462\n",
      "\n",
      "\n",
      "Epoch: 429\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87625224]\n",
      " [0.81439662]\n",
      " [0.87213124]]\n",
      "Loss: \n",
      " 0.0014376093091675035\n",
      "\n",
      "\n",
      "Epoch: 430\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87638907]\n",
      " [0.81456777]\n",
      " [0.87226811]]\n",
      "Loss: \n",
      " 0.0014268070212788834\n",
      "\n",
      "\n",
      "Epoch: 431\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87652513]\n",
      " [0.81473799]\n",
      " [0.8724042 ]]\n",
      "Loss: \n",
      " 0.0014161086485998235\n",
      "\n",
      "\n",
      "Epoch: 432\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87666042]\n",
      " [0.8149073 ]\n",
      " [0.87253952]]\n",
      "Loss: \n",
      " 0.001405513002209346\n",
      "\n",
      "\n",
      "Epoch: 433\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87679494]\n",
      " [0.8150757 ]\n",
      " [0.87267409]]\n",
      "Loss: \n",
      " 0.0013950189092770005\n",
      "\n",
      "\n",
      "Epoch: 434\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87692871]\n",
      " [0.81524319]\n",
      " [0.8728079 ]]\n",
      "Loss: \n",
      " 0.0013846252128093398\n",
      "\n",
      "\n",
      "Epoch: 435\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87706173]\n",
      " [0.81540979]\n",
      " [0.87294096]]\n",
      "Loss: \n",
      " 0.001374330771400864\n",
      "\n",
      "\n",
      "Epoch: 436\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87719401]\n",
      " [0.8155755 ]\n",
      " [0.87307327]]\n",
      "Loss: \n",
      " 0.001364134458989518\n",
      "\n",
      "\n",
      "Epoch: 437\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87732554]\n",
      " [0.81574032]\n",
      " [0.87320485]]\n",
      "Loss: \n",
      " 0.0013540351646165215\n",
      "\n",
      "\n",
      "Epoch: 438\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87745634]\n",
      " [0.81590427]\n",
      " [0.8733357 ]]\n",
      "Loss: \n",
      " 0.0013440317921905268\n",
      "\n",
      "\n",
      "Epoch: 439\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87758641]\n",
      " [0.81606734]\n",
      " [0.87346582]]\n",
      "Loss: \n",
      " 0.0013341232602559865\n",
      "\n",
      "\n",
      "Epoch: 440\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87771576]\n",
      " [0.81622956]\n",
      " [0.87359522]]\n",
      "Loss: \n",
      " 0.0013243085017656218\n",
      "\n",
      "\n",
      "Epoch: 441\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87784439]\n",
      " [0.81639091]\n",
      " [0.87372391]]\n",
      "Loss: \n",
      " 0.0013145864638569732\n",
      "\n",
      "\n",
      "Epoch: 442\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87797231]\n",
      " [0.81655141]\n",
      " [0.87385188]]\n",
      "Loss: \n",
      " 0.0013049561076328338\n",
      "\n",
      "\n",
      "Epoch: 443\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87809953]\n",
      " [0.81671106]\n",
      " [0.87397915]]\n",
      "Loss: \n",
      " 0.001295416407945701\n",
      "\n",
      "\n",
      "Epoch: 444\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87822604]\n",
      " [0.81686988]\n",
      " [0.87410573]]\n",
      "Loss: \n",
      " 0.0012859663531859002\n",
      "\n",
      "\n",
      "Epoch: 445\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87835186]\n",
      " [0.81702786]\n",
      " [0.8742316 ]]\n",
      "Loss: \n",
      " 0.001276604945073496\n",
      "\n",
      "\n",
      "Epoch: 446\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87847699]\n",
      " [0.81718502]\n",
      " [0.87435679]]\n",
      "Loss: \n",
      " 0.001267331198453908\n",
      "\n",
      "\n",
      "Epoch: 447\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87860143]\n",
      " [0.81734135]\n",
      " [0.8744813 ]]\n",
      "Loss: \n",
      " 0.0012581441410969801\n",
      "\n",
      "\n",
      "Epoch: 448\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87872519]\n",
      " [0.81749687]\n",
      " [0.87460512]]\n",
      "Loss: \n",
      " 0.0012490428134997252\n",
      "\n",
      "\n",
      "Epoch: 449\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87884828]\n",
      " [0.81765157]\n",
      " [0.87472828]]\n",
      "Loss: \n",
      " 0.001240026268692393\n",
      "\n",
      "\n",
      "Epoch: 450\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8789707 ]\n",
      " [0.81780548]\n",
      " [0.87485076]]\n",
      "Loss: \n",
      " 0.001231093572047955\n",
      "\n",
      "\n",
      "Epoch: 451\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87909245]\n",
      " [0.81795858]\n",
      " [0.87497259]]\n",
      "Loss: \n",
      " 0.0012222438010949207\n",
      "\n",
      "\n",
      "Epoch: 452\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87921355]\n",
      " [0.8181109 ]\n",
      " [0.87509375]]\n",
      "Loss: \n",
      " 0.0012134760453333773\n",
      "\n",
      "\n",
      "Epoch: 453\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87933399]\n",
      " [0.81826242]\n",
      " [0.87521426]]\n",
      "Loss: \n",
      " 0.001204789406054194\n",
      "\n",
      "\n",
      "Epoch: 454\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87945378]\n",
      " [0.81841317]\n",
      " [0.87533412]]\n",
      "Loss: \n",
      " 0.001196182996161408\n",
      "\n",
      "\n",
      "Epoch: 455\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87957292]\n",
      " [0.81856314]\n",
      " [0.87545334]]\n",
      "Loss: \n",
      " 0.0011876559399976114\n",
      "\n",
      "\n",
      "Epoch: 456\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87969143]\n",
      " [0.81871233]\n",
      " [0.87557192]]\n",
      "Loss: \n",
      " 0.0011792073731723535\n",
      "\n",
      "\n",
      "Epoch: 457\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87980929]\n",
      " [0.81886077]\n",
      " [0.87568986]]\n",
      "Loss: \n",
      " 0.001170836442393505\n",
      "\n",
      "\n",
      "Epoch: 458\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.87992653]\n",
      " [0.81900844]\n",
      " [0.87580717]]\n",
      "Loss: \n",
      " 0.0011625423053015103\n",
      "\n",
      "\n",
      "Epoch: 459\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88004314]\n",
      " [0.81915536]\n",
      " [0.87592386]]\n",
      "Loss: \n",
      " 0.0011543241303064323\n",
      "\n",
      "\n",
      "Epoch: 460\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88015913]\n",
      " [0.81930153]\n",
      " [0.87603993]]\n",
      "Loss: \n",
      " 0.0011461810964278165\n",
      "\n",
      "\n",
      "Epoch: 461\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88027451]\n",
      " [0.81944696]\n",
      " [0.87615538]]\n",
      "Loss: \n",
      " 0.0011381123931372488\n",
      "\n",
      "\n",
      "Epoch: 462\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88038927]\n",
      " [0.81959165]\n",
      " [0.87627022]]\n",
      "Loss: \n",
      " 0.0011301172202036126\n",
      "\n",
      "\n",
      "Epoch: 463\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88050342]\n",
      " [0.81973561]\n",
      " [0.87638445]]\n",
      "Loss: \n",
      " 0.0011221947875409432\n",
      "\n",
      "\n",
      "Epoch: 464\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88061697]\n",
      " [0.81987883]\n",
      " [0.87649808]]\n",
      "Loss: \n",
      " 0.0011143443150588438\n",
      "\n",
      "\n",
      "Epoch: 465\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88072992]\n",
      " [0.82002134]\n",
      " [0.87661111]]\n",
      "Loss: \n",
      " 0.001106565032515474\n",
      "\n",
      "\n",
      "Epoch: 466\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88084227]\n",
      " [0.82016312]\n",
      " [0.87672355]]\n",
      "Loss: \n",
      " 0.0010988561793729352\n",
      "\n",
      "\n",
      "Epoch: 467\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88095403]\n",
      " [0.8203042 ]\n",
      " [0.87683539]]\n",
      "Loss: \n",
      " 0.0010912170046551547\n",
      "\n",
      "\n",
      "Epoch: 468\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88106521]\n",
      " [0.82044456]\n",
      " [0.87694665]]\n",
      "Loss: \n",
      " 0.001083646766808116\n",
      "\n",
      "\n",
      "Epoch: 469\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88117581]\n",
      " [0.82058422]\n",
      " [0.87705733]]\n",
      "Loss: \n",
      " 0.0010761447335624133\n",
      "\n",
      "\n",
      "Epoch: 470\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88128582]\n",
      " [0.82072319]\n",
      " [0.87716743]]\n",
      "Loss: \n",
      " 0.0010687101817981326\n",
      "\n",
      "\n",
      "Epoch: 471\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88139526]\n",
      " [0.82086145]\n",
      " [0.87727696]]\n",
      "Loss: \n",
      " 0.001061342397411946\n",
      "\n",
      "\n",
      "Epoch: 472\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88150414]\n",
      " [0.82099903]\n",
      " [0.87738592]]\n",
      "Loss: \n",
      " 0.0010540406751864528\n",
      "\n",
      "\n",
      "Epoch: 473\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88161244]\n",
      " [0.82113593]\n",
      " [0.87749431]]\n",
      "Loss: \n",
      " 0.0010468043186616484\n",
      "\n",
      "\n",
      "Epoch: 474\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88172019]\n",
      " [0.82127214]\n",
      " [0.87760214]]\n",
      "Loss: \n",
      " 0.001039632640008533\n",
      "\n",
      "\n",
      "Epoch: 475\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88182738]\n",
      " [0.82140768]\n",
      " [0.87770941]]\n",
      "Loss: \n",
      " 0.0010325249599048222\n",
      "\n",
      "\n",
      "Epoch: 476\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88193401]\n",
      " [0.82154255]\n",
      " [0.87781613]]\n",
      "Loss: \n",
      " 0.0010254806074126747\n",
      "\n",
      "\n",
      "Epoch: 477\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88204009]\n",
      " [0.82167675]\n",
      " [0.8779223 ]]\n",
      "Loss: \n",
      " 0.0010184989198584544\n",
      "\n",
      "\n",
      "Epoch: 478\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88214563]\n",
      " [0.82181029]\n",
      " [0.87802793]]\n",
      "Loss: \n",
      " 0.001011579242714444\n",
      "\n",
      "\n",
      "Epoch: 479\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88225062]\n",
      " [0.82194318]\n",
      " [0.87813301]]\n",
      "Loss: \n",
      " 0.0010047209294825282\n",
      "\n",
      "\n",
      "Epoch: 480\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88235508]\n",
      " [0.82207541]\n",
      " [0.87823755]]\n",
      "Loss: \n",
      " 0.0009979233415797187\n",
      "\n",
      "\n",
      "Epoch: 481\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.882459  ]\n",
      " [0.82220699]\n",
      " [0.87834156]]\n",
      "Loss: \n",
      " 0.0009911858482256216\n",
      "\n",
      "\n",
      "Epoch: 482\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88256239]\n",
      " [0.82233793]\n",
      " [0.87844504]]\n",
      "Loss: \n",
      " 0.0009845078263316493\n",
      "\n",
      "\n",
      "Epoch: 483\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88266525]\n",
      " [0.82246822]\n",
      " [0.87854799]]\n",
      "Loss: \n",
      " 0.0009778886603920983\n",
      "\n",
      "\n",
      "Epoch: 484\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88276759]\n",
      " [0.82259789]\n",
      " [0.87865042]]\n",
      "Loss: \n",
      " 0.0009713277423769747\n",
      "\n",
      "\n",
      "Epoch: 485\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88286941]\n",
      " [0.82272692]\n",
      " [0.87875233]]\n",
      "Loss: \n",
      " 0.0009648244716265122\n",
      "\n",
      "\n",
      "Epoch: 486\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88297072]\n",
      " [0.82285532]\n",
      " [0.87885372]]\n",
      "Loss: \n",
      " 0.0009583782547474775\n",
      "\n",
      "\n",
      "Epoch: 487\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88307151]\n",
      " [0.8229831 ]\n",
      " [0.8789546 ]]\n",
      "Loss: \n",
      " 0.0009519885055110114\n",
      "\n",
      "\n",
      "Epoch: 488\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88317179]\n",
      " [0.82311026]\n",
      " [0.87905497]]\n",
      "Loss: \n",
      " 0.0009456546447522712\n",
      "\n",
      "\n",
      "Epoch: 489\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88327156]\n",
      " [0.82323681]\n",
      " [0.87915483]]\n",
      "Loss: \n",
      " 0.0009393761002715406\n",
      "\n",
      "\n",
      "Epoch: 490\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88337083]\n",
      " [0.82336274]\n",
      " [0.87925419]]\n",
      "Loss: \n",
      " 0.0009331523067370217\n",
      "\n",
      "\n",
      "Epoch: 491\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88346961]\n",
      " [0.82348807]\n",
      " [0.87935305]]\n",
      "Loss: \n",
      " 0.0009269827055891053\n",
      "\n",
      "\n",
      "Epoch: 492\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88356788]\n",
      " [0.8236128 ]\n",
      " [0.87945142]]\n",
      "Loss: \n",
      " 0.0009208667449462279\n",
      "\n",
      "\n",
      "Epoch: 493\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88366567]\n",
      " [0.82373692]\n",
      " [0.87954929]]\n",
      "Loss: \n",
      " 0.0009148038795121846\n",
      "\n",
      "\n",
      "Epoch: 494\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88376297]\n",
      " [0.82386045]\n",
      " [0.87964668]]\n",
      "Loss: \n",
      " 0.0009087935704849157\n",
      "\n",
      "\n",
      "Epoch: 495\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88385978]\n",
      " [0.82398339]\n",
      " [0.87974358]]\n",
      "Loss: \n",
      " 0.0009028352854667604\n",
      "\n",
      "\n",
      "Epoch: 496\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88395611]\n",
      " [0.82410574]\n",
      " [0.87984   ]]\n",
      "Loss: \n",
      " 0.0008969284983761148\n",
      "\n",
      "\n",
      "Epoch: 497\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88405196]\n",
      " [0.82422751]\n",
      " [0.87993593]]\n",
      "Loss: \n",
      " 0.000891072689360482\n",
      "\n",
      "\n",
      "Epoch: 498\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88414733]\n",
      " [0.8243487 ]\n",
      " [0.88003139]]\n",
      "Loss: \n",
      " 0.0008852673447108914\n",
      "\n",
      "\n",
      "Epoch: 499\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88424223]\n",
      " [0.82446931]\n",
      " [0.88012638]]\n",
      "Loss: \n",
      " 0.0008795119567776571\n",
      "\n",
      "\n",
      "Epoch: 500\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88433667]\n",
      " [0.82458935]\n",
      " [0.8802209 ]]\n",
      "Loss: \n",
      " 0.0008738060238874626\n",
      "\n",
      "\n",
      "Epoch: 501\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88443063]\n",
      " [0.82470882]\n",
      " [0.88031496]]\n",
      "Loss: \n",
      " 0.0008681490502617808\n",
      "\n",
      "\n",
      "Epoch: 502\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88452413]\n",
      " [0.82482773]\n",
      " [0.88040855]]\n",
      "Loss: \n",
      " 0.0008625405459364564\n",
      "\n",
      "\n",
      "Epoch: 503\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88461718]\n",
      " [0.82494607]\n",
      " [0.88050167]]\n",
      "Loss: \n",
      " 0.0008569800266826858\n",
      "\n",
      "\n",
      "Epoch: 504\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88470976]\n",
      " [0.82506386]\n",
      " [0.88059435]]\n",
      "Loss: \n",
      " 0.000851467013929126\n",
      "\n",
      "\n",
      "Epoch: 505\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88480189]\n",
      " [0.82518109]\n",
      " [0.88068656]]\n",
      "Loss: \n",
      " 0.0008460010346852247\n",
      "\n",
      "\n",
      "Epoch: 506\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88489358]\n",
      " [0.82529777]\n",
      " [0.88077833]]\n",
      "Loss: \n",
      " 0.000840581621465778\n",
      "\n",
      "\n",
      "Epoch: 507\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88498481]\n",
      " [0.82541391]\n",
      " [0.88086965]]\n",
      "Loss: \n",
      " 0.0008352083122166263\n",
      "\n",
      "\n",
      "Epoch: 508\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8850756 ]\n",
      " [0.82552949]\n",
      " [0.88096052]]\n",
      "Loss: \n",
      " 0.000829880650241498\n",
      "\n",
      "\n",
      "Epoch: 509\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88516594]\n",
      " [0.82564454]\n",
      " [0.88105095]]\n",
      "Loss: \n",
      " 0.0008245981841299798\n",
      "\n",
      "\n",
      "Epoch: 510\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88525585]\n",
      " [0.82575905]\n",
      " [0.88114094]]\n",
      "Loss: \n",
      " 0.0008193604676866098\n",
      "\n",
      "\n",
      "Epoch: 511\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88534532]\n",
      " [0.82587303]\n",
      " [0.88123049]]\n",
      "Loss: \n",
      " 0.000814167059861017\n",
      "\n",
      "\n",
      "Epoch: 512\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88543435]\n",
      " [0.82598648]\n",
      " [0.88131961]]\n",
      "Loss: \n",
      " 0.0008090175246791902\n",
      "\n",
      "\n",
      "Epoch: 513\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88552296]\n",
      " [0.8260994 ]\n",
      " [0.8814083 ]]\n",
      "Loss: \n",
      " 0.0008039114311757437\n",
      "\n",
      "\n",
      "Epoch: 514\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88561114]\n",
      " [0.8262118 ]\n",
      " [0.88149656]]\n",
      "Loss: \n",
      " 0.000798848353327243\n",
      "\n",
      "\n",
      "Epoch: 515\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88569889]\n",
      " [0.82632367]\n",
      " [0.8815844 ]]\n",
      "Loss: \n",
      " 0.0007938278699865419\n",
      "\n",
      "\n",
      "Epoch: 516\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88578622]\n",
      " [0.82643503]\n",
      " [0.88167181]]\n",
      "Loss: \n",
      " 0.0007888495648180977\n",
      "\n",
      "\n",
      "Epoch: 517\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88587313]\n",
      " [0.82654587]\n",
      " [0.8817588 ]]\n",
      "Loss: \n",
      " 0.0007839130262343145\n",
      "\n",
      "\n",
      "Epoch: 518\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88595963]\n",
      " [0.82665621]\n",
      " [0.88184537]]\n",
      "Loss: \n",
      " 0.0007790178473327833\n",
      "\n",
      "\n",
      "Epoch: 519\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88604571]\n",
      " [0.82676603]\n",
      " [0.88193153]]\n",
      "Loss: \n",
      " 0.000774163625834528\n",
      "\n",
      "\n",
      "Epoch: 520\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88613138]\n",
      " [0.82687535]\n",
      " [0.88201728]]\n",
      "Loss: \n",
      " 0.0007693499640231351\n",
      "\n",
      "\n",
      "Epoch: 521\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88621663]\n",
      " [0.82698417]\n",
      " [0.88210262]]\n",
      "Loss: \n",
      " 0.0007645764686848504\n",
      "\n",
      "\n",
      "Epoch: 522\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88630149]\n",
      " [0.82709249]\n",
      " [0.88218755]]\n",
      "Loss: \n",
      " 0.0007598427510495245\n",
      "\n",
      "\n",
      "Epoch: 523\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88638594]\n",
      " [0.82720032]\n",
      " [0.88227208]]\n",
      "Loss: \n",
      " 0.0007551484267324698\n",
      "\n",
      "\n",
      "Epoch: 524\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88646999]\n",
      " [0.82730765]\n",
      " [0.8823562 ]]\n",
      "Loss: \n",
      " 0.0007504931156771907\n",
      "\n",
      "\n",
      "Epoch: 525\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88655364]\n",
      " [0.82741449]\n",
      " [0.88243993]]\n",
      "Loss: \n",
      " 0.000745876442098948\n",
      "\n",
      "\n",
      "Epoch: 526\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88663689]\n",
      " [0.82752085]\n",
      " [0.88252326]]\n",
      "Loss: \n",
      " 0.0007412980344291827\n",
      "\n",
      "\n",
      "Epoch: 527\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88671975]\n",
      " [0.82762672]\n",
      " [0.88260619]]\n",
      "Loss: \n",
      " 0.0007367575252607569\n",
      "\n",
      "\n",
      "Epoch: 528\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88680222]\n",
      " [0.82773211]\n",
      " [0.88268874]]\n",
      "Loss: \n",
      " 0.0007322545512940063\n",
      "\n",
      "\n",
      "Epoch: 529\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8868843 ]\n",
      " [0.82783703]\n",
      " [0.88277089]]\n",
      "Loss: \n",
      " 0.0007277887532836138\n",
      "\n",
      "\n",
      "Epoch: 530\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.886966  ]\n",
      " [0.82794147]\n",
      " [0.88285266]]\n",
      "Loss: \n",
      " 0.0007233597759862173\n",
      "\n",
      "\n",
      "Epoch: 531\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88704731]\n",
      " [0.82804544]\n",
      " [0.88293404]]\n",
      "Loss: \n",
      " 0.000718967268108842\n",
      "\n",
      "\n",
      "Epoch: 532\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88712824]\n",
      " [0.82814894]\n",
      " [0.88301504]]\n",
      "Loss: \n",
      " 0.0007146108822580947\n",
      "\n",
      "\n",
      "Epoch: 533\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88720879]\n",
      " [0.82825197]\n",
      " [0.88309566]]\n",
      "Loss: \n",
      " 0.000710290274890037\n",
      "\n",
      "\n",
      "Epoch: 534\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88728896]\n",
      " [0.82835454]\n",
      " [0.88317591]]\n",
      "Loss: \n",
      " 0.0007060051062608685\n",
      "\n",
      "\n",
      "Epoch: 535\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88736876]\n",
      " [0.82845665]\n",
      " [0.88325578]]\n",
      "Loss: \n",
      " 0.000701755040378308\n",
      "\n",
      "\n",
      "Epoch: 536\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88744819]\n",
      " [0.8285583 ]\n",
      " [0.88333528]]\n",
      "Loss: \n",
      " 0.0006975397449536649\n",
      "\n",
      "\n",
      "Epoch: 537\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88752725]\n",
      " [0.8286595 ]\n",
      " [0.8834144 ]]\n",
      "Loss: \n",
      " 0.0006933588913546392\n",
      "\n",
      "\n",
      "Epoch: 538\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88760594]\n",
      " [0.82876024]\n",
      " [0.88349316]]\n",
      "Loss: \n",
      " 0.0006892121545587857\n",
      "\n",
      "\n",
      "Epoch: 539\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88768427]\n",
      " [0.82886053]\n",
      " [0.88357155]]\n",
      "Loss: \n",
      " 0.0006850992131076696\n",
      "\n",
      "\n",
      "Epoch: 540\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88776223]\n",
      " [0.82896038]\n",
      " [0.88364958]]\n",
      "Loss: \n",
      " 0.0006810197490616931\n",
      "\n",
      "\n",
      "Epoch: 541\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88783984]\n",
      " [0.82905978]\n",
      " [0.88372725]]\n",
      "Loss: \n",
      " 0.0006769734479555517\n",
      "\n",
      "\n",
      "Epoch: 542\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88791708]\n",
      " [0.82915874]\n",
      " [0.88380456]]\n",
      "Loss: \n",
      " 0.0006729599987543388\n",
      "\n",
      "\n",
      "Epoch: 543\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88799397]\n",
      " [0.82925727]\n",
      " [0.88388151]]\n",
      "Loss: \n",
      " 0.0006689790938103224\n",
      "\n",
      "\n",
      "Epoch: 544\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88807051]\n",
      " [0.82935535]\n",
      " [0.88395811]]\n",
      "Loss: \n",
      " 0.0006650304288202837\n",
      "\n",
      "\n",
      "Epoch: 545\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88814669]\n",
      " [0.829453  ]\n",
      " [0.88403436]]\n",
      "Loss: \n",
      " 0.0006611137027835366\n",
      "\n",
      "\n",
      "Epoch: 546\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88822253]\n",
      " [0.82955022]\n",
      " [0.88411025]]\n",
      "Loss: \n",
      " 0.0006572286179604582\n",
      "\n",
      "\n",
      "Epoch: 547\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88829802]\n",
      " [0.82964701]\n",
      " [0.8841858 ]]\n",
      "Loss: \n",
      " 0.0006533748798317217\n",
      "\n",
      "\n",
      "Epoch: 548\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88837316]\n",
      " [0.82974338]\n",
      " [0.884261  ]]\n",
      "Loss: \n",
      " 0.0006495521970580338\n",
      "\n",
      "\n",
      "Epoch: 549\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88844796]\n",
      " [0.82983932]\n",
      " [0.88433586]]\n",
      "Loss: \n",
      " 0.0006457602814404677\n",
      "\n",
      "\n",
      "Epoch: 550\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88852241]\n",
      " [0.82993483]\n",
      " [0.88441037]]\n",
      "Loss: \n",
      " 0.0006419988478813673\n",
      "\n",
      "\n",
      "Epoch: 551\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88859653]\n",
      " [0.83002993]\n",
      " [0.88448455]]\n",
      "Loss: \n",
      " 0.0006382676143458177\n",
      "\n",
      "\n",
      "Epoch: 552\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88867032]\n",
      " [0.83012462]\n",
      " [0.88455838]]\n",
      "Loss: \n",
      " 0.0006345663018236347\n",
      "\n",
      "\n",
      "Epoch: 553\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88874376]\n",
      " [0.83021888]\n",
      " [0.88463189]]\n",
      "Loss: \n",
      " 0.0006308946342919031\n",
      "\n",
      "\n",
      "Epoch: 554\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88881688]\n",
      " [0.83031274]\n",
      " [0.88470505]]\n",
      "Loss: \n",
      " 0.0006272523386780396\n",
      "\n",
      "\n",
      "Epoch: 555\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88888966]\n",
      " [0.83040619]\n",
      " [0.88477789]]\n",
      "Loss: \n",
      " 0.0006236391448234509\n",
      "\n",
      "\n",
      "Epoch: 556\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88896211]\n",
      " [0.83049923]\n",
      " [0.88485039]]\n",
      "Loss: \n",
      " 0.0006200547854475444\n",
      "\n",
      "\n",
      "Epoch: 557\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88903424]\n",
      " [0.83059186]\n",
      " [0.88492257]]\n",
      "Loss: \n",
      " 0.0006164989961123826\n",
      "\n",
      "\n",
      "Epoch: 558\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88910604]\n",
      " [0.8306841 ]\n",
      " [0.88499442]]\n",
      "Loss: \n",
      " 0.0006129715151878246\n",
      "\n",
      "\n",
      "Epoch: 559\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88917752]\n",
      " [0.83077593]\n",
      " [0.88506595]]\n",
      "Loss: \n",
      " 0.0006094720838170606\n",
      "\n",
      "\n",
      "Epoch: 560\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88924868]\n",
      " [0.83086737]\n",
      " [0.88513716]]\n",
      "Loss: \n",
      " 0.000606000445882733\n",
      "\n",
      "\n",
      "Epoch: 561\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88931952]\n",
      " [0.83095841]\n",
      " [0.88520804]]\n",
      "Loss: \n",
      " 0.0006025563479734586\n",
      "\n",
      "\n",
      "Epoch: 562\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88939004]\n",
      " [0.83104905]\n",
      " [0.88527861]]\n",
      "Loss: \n",
      " 0.0005991395393508627\n",
      "\n",
      "\n",
      "Epoch: 563\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88946024]\n",
      " [0.83113931]\n",
      " [0.88534886]]\n",
      "Loss: \n",
      " 0.0005957497719170621\n",
      "\n",
      "\n",
      "Epoch: 564\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88953014]\n",
      " [0.83122917]\n",
      " [0.8854188 ]]\n",
      "Loss: \n",
      " 0.000592386800182571\n",
      "\n",
      "\n",
      "Epoch: 565\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88959972]\n",
      " [0.83131865]\n",
      " [0.88548842]]\n",
      "Loss: \n",
      " 0.0005890503812346775\n",
      "\n",
      "\n",
      "Epoch: 566\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88966899]\n",
      " [0.83140775]\n",
      " [0.88555773]]\n",
      "Loss: \n",
      " 0.0005857402747062753\n",
      "\n",
      "\n",
      "Epoch: 567\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88973795]\n",
      " [0.83149646]\n",
      " [0.88562674]]\n",
      "Loss: \n",
      " 0.0005824562427450803\n",
      "\n",
      "\n",
      "Epoch: 568\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88980661]\n",
      " [0.8315848 ]\n",
      " [0.88569543]]\n",
      "Loss: \n",
      " 0.0005791980499832932\n",
      "\n",
      "\n",
      "Epoch: 569\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88987496]\n",
      " [0.83167275]\n",
      " [0.88576382]]\n",
      "Loss: \n",
      " 0.0005759654635077124\n",
      "\n",
      "\n",
      "Epoch: 570\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.88994301]\n",
      " [0.83176033]\n",
      " [0.88583191]]\n",
      "Loss: \n",
      " 0.0005727582528301912\n",
      "\n",
      "\n",
      "Epoch: 571\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89001075]\n",
      " [0.83184754]\n",
      " [0.8858997 ]]\n",
      "Loss: \n",
      " 0.0005695761898585507\n",
      "\n",
      "\n",
      "Epoch: 572\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8900782 ]\n",
      " [0.83193437]\n",
      " [0.88596718]]\n",
      "Loss: \n",
      " 0.0005664190488678867\n",
      "\n",
      "\n",
      "Epoch: 573\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89014535]\n",
      " [0.83202084]\n",
      " [0.88603437]]\n",
      "Loss: \n",
      " 0.0005632866064722431\n",
      "\n",
      "\n",
      "Epoch: 574\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89021221]\n",
      " [0.83210693]\n",
      " [0.88610126]]\n",
      "Loss: \n",
      " 0.0005601786415966983\n",
      "\n",
      "\n",
      "Epoch: 575\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89027877]\n",
      " [0.83219267]\n",
      " [0.88616785]]\n",
      "Loss: \n",
      " 0.0005570949354497997\n",
      "\n",
      "\n",
      "Epoch: 576\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89034504]\n",
      " [0.83227803]\n",
      " [0.88623415]]\n",
      "Loss: \n",
      " 0.0005540352714964145\n",
      "\n",
      "\n",
      "Epoch: 577\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89041102]\n",
      " [0.83236304]\n",
      " [0.88630016]]\n",
      "Loss: \n",
      " 0.0005509994354309372\n",
      "\n",
      "\n",
      "Epoch: 578\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89047671]\n",
      " [0.83244769]\n",
      " [0.88636588]]\n",
      "Loss: \n",
      " 0.0005479872151508196\n",
      "\n",
      "\n",
      "Epoch: 579\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89054211]\n",
      " [0.83253198]\n",
      " [0.88643131]]\n",
      "Loss: \n",
      " 0.0005449984007305044\n",
      "\n",
      "\n",
      "Epoch: 580\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89060722]\n",
      " [0.83261591]\n",
      " [0.88649646]]\n",
      "Loss: \n",
      " 0.0005420327843957145\n",
      "\n",
      "\n",
      "Epoch: 581\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89067206]\n",
      " [0.83269949]\n",
      " [0.88656132]]\n",
      "Loss: \n",
      " 0.0005390901604980411\n",
      "\n",
      "\n",
      "Epoch: 582\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89073661]\n",
      " [0.83278272]\n",
      " [0.88662589]]\n",
      "Loss: \n",
      " 0.000536170325489926\n",
      "\n",
      "\n",
      "Epoch: 583\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89080088]\n",
      " [0.8328656 ]\n",
      " [0.88669019]]\n",
      "Loss: \n",
      " 0.0005332730778999474\n",
      "\n",
      "\n",
      "Epoch: 584\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89086487]\n",
      " [0.83294814]\n",
      " [0.8867542 ]]\n",
      "Loss: \n",
      " 0.0005303982183084527\n",
      "\n",
      "\n",
      "Epoch: 585\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89092858]\n",
      " [0.83303032]\n",
      " [0.88681794]]\n",
      "Loss: \n",
      " 0.0005275455493235001\n",
      "\n",
      "\n",
      "Epoch: 586\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89099201]\n",
      " [0.83311217]\n",
      " [0.8868814 ]]\n",
      "Loss: \n",
      " 0.0005247148755571417\n",
      "\n",
      "\n",
      "Epoch: 587\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89105518]\n",
      " [0.83319367]\n",
      " [0.88694458]]\n",
      "Loss: \n",
      " 0.0005219060036020375\n",
      "\n",
      "\n",
      "Epoch: 588\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89111806]\n",
      " [0.83327483]\n",
      " [0.88700749]]\n",
      "Loss: \n",
      " 0.0005191187420083072\n",
      "\n",
      "\n",
      "Epoch: 589\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89118068]\n",
      " [0.83335565]\n",
      " [0.88707012]]\n",
      "Loss: \n",
      " 0.0005163529012607882\n",
      "\n",
      "\n",
      "Epoch: 590\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89124303]\n",
      " [0.83343613]\n",
      " [0.88713249]]\n",
      "Loss: \n",
      " 0.0005136082937565229\n",
      "\n",
      "\n",
      "Epoch: 591\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89130511]\n",
      " [0.83351629]\n",
      " [0.88719459]]\n",
      "Loss: \n",
      " 0.0005108847337825786\n",
      "\n",
      "\n",
      "Epoch: 592\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89136692]\n",
      " [0.8335961 ]\n",
      " [0.88725641]]\n",
      "Loss: \n",
      " 0.0005081820374941481\n",
      "\n",
      "\n",
      "Epoch: 593\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89142847]\n",
      " [0.83367559]\n",
      " [0.88731798]]\n",
      "Loss: \n",
      " 0.000505500022892947\n",
      "\n",
      "\n",
      "Epoch: 594\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89148975]\n",
      " [0.83375475]\n",
      " [0.88737927]]\n",
      "Loss: \n",
      " 0.0005028385098058835\n",
      "\n",
      "\n",
      "Epoch: 595\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89155077]\n",
      " [0.83383358]\n",
      " [0.88744031]]\n",
      "Loss: \n",
      " 0.0005001973198640247\n",
      "\n",
      "\n",
      "Epoch: 596\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89161153]\n",
      " [0.83391209]\n",
      " [0.88750108]]\n",
      "Loss: \n",
      " 0.000497576276481834\n",
      "\n",
      "\n",
      "Epoch: 597\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89167203]\n",
      " [0.83399027]\n",
      " [0.88756159]]\n",
      "Loss: \n",
      " 0.0004949752048366696\n",
      "\n",
      "\n",
      "Epoch: 598\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89173228]\n",
      " [0.83406813]\n",
      " [0.88762184]]\n",
      "Loss: \n",
      " 0.0004923939318485672\n",
      "\n",
      "\n",
      "Epoch: 599\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89179226]\n",
      " [0.83414567]\n",
      " [0.88768183]]\n",
      "Loss: \n",
      " 0.000489832286160275\n",
      "\n",
      "\n",
      "Epoch: 600\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.891852  ]\n",
      " [0.83422289]\n",
      " [0.88774157]]\n",
      "Loss: \n",
      " 0.00048729009811756516\n",
      "\n",
      "\n",
      "Epoch: 601\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89191147]\n",
      " [0.83429979]\n",
      " [0.88780106]]\n",
      "Loss: \n",
      " 0.00048476719974977124\n",
      "\n",
      "\n",
      "Epoch: 602\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8919707 ]\n",
      " [0.83437638]\n",
      " [0.88786029]]\n",
      "Loss: \n",
      " 0.00048226342475062305\n",
      "\n",
      "\n",
      "Epoch: 603\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89202967]\n",
      " [0.83445265]\n",
      " [0.88791926]]\n",
      "Loss: \n",
      " 0.00047977860845928587\n",
      "\n",
      "\n",
      "Epoch: 604\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8920884 ]\n",
      " [0.83452861]\n",
      " [0.88797799]]\n",
      "Loss: \n",
      " 0.0004773125878416822\n",
      "\n",
      "\n",
      "Epoch: 605\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89214687]\n",
      " [0.83460426]\n",
      " [0.88803647]]\n",
      "Loss: \n",
      " 0.00047486520147201386\n",
      "\n",
      "\n",
      "Epoch: 606\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8922051]\n",
      " [0.8346796]\n",
      " [0.8880947]]\n",
      "Loss: \n",
      " 0.00047243628951457953\n",
      "\n",
      "\n",
      "Epoch: 607\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89226309]\n",
      " [0.83475464]\n",
      " [0.88815268]]\n",
      "Loss: \n",
      " 0.0004700256937057745\n",
      "\n",
      "\n",
      "Epoch: 608\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89232083]\n",
      " [0.83482937]\n",
      " [0.88821042]]\n",
      "Loss: \n",
      " 0.00046763325733634224\n",
      "\n",
      "\n",
      "Epoch: 609\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89237833]\n",
      " [0.8349038 ]\n",
      " [0.88826792]]\n",
      "Loss: \n",
      " 0.0004652588252338663\n",
      "\n",
      "\n",
      "Epoch: 610\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89243558]\n",
      " [0.83497792]\n",
      " [0.88832517]]\n",
      "Loss: \n",
      " 0.00046290224374546333\n",
      "\n",
      "\n",
      "Epoch: 611\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8924926 ]\n",
      " [0.83505174]\n",
      " [0.88838218]]\n",
      "Loss: \n",
      " 0.00046056336072071956\n",
      "\n",
      "\n",
      "Epoch: 612\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89254937]\n",
      " [0.83512527]\n",
      " [0.88843895]]\n",
      "Loss: \n",
      " 0.00045824202549482753\n",
      "\n",
      "\n",
      "Epoch: 613\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89260591]\n",
      " [0.83519849]\n",
      " [0.88849548]]\n",
      "Loss: \n",
      " 0.0004559380888719448\n",
      "\n",
      "\n",
      "Epoch: 614\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89266222]\n",
      " [0.83527142]\n",
      " [0.88855178]]\n",
      "Loss: \n",
      " 0.0004536514031087927\n",
      "\n",
      "\n",
      "Epoch: 615\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89271828]\n",
      " [0.83534406]\n",
      " [0.88860784]]\n",
      "Loss: \n",
      " 0.00045138182189839466\n",
      "\n",
      "\n",
      "Epoch: 616\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89277412]\n",
      " [0.8354164 ]\n",
      " [0.88866366]]\n",
      "Loss: \n",
      " 0.00044912920035409284\n",
      "\n",
      "\n",
      "Epoch: 617\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89282972]\n",
      " [0.83548846]\n",
      " [0.88871925]]\n",
      "Loss: \n",
      " 0.00044689339499374617\n",
      "\n",
      "\n",
      "Epoch: 618\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89288509]\n",
      " [0.83556022]\n",
      " [0.88877461]]\n",
      "Loss: \n",
      " 0.0004446742637240914\n",
      "\n",
      "\n",
      "Epoch: 619\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89294023]\n",
      " [0.83563169]\n",
      " [0.88882973]]\n",
      "Loss: \n",
      " 0.00044247166582535936\n",
      "\n",
      "\n",
      "Epoch: 620\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89299515]\n",
      " [0.83570288]\n",
      " [0.88888463]]\n",
      "Loss: \n",
      " 0.00044028546193604774\n",
      "\n",
      "\n",
      "Epoch: 621\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89304983]\n",
      " [0.83577378]\n",
      " [0.8889393 ]]\n",
      "Loss: \n",
      " 0.00043811551403789454\n",
      "\n",
      "\n",
      "Epoch: 622\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89310429]\n",
      " [0.8358444 ]\n",
      " [0.88899374]]\n",
      "Loss: \n",
      " 0.00043596168544104735\n",
      "\n",
      "\n",
      "Epoch: 623\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89315852]\n",
      " [0.83591473]\n",
      " [0.88904796]]\n",
      "Loss: \n",
      " 0.00043382384076942095\n",
      "\n",
      "\n",
      "Epoch: 624\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89321253]\n",
      " [0.83598478]\n",
      " [0.88910195]]\n",
      "Loss: \n",
      " 0.0004317018459462059\n",
      "\n",
      "\n",
      "Epoch: 625\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89326632]\n",
      " [0.83605456]\n",
      " [0.88915571]]\n",
      "Loss: \n",
      " 0.00042959556817961567\n",
      "\n",
      "\n",
      "Epoch: 626\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89331988]\n",
      " [0.83612405]\n",
      " [0.88920926]]\n",
      "Loss: \n",
      " 0.0004275048759487699\n",
      "\n",
      "\n",
      "Epoch: 627\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89337323]\n",
      " [0.83619327]\n",
      " [0.88926258]]\n",
      "Loss: \n",
      " 0.0004254296389897499\n",
      "\n",
      "\n",
      "Epoch: 628\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89342635]\n",
      " [0.83626222]\n",
      " [0.88931568]]\n",
      "Loss: \n",
      " 0.0004233697282818734\n",
      "\n",
      "\n",
      "Epoch: 629\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89347926]\n",
      " [0.83633089]\n",
      " [0.88936856]]\n",
      "Loss: \n",
      " 0.0004213250160340848\n",
      "\n",
      "\n",
      "Epoch: 630\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89353195]\n",
      " [0.83639929]\n",
      " [0.88942123]]\n",
      "Loss: \n",
      " 0.00041929537567154696\n",
      "\n",
      "\n",
      "Epoch: 631\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89358443]\n",
      " [0.83646741]\n",
      " [0.88947368]]\n",
      "Loss: \n",
      " 0.0004172806818224022\n",
      "\n",
      "\n",
      "Epoch: 632\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89363669]\n",
      " [0.83653527]\n",
      " [0.88952591]]\n",
      "Loss: \n",
      " 0.00041528081030468134\n",
      "\n",
      "\n",
      "Epoch: 633\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89368874]\n",
      " [0.83660286]\n",
      " [0.88957793]]\n",
      "Loss: \n",
      " 0.0004132956381133663\n",
      "\n",
      "\n",
      "Epoch: 634\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89374057]\n",
      " [0.83667018]\n",
      " [0.88962973]]\n",
      "Loss: \n",
      " 0.0004113250434076557\n",
      "\n",
      "\n",
      "Epoch: 635\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8937922 ]\n",
      " [0.83673724]\n",
      " [0.88968132]]\n",
      "Loss: \n",
      " 0.00040936890549833773\n",
      "\n",
      "\n",
      "Epoch: 636\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89384361]\n",
      " [0.83680403]\n",
      " [0.8897327 ]]\n",
      "Loss: \n",
      " 0.00040742710483533754\n",
      "\n",
      "\n",
      "Epoch: 637\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89389482]\n",
      " [0.83687056]\n",
      " [0.88978387]]\n",
      "Loss: \n",
      " 0.00040549952299543816\n",
      "\n",
      "\n",
      "Epoch: 638\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89394581]\n",
      " [0.83693682]\n",
      " [0.88983483]]\n",
      "Loss: \n",
      " 0.00040358604267012036\n",
      "\n",
      "\n",
      "Epoch: 639\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8939966 ]\n",
      " [0.83700283]\n",
      " [0.88988559]]\n",
      "Loss: \n",
      " 0.00040168654765357007\n",
      "\n",
      "\n",
      "Epoch: 640\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89404719]\n",
      " [0.83706858]\n",
      " [0.88993613]]\n",
      "Loss: \n",
      " 0.000399800922830827\n",
      "\n",
      "\n",
      "Epoch: 641\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89409757]\n",
      " [0.83713407]\n",
      " [0.88998648]]\n",
      "Loss: \n",
      " 0.00039792905416606176\n",
      "\n",
      "\n",
      "Epoch: 642\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89414774]\n",
      " [0.8371993 ]\n",
      " [0.89003661]]\n",
      "Loss: \n",
      " 0.00039607082869105257\n",
      "\n",
      "\n",
      "Epoch: 643\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89419772]\n",
      " [0.83726428]\n",
      " [0.89008654]]\n",
      "Loss: \n",
      " 0.00039422613449372314\n",
      "\n",
      "\n",
      "Epoch: 644\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89424749]\n",
      " [0.837329  ]\n",
      " [0.89013627]]\n",
      "Loss: \n",
      " 0.00039239486070686956\n",
      "\n",
      "\n",
      "Epoch: 645\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89429706]\n",
      " [0.83739347]\n",
      " [0.8901858 ]]\n",
      "Loss: \n",
      " 0.0003905768974970378\n",
      "\n",
      "\n",
      "Epoch: 646\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89434643]\n",
      " [0.8374577 ]\n",
      " [0.89023513]]\n",
      "Loss: \n",
      " 0.00038877213605347725\n",
      "\n",
      "\n",
      "Epoch: 647\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8943956 ]\n",
      " [0.83752167]\n",
      " [0.89028426]]\n",
      "Loss: \n",
      " 0.000386980468577279\n",
      "\n",
      "\n",
      "Epoch: 648\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89444458]\n",
      " [0.83758539]\n",
      " [0.89033319]]\n",
      "Loss: \n",
      " 0.00038520178827063876\n",
      "\n",
      "\n",
      "Epoch: 649\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89449336]\n",
      " [0.83764886]\n",
      " [0.89038192]]\n",
      "Loss: \n",
      " 0.000383435989326218\n",
      "\n",
      "\n",
      "Epoch: 650\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89454194]\n",
      " [0.83771209]\n",
      " [0.89043046]]\n",
      "Loss: \n",
      " 0.00038168296691667433\n",
      "\n",
      "\n",
      "Epoch: 651\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89459033]\n",
      " [0.83777507]\n",
      " [0.8904788 ]]\n",
      "Loss: \n",
      " 0.0003799426171842905\n",
      "\n",
      "\n",
      "Epoch: 652\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89463853]\n",
      " [0.83783781]\n",
      " [0.89052694]]\n",
      "Loss: \n",
      " 0.00037821483723073714\n",
      "\n",
      "\n",
      "Epoch: 653\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89468654]\n",
      " [0.8379003 ]\n",
      " [0.89057489]]\n",
      "Loss: \n",
      " 0.0003764995251069511\n",
      "\n",
      "\n",
      "Epoch: 654\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89473435]\n",
      " [0.83796256]\n",
      " [0.89062265]]\n",
      "Loss: \n",
      " 0.00037479657980315427\n",
      "\n",
      "\n",
      "Epoch: 655\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89478197]\n",
      " [0.83802457]\n",
      " [0.89067022]]\n",
      "Loss: \n",
      " 0.0003731059012389627\n",
      "\n",
      "\n",
      "Epoch: 656\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8948294 ]\n",
      " [0.83808635]\n",
      " [0.8907176 ]]\n",
      "Loss: \n",
      " 0.00037142739025365266\n",
      "\n",
      "\n",
      "Epoch: 657\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89487665]\n",
      " [0.83814788]\n",
      " [0.89076478]]\n",
      "Loss: \n",
      " 0.00036976094859649027\n",
      "\n",
      "\n",
      "Epoch: 658\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8949237 ]\n",
      " [0.83820918]\n",
      " [0.89081178]]\n",
      "Loss: \n",
      " 0.00036810647891722916\n",
      "\n",
      "\n",
      "Epoch: 659\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89497057]\n",
      " [0.83827024]\n",
      " [0.89085859]]\n",
      "Loss: \n",
      " 0.00036646388475668825\n",
      "\n",
      "\n",
      "Epoch: 660\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89501726]\n",
      " [0.83833107]\n",
      " [0.89090522]]\n",
      "Loss: \n",
      " 0.0003648330705374554\n",
      "\n",
      "\n",
      "Epoch: 661\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89506376]\n",
      " [0.83839167]\n",
      " [0.89095166]]\n",
      "Loss: \n",
      " 0.0003632139415546852\n",
      "\n",
      "\n",
      "Epoch: 662\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89511007]\n",
      " [0.83845203]\n",
      " [0.89099791]]\n",
      "Loss: \n",
      " 0.0003616064039670377\n",
      "\n",
      "\n",
      "Epoch: 663\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89515621]\n",
      " [0.83851216]\n",
      " [0.89104398]]\n",
      "Loss: \n",
      " 0.0003600103647876818\n",
      "\n",
      "\n",
      "Epoch: 664\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89520216]\n",
      " [0.83857207]\n",
      " [0.89108987]]\n",
      "Loss: \n",
      " 0.00035842573187543515\n",
      "\n",
      "\n",
      "Epoch: 665\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89524793]\n",
      " [0.83863174]\n",
      " [0.89113557]]\n",
      "Loss: \n",
      " 0.0003568524139260135\n",
      "\n",
      "\n",
      "Epoch: 666\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89529352]\n",
      " [0.83869118]\n",
      " [0.89118109]]\n",
      "Loss: \n",
      " 0.0003552903204633398\n",
      "\n",
      "\n",
      "Epoch: 667\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89533893]\n",
      " [0.8387504 ]\n",
      " [0.89122644]]\n",
      "Loss: \n",
      " 0.0003537393618310215\n",
      "\n",
      "\n",
      "Epoch: 668\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89538416]\n",
      " [0.8388094 ]\n",
      " [0.8912716 ]]\n",
      "Loss: \n",
      " 0.0003521994491838567\n",
      "\n",
      "\n",
      "Epoch: 669\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89542921]\n",
      " [0.83886816]\n",
      " [0.89131658]]\n",
      "Loss: \n",
      " 0.0003506704944794935\n",
      "\n",
      "\n",
      "Epoch: 670\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89547409]\n",
      " [0.83892671]\n",
      " [0.89136139]]\n",
      "Loss: \n",
      " 0.0003491524104701689\n",
      "\n",
      "\n",
      "Epoch: 671\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89551879]\n",
      " [0.83898503]\n",
      " [0.89140602]]\n",
      "Loss: \n",
      " 0.0003476451106945319\n",
      "\n",
      "\n",
      "Epoch: 672\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89556332]\n",
      " [0.83904313]\n",
      " [0.89145047]]\n",
      "Loss: \n",
      " 0.00034614850946958236\n",
      "\n",
      "\n",
      "Epoch: 673\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89560767]\n",
      " [0.83910101]\n",
      " [0.89149475]]\n",
      "Loss: \n",
      " 0.0003446625218826911\n",
      "\n",
      "\n",
      "Epoch: 674\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89565185]\n",
      " [0.83915867]\n",
      " [0.89153886]]\n",
      "Loss: \n",
      " 0.00034318706378371394\n",
      "\n",
      "\n",
      "Epoch: 675\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89569586]\n",
      " [0.83921612]\n",
      " [0.89158279]]\n",
      "Loss: \n",
      " 0.000341722051777198\n",
      "\n",
      "\n",
      "Epoch: 676\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8957397 ]\n",
      " [0.83927334]\n",
      " [0.89162655]]\n",
      "Loss: \n",
      " 0.0003402674032147003\n",
      "\n",
      "\n",
      "Epoch: 677\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89578336]\n",
      " [0.83933035]\n",
      " [0.89167013]]\n",
      "Loss: \n",
      " 0.0003388230361871316\n",
      "\n",
      "\n",
      "Epoch: 678\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89582686]\n",
      " [0.83938715]\n",
      " [0.89171355]]\n",
      "Loss: \n",
      " 0.00033738886951727447\n",
      "\n",
      "\n",
      "Epoch: 679\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89587019]\n",
      " [0.83944373]\n",
      " [0.8917568 ]]\n",
      "Loss: \n",
      " 0.00033596482275232835\n",
      "\n",
      "\n",
      "Epoch: 680\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89591335]\n",
      " [0.8395001 ]\n",
      " [0.89179987]]\n",
      "Loss: \n",
      " 0.0003345508161565454\n",
      "\n",
      "\n",
      "Epoch: 681\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89595634]\n",
      " [0.83955625]\n",
      " [0.89184278]]\n",
      "Loss: \n",
      " 0.00033314677070399274\n",
      "\n",
      "\n",
      "Epoch: 682\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89599916]\n",
      " [0.8396122 ]\n",
      " [0.89188552]]\n",
      "Loss: \n",
      " 0.0003317526080713346\n",
      "\n",
      "\n",
      "Epoch: 683\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89604182]\n",
      " [0.83966793]\n",
      " [0.8919281 ]]\n",
      "Loss: \n",
      " 0.0003303682506307491\n",
      "\n",
      "\n",
      "Epoch: 684\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89608432]\n",
      " [0.83972346]\n",
      " [0.89197051]]\n",
      "Loss: \n",
      " 0.0003289936214429104\n",
      "\n",
      "\n",
      "Epoch: 685\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89612665]\n",
      " [0.83977878]\n",
      " [0.89201275]]\n",
      "Loss: \n",
      " 0.00032762864425003624\n",
      "\n",
      "\n",
      "Epoch: 686\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89616882]\n",
      " [0.83983389]\n",
      " [0.89205483]]\n",
      "Loss: \n",
      " 0.000326273243469039\n",
      "\n",
      "\n",
      "Epoch: 687\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89621082]\n",
      " [0.83988879]\n",
      " [0.89209674]]\n",
      "Loss: \n",
      " 0.0003249273441847292\n",
      "\n",
      "\n",
      "Epoch: 688\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89625266]\n",
      " [0.83994349]\n",
      " [0.8921385 ]]\n",
      "Loss: \n",
      " 0.00032359087214313284\n",
      "\n",
      "\n",
      "Epoch: 689\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89629435]\n",
      " [0.83999799]\n",
      " [0.89218009]]\n",
      "Loss: \n",
      " 0.0003222637537448354\n",
      "\n",
      "\n",
      "Epoch: 690\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89633587]\n",
      " [0.84005228]\n",
      " [0.89222152]]\n",
      "Loss: \n",
      " 0.00032094591603844556\n",
      "\n",
      "\n",
      "Epoch: 691\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89637723]\n",
      " [0.84010637]\n",
      " [0.89226278]]\n",
      "Loss: \n",
      " 0.00031963728671411973\n",
      "\n",
      "\n",
      "Epoch: 692\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89641844]\n",
      " [0.84016026]\n",
      " [0.89230389]]\n",
      "Loss: \n",
      " 0.00031833779409712765\n",
      "\n",
      "\n",
      "Epoch: 693\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89645948]\n",
      " [0.84021395]\n",
      " [0.89234484]]\n",
      "Loss: \n",
      " 0.00031704736714156714\n",
      "\n",
      "\n",
      "Epoch: 694\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89650037]\n",
      " [0.84026744]\n",
      " [0.89238564]]\n",
      "Loss: \n",
      " 0.00031576593542404196\n",
      "\n",
      "\n",
      "Epoch: 695\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89654111]\n",
      " [0.84032073]\n",
      " [0.89242627]]\n",
      "Loss: \n",
      " 0.00031449342913752895\n",
      "\n",
      "\n",
      "Epoch: 696\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89658168]\n",
      " [0.84037382]\n",
      " [0.89246675]]\n",
      "Loss: \n",
      " 0.0003132297790852206\n",
      "\n",
      "\n",
      "Epoch: 697\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89662211]\n",
      " [0.84042671]\n",
      " [0.89250707]]\n",
      "Loss: \n",
      " 0.0003119749166744778\n",
      "\n",
      "\n",
      "Epoch: 698\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89666238]\n",
      " [0.84047941]\n",
      " [0.89254724]]\n",
      "Loss: \n",
      " 0.00031072877391084846\n",
      "\n",
      "\n",
      "Epoch: 699\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89670249]\n",
      " [0.84053192]\n",
      " [0.89258725]]\n",
      "Loss: \n",
      " 0.0003094912833921636\n",
      "\n",
      "\n",
      "Epoch: 700\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89674246]\n",
      " [0.84058423]\n",
      " [0.89262711]]\n",
      "Loss: \n",
      " 0.0003082623783026539\n",
      "\n",
      "\n",
      "Epoch: 701\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89678227]\n",
      " [0.84063635]\n",
      " [0.89266682]]\n",
      "Loss: \n",
      " 0.000307041992407199\n",
      "\n",
      "\n",
      "Epoch: 702\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89682193]\n",
      " [0.84068828]\n",
      " [0.89270637]]\n",
      "Loss: \n",
      " 0.00030583006004558454\n",
      "\n",
      "\n",
      "Epoch: 703\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89686144]\n",
      " [0.84074001]\n",
      " [0.89274578]]\n",
      "Loss: \n",
      " 0.0003046265161268411\n",
      "\n",
      "\n",
      "Epoch: 704\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8969008 ]\n",
      " [0.84079155]\n",
      " [0.89278503]]\n",
      "Loss: \n",
      " 0.0003034312961236703\n",
      "\n",
      "\n",
      "Epoch: 705\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89694001]\n",
      " [0.84084291]\n",
      " [0.89282413]]\n",
      "Loss: \n",
      " 0.0003022443360668942\n",
      "\n",
      "\n",
      "Epoch: 706\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89697907]\n",
      " [0.84089408]\n",
      " [0.89286308]]\n",
      "Loss: \n",
      " 0.000301065572539998\n",
      "\n",
      "\n",
      "Epoch: 707\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89701799]\n",
      " [0.84094505]\n",
      " [0.89290189]]\n",
      "Loss: \n",
      " 0.0002998949426737053\n",
      "\n",
      "\n",
      "Epoch: 708\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89705676]\n",
      " [0.84099585]\n",
      " [0.89294054]]\n",
      "Loss: \n",
      " 0.00029873238414064286\n",
      "\n",
      "\n",
      "Epoch: 709\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89709538]\n",
      " [0.84104645]\n",
      " [0.89297905]]\n",
      "Loss: \n",
      " 0.0002975778351500366\n",
      "\n",
      "\n",
      "Epoch: 710\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89713385]\n",
      " [0.84109687]\n",
      " [0.89301741]]\n",
      "Loss: \n",
      " 0.0002964312344424868\n",
      "\n",
      "\n",
      "Epoch: 711\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89717219]\n",
      " [0.84114711]\n",
      " [0.89305563]]\n",
      "Loss: \n",
      " 0.00029529252128479344\n",
      "\n",
      "\n",
      "Epoch: 712\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89721037]\n",
      " [0.84119716]\n",
      " [0.8930937 ]]\n",
      "Loss: \n",
      " 0.0002941616354648357\n",
      "\n",
      "\n",
      "Epoch: 713\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89724842]\n",
      " [0.84124703]\n",
      " [0.89313163]]\n",
      "Loss: \n",
      " 0.0002930385172865068\n",
      "\n",
      "\n",
      "Epoch: 714\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89728632]\n",
      " [0.84129672]\n",
      " [0.89316941]]\n",
      "Loss: \n",
      " 0.0002919231075647175\n",
      "\n",
      "\n",
      "Epoch: 715\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89732408]\n",
      " [0.84134622]\n",
      " [0.89320705]]\n",
      "Loss: \n",
      " 0.0002908153476204436\n",
      "\n",
      "\n",
      "Epoch: 716\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8973617 ]\n",
      " [0.84139555]\n",
      " [0.89324454]]\n",
      "Loss: \n",
      " 0.0002897151792758096\n",
      "\n",
      "\n",
      "Epoch: 717\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89739917]\n",
      " [0.84144469]\n",
      " [0.8932819 ]]\n",
      "Loss: \n",
      " 0.0002886225448492774\n",
      "\n",
      "\n",
      "Epoch: 718\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89743651]\n",
      " [0.84149366]\n",
      " [0.89331911]]\n",
      "Loss: \n",
      " 0.0002875373871508397\n",
      "\n",
      "\n",
      "Epoch: 719\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89747371]\n",
      " [0.84154245]\n",
      " [0.89335619]]\n",
      "Loss: \n",
      " 0.00028645964947727245\n",
      "\n",
      "\n",
      "Epoch: 720\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89751076]\n",
      " [0.84159107]\n",
      " [0.89339312]]\n",
      "Loss: \n",
      " 0.00028538927560745677\n",
      "\n",
      "\n",
      "Epoch: 721\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89754768]\n",
      " [0.8416395 ]\n",
      " [0.89342991]]\n",
      "Loss: \n",
      " 0.0002843262097977581\n",
      "\n",
      "\n",
      "Epoch: 722\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89758447]\n",
      " [0.84168776]\n",
      " [0.89346657]]\n",
      "Loss: \n",
      " 0.0002832703967774219\n",
      "\n",
      "\n",
      "Epoch: 723\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89762111]\n",
      " [0.84173585]\n",
      " [0.89350309]]\n",
      "Loss: \n",
      " 0.00028222178174404296\n",
      "\n",
      "\n",
      "Epoch: 724\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89765762]\n",
      " [0.84178376]\n",
      " [0.89353947]]\n",
      "Loss: \n",
      " 0.00028118031035907916\n",
      "\n",
      "\n",
      "Epoch: 725\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.897694  ]\n",
      " [0.8418315 ]\n",
      " [0.89357571]]\n",
      "Loss: \n",
      " 0.00028014592874342313\n",
      "\n",
      "\n",
      "Epoch: 726\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89773023]\n",
      " [0.84187907]\n",
      " [0.89361182]]\n",
      "Loss: \n",
      " 0.00027911858347300084\n",
      "\n",
      "\n",
      "Epoch: 727\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89776634]\n",
      " [0.84192647]\n",
      " [0.89364779]]\n",
      "Loss: \n",
      " 0.0002780982215744307\n",
      "\n",
      "\n",
      "Epoch: 728\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89780231]\n",
      " [0.84197369]\n",
      " [0.89368363]]\n",
      "Loss: \n",
      " 0.0002770847905207358\n",
      "\n",
      "\n",
      "Epoch: 729\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89783815]\n",
      " [0.84202075]\n",
      " [0.89371933]]\n",
      "Loss: \n",
      " 0.0002760782382270911\n",
      "\n",
      "\n",
      "Epoch: 730\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89787385]\n",
      " [0.84206763]\n",
      " [0.8937549 ]]\n",
      "Loss: \n",
      " 0.00027507851304661674\n",
      "\n",
      "\n",
      "Epoch: 731\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89790942]\n",
      " [0.84211435]\n",
      " [0.89379033]]\n",
      "Loss: \n",
      " 0.00027408556376621874\n",
      "\n",
      "\n",
      "Epoch: 732\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89794486]\n",
      " [0.8421609 ]\n",
      " [0.89382564]]\n",
      "Loss: \n",
      " 0.0002730993396024906\n",
      "\n",
      "\n",
      "Epoch: 733\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89798017]\n",
      " [0.84220728]\n",
      " [0.89386081]]\n",
      "Loss: \n",
      " 0.000272119790197611\n",
      "\n",
      "\n",
      "Epoch: 734\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89801535]\n",
      " [0.8422535 ]\n",
      " [0.89389585]]\n",
      "Loss: \n",
      " 0.00027114686561536416\n",
      "\n",
      "\n",
      "Epoch: 735\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8980504 ]\n",
      " [0.84229955]\n",
      " [0.89393076]]\n",
      "Loss: \n",
      " 0.00027018051633711273\n",
      "\n",
      "\n",
      "Epoch: 736\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89808533]\n",
      " [0.84234544]\n",
      " [0.89396554]]\n",
      "Loss: \n",
      " 0.00026922069325788033\n",
      "\n",
      "\n",
      "Epoch: 737\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89812012]\n",
      " [0.84239116]\n",
      " [0.89400019]]\n",
      "Loss: \n",
      " 0.0002682673476824396\n",
      "\n",
      "\n",
      "Epoch: 738\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89815478]\n",
      " [0.84243672]\n",
      " [0.89403471]]\n",
      "Loss: \n",
      " 0.00026732043132148545\n",
      "\n",
      "\n",
      "Epoch: 739\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89818932]\n",
      " [0.84248211]\n",
      " [0.89406911]]\n",
      "Loss: \n",
      " 0.00026637989628776885\n",
      "\n",
      "\n",
      "Epoch: 740\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89822373]\n",
      " [0.84252735]\n",
      " [0.89410337]]\n",
      "Loss: \n",
      " 0.00026544569509236757\n",
      "\n",
      "\n",
      "Epoch: 741\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89825802]\n",
      " [0.84257242]\n",
      " [0.89413751]]\n",
      "Loss: \n",
      " 0.00026451778064092346\n",
      "\n",
      "\n",
      "Epoch: 742\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89829218]\n",
      " [0.84261733]\n",
      " [0.89417152]]\n",
      "Loss: \n",
      " 0.00026359610622995674\n",
      "\n",
      "\n",
      "Epoch: 743\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89832621]\n",
      " [0.84266208]\n",
      " [0.89420541]]\n",
      "Loss: \n",
      " 0.00026268062554320767\n",
      "\n",
      "\n",
      "Epoch: 744\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89836012]\n",
      " [0.84270668]\n",
      " [0.89423917]]\n",
      "Loss: \n",
      " 0.0002617712926480135\n",
      "\n",
      "\n",
      "Epoch: 745\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89839391]\n",
      " [0.84275111]\n",
      " [0.89427281]]\n",
      "Loss: \n",
      " 0.00026086806199173584\n",
      "\n",
      "\n",
      "Epoch: 746\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89842757]\n",
      " [0.84279539]\n",
      " [0.89430632]]\n",
      "Loss: \n",
      " 0.00025997088839820303\n",
      "\n",
      "\n",
      "Epoch: 747\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89846111]\n",
      " [0.84283951]\n",
      " [0.8943397 ]]\n",
      "Loss: \n",
      " 0.0002590797270642307\n",
      "\n",
      "\n",
      "Epoch: 748\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89849453]\n",
      " [0.84288347]\n",
      " [0.89437297]]\n",
      "Loss: \n",
      " 0.00025819453355612414\n",
      "\n",
      "\n",
      "Epoch: 749\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89852783]\n",
      " [0.84292728]\n",
      " [0.89440611]]\n",
      "Loss: \n",
      " 0.0002573152638062664\n",
      "\n",
      "\n",
      "Epoch: 750\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.898561  ]\n",
      " [0.84297093]\n",
      " [0.89443913]]\n",
      "Loss: \n",
      " 0.0002564418741097118\n",
      "\n",
      "\n",
      "Epoch: 751\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89859406]\n",
      " [0.84301443]\n",
      " [0.89447203]]\n",
      "Loss: \n",
      " 0.0002555743211208339\n",
      "\n",
      "\n",
      "Epoch: 752\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89862699]\n",
      " [0.84305778]\n",
      " [0.89450481]]\n",
      "Loss: \n",
      " 0.00025471256184998644\n",
      "\n",
      "\n",
      "Epoch: 753\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89865981]\n",
      " [0.84310097]\n",
      " [0.89453746]]\n",
      "Loss: \n",
      " 0.00025385655366022385\n",
      "\n",
      "\n",
      "Epoch: 754\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8986925 ]\n",
      " [0.84314401]\n",
      " [0.89457   ]]\n",
      "Loss: \n",
      " 0.0002530062542640417\n",
      "\n",
      "\n",
      "Epoch: 755\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89872508]\n",
      " [0.8431869 ]\n",
      " [0.89460242]]\n",
      "Loss: \n",
      " 0.0002521616217201507\n",
      "\n",
      "\n",
      "Epoch: 756\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89875754]\n",
      " [0.84322963]\n",
      " [0.89463472]]\n",
      "Loss: \n",
      " 0.0002513226144302939\n",
      "\n",
      "\n",
      "Epoch: 757\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89878988]\n",
      " [0.84327222]\n",
      " [0.8946669 ]]\n",
      "Loss: \n",
      " 0.00025048919113608147\n",
      "\n",
      "\n",
      "Epoch: 758\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89882211]\n",
      " [0.84331466]\n",
      " [0.89469896]]\n",
      "Loss: \n",
      " 0.0002496613109158771\n",
      "\n",
      "\n",
      "Epoch: 759\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89885422]\n",
      " [0.84335694]\n",
      " [0.8947309 ]]\n",
      "Loss: \n",
      " 0.0002488389331816962\n",
      "\n",
      "\n",
      "Epoch: 760\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89888621]\n",
      " [0.84339908]\n",
      " [0.89476273]]\n",
      "Loss: \n",
      " 0.0002480220176761571\n",
      "\n",
      "\n",
      "Epoch: 761\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89891809]\n",
      " [0.84344108]\n",
      " [0.89479444]]\n",
      "Loss: \n",
      " 0.00024721052446944957\n",
      "\n",
      "\n",
      "Epoch: 762\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89894985]\n",
      " [0.84348292]\n",
      " [0.89482604]]\n",
      "Loss: \n",
      " 0.00024640441395632997\n",
      "\n",
      "\n",
      "Epoch: 763\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8989815 ]\n",
      " [0.84352462]\n",
      " [0.89485752]]\n",
      "Loss: \n",
      " 0.00024560364685317514\n",
      "\n",
      "\n",
      "Epoch: 764\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89901304]\n",
      " [0.84356617]\n",
      " [0.89488889]]\n",
      "Loss: \n",
      " 0.00024480818419502485\n",
      "\n",
      "\n",
      "Epoch: 765\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89904446]\n",
      " [0.84360758]\n",
      " [0.89492014]]\n",
      "Loss: \n",
      " 0.00024401798733269357\n",
      "\n",
      "\n",
      "Epoch: 766\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89907577]\n",
      " [0.84364884]\n",
      " [0.89495128]]\n",
      "Loss: \n",
      " 0.000243233017929894\n",
      "\n",
      "\n",
      "Epoch: 767\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89910697]\n",
      " [0.84368996]\n",
      " [0.8949823 ]]\n",
      "Loss: \n",
      " 0.00024245323796037786\n",
      "\n",
      "\n",
      "Epoch: 768\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89913805]\n",
      " [0.84373093]\n",
      " [0.89501322]]\n",
      "Loss: \n",
      " 0.00024167860970513997\n",
      "\n",
      "\n",
      "Epoch: 769\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89916903]\n",
      " [0.84377176]\n",
      " [0.89504401]]\n",
      "Loss: \n",
      " 0.00024090909574960668\n",
      "\n",
      "\n",
      "Epoch: 770\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89919989]\n",
      " [0.84381245]\n",
      " [0.8950747 ]]\n",
      "Loss: \n",
      " 0.00024014465898089833\n",
      "\n",
      "\n",
      "Epoch: 771\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89923064]\n",
      " [0.843853  ]\n",
      " [0.89510528]]\n",
      "Loss: \n",
      " 0.00023938526258509784\n",
      "\n",
      "\n",
      "Epoch: 772\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89926128]\n",
      " [0.84389341]\n",
      " [0.89513575]]\n",
      "Loss: \n",
      " 0.00023863087004451702\n",
      "\n",
      "\n",
      "Epoch: 773\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89929182]\n",
      " [0.84393367]\n",
      " [0.8951661 ]]\n",
      "Loss: \n",
      " 0.0002378814451350713\n",
      "\n",
      "\n",
      "Epoch: 774\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89932224]\n",
      " [0.8439738 ]\n",
      " [0.89519635]]\n",
      "Loss: \n",
      " 0.00023713695192357926\n",
      "\n",
      "\n",
      "Epoch: 775\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89935256]\n",
      " [0.84401379]\n",
      " [0.89522648]]\n",
      "Loss: \n",
      " 0.00023639735476518124\n",
      "\n",
      "\n",
      "Epoch: 776\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89938276]\n",
      " [0.84405364]\n",
      " [0.89525651]]\n",
      "Loss: \n",
      " 0.00023566261830071847\n",
      "\n",
      "\n",
      "Epoch: 777\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89941286]\n",
      " [0.84409335]\n",
      " [0.89528643]]\n",
      "Loss: \n",
      " 0.0002349327074541821\n",
      "\n",
      "\n",
      "Epoch: 778\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89944286]\n",
      " [0.84413292]\n",
      " [0.89531624]]\n",
      "Loss: \n",
      " 0.00023420758743015395\n",
      "\n",
      "\n",
      "Epoch: 779\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89947274]\n",
      " [0.84417236]\n",
      " [0.89534594]]\n",
      "Loss: \n",
      " 0.00023348722371130956\n",
      "\n",
      "\n",
      "Epoch: 780\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89950252]\n",
      " [0.84421166]\n",
      " [0.89537554]]\n",
      "Loss: \n",
      " 0.0002327715820559036\n",
      "\n",
      "\n",
      "Epoch: 781\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8995322 ]\n",
      " [0.84425082]\n",
      " [0.89540503]]\n",
      "Loss: \n",
      " 0.00023206062849532105\n",
      "\n",
      "\n",
      "Epoch: 782\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89956177]\n",
      " [0.84428985]\n",
      " [0.89543441]]\n",
      "Loss: \n",
      " 0.00023135432933162918\n",
      "\n",
      "\n",
      "Epoch: 783\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89959123]\n",
      " [0.84432874]\n",
      " [0.89546369]]\n",
      "Loss: \n",
      " 0.00023065265113515757\n",
      "\n",
      "\n",
      "Epoch: 784\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89962059]\n",
      " [0.8443675 ]\n",
      " [0.89549286]]\n",
      "Loss: \n",
      " 0.00022995556074211125\n",
      "\n",
      "\n",
      "Epoch: 785\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89964985]\n",
      " [0.84440613]\n",
      " [0.89552193]]\n",
      "Loss: \n",
      " 0.000229263025252195\n",
      "\n",
      "\n",
      "Epoch: 786\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.899679  ]\n",
      " [0.84444462]\n",
      " [0.89555089]]\n",
      "Loss: \n",
      " 0.00022857501202626905\n",
      "\n",
      "\n",
      "Epoch: 787\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89970805]\n",
      " [0.84448298]\n",
      " [0.89557975]]\n",
      "Loss: \n",
      " 0.0002278914886840365\n",
      "\n",
      "\n",
      "Epoch: 788\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.899737  ]\n",
      " [0.84452121]\n",
      " [0.89560851]]\n",
      "Loss: \n",
      " 0.00022721242310174317\n",
      "\n",
      "\n",
      "Epoch: 789\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89976585]\n",
      " [0.84455931]\n",
      " [0.89563716]]\n",
      "Loss: \n",
      " 0.00022653778340987575\n",
      "\n",
      "\n",
      "Epoch: 790\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89979459]\n",
      " [0.84459728]\n",
      " [0.89566571]]\n",
      "Loss: \n",
      " 0.000225867537990949\n",
      "\n",
      "\n",
      "Epoch: 791\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89982323]\n",
      " [0.84463512]\n",
      " [0.89569416]]\n",
      "Loss: \n",
      " 0.00022520165547725232\n",
      "\n",
      "\n",
      "Epoch: 792\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89985178]\n",
      " [0.84467283]\n",
      " [0.89572251]]\n",
      "Loss: \n",
      " 0.00022454010474863852\n",
      "\n",
      "\n",
      "Epoch: 793\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89988022]\n",
      " [0.8447104 ]\n",
      " [0.89575075]]\n",
      "Loss: \n",
      " 0.00022388285493034525\n",
      "\n",
      "\n",
      "Epoch: 794\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89990856]\n",
      " [0.84474785]\n",
      " [0.8957789 ]]\n",
      "Loss: \n",
      " 0.00022322987539084307\n",
      "\n",
      "\n",
      "Epoch: 795\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.8999368 ]\n",
      " [0.84478518]\n",
      " [0.89580694]]\n",
      "Loss: \n",
      " 0.00022258113573965215\n",
      "\n",
      "\n",
      "Epoch: 796\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89996494]\n",
      " [0.84482237]\n",
      " [0.89583489]]\n",
      "Loss: \n",
      " 0.00022193660582527279\n",
      "\n",
      "\n",
      "Epoch: 797\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89999299]\n",
      " [0.84485944]\n",
      " [0.89586273]]\n",
      "Loss: \n",
      " 0.00022129625573304046\n",
      "\n",
      "\n",
      "Epoch: 798\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90002093]\n",
      " [0.84489638]\n",
      " [0.89589048]]\n",
      "Loss: \n",
      " 0.00022066005578306775\n",
      "\n",
      "\n",
      "Epoch: 799\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90004878]\n",
      " [0.84493319]\n",
      " [0.89591812]]\n",
      "Loss: \n",
      " 0.00022002797652817869\n",
      "\n",
      "\n",
      "Epoch: 800\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90007653]\n",
      " [0.84496988]\n",
      " [0.89594567]]\n",
      "Loss: \n",
      " 0.00021939998875187256\n",
      "\n",
      "\n",
      "Epoch: 801\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90010419]\n",
      " [0.84500645]\n",
      " [0.89597312]]\n",
      "Loss: \n",
      " 0.00021877606346629643\n",
      "\n",
      "\n",
      "Epoch: 802\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90013174]\n",
      " [0.84504289]\n",
      " [0.89600047]]\n",
      "Loss: \n",
      " 0.00021815617191025334\n",
      "\n",
      "\n",
      "Epoch: 803\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.9001592 ]\n",
      " [0.8450792 ]\n",
      " [0.89602773]]\n",
      "Loss: \n",
      " 0.00021754028554722213\n",
      "\n",
      "\n",
      "Epoch: 804\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90018657]\n",
      " [0.8451154 ]\n",
      " [0.89605489]]\n",
      "Loss: \n",
      " 0.00021692837606338832\n",
      "\n",
      "\n",
      "Epoch: 805\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90021384]\n",
      " [0.84515147]\n",
      " [0.89608195]]\n",
      "Loss: \n",
      " 0.00021632041536571425\n",
      "\n",
      "\n",
      "Epoch: 806\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90024101]\n",
      " [0.84518741]\n",
      " [0.89610892]]\n",
      "Loss: \n",
      " 0.00021571637558000516\n",
      "\n",
      "\n",
      "Epoch: 807\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90026809]\n",
      " [0.84522324]\n",
      " [0.89613579]]\n",
      "Loss: \n",
      " 0.0002151162290490164\n",
      "\n",
      "\n",
      "Epoch: 808\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90029508]\n",
      " [0.84525894]\n",
      " [0.89616257]]\n",
      "Loss: \n",
      " 0.00021451994833056003\n",
      "\n",
      "\n",
      "Epoch: 809\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90032197]\n",
      " [0.84529453]\n",
      " [0.89618925]]\n",
      "Loss: \n",
      " 0.0002139275061956398\n",
      "\n",
      "\n",
      "Epoch: 810\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90034877]\n",
      " [0.84532999]\n",
      " [0.89621583]]\n",
      "Loss: \n",
      " 0.00021333887562661116\n",
      "\n",
      "\n",
      "Epoch: 811\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90037548]\n",
      " [0.84536533]\n",
      " [0.89624233]]\n",
      "Loss: \n",
      " 0.00021275402981533187\n",
      "\n",
      "\n",
      "Epoch: 812\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90040209]\n",
      " [0.84540056]\n",
      " [0.89626873]]\n",
      "Loss: \n",
      " 0.0002121729421613685\n",
      "\n",
      "\n",
      "Epoch: 813\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90042861]\n",
      " [0.84543566]\n",
      " [0.89629503]]\n",
      "Loss: \n",
      " 0.0002115955862701948\n",
      "\n",
      "\n",
      "Epoch: 814\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90045504]\n",
      " [0.84547065]\n",
      " [0.89632125]]\n",
      "Loss: \n",
      " 0.00021102193595140366\n",
      "\n",
      "\n",
      "Epoch: 815\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90048137]\n",
      " [0.84550552]\n",
      " [0.89634737]]\n",
      "Loss: \n",
      " 0.0002104519652169647\n",
      "\n",
      "\n",
      "Epoch: 816\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90050762]\n",
      " [0.84554027]\n",
      " [0.8963734 ]]\n",
      "Loss: \n",
      " 0.00020988564827946542\n",
      "\n",
      "\n",
      "Epoch: 817\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90053378]\n",
      " [0.8455749 ]\n",
      " [0.89639934]]\n",
      "Loss: \n",
      " 0.00020932295955038984\n",
      "\n",
      "\n",
      "Epoch: 818\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90055984]\n",
      " [0.84560942]\n",
      " [0.89642518]]\n",
      "Loss: \n",
      " 0.00020876387363840632\n",
      "\n",
      "\n",
      "Epoch: 819\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90058582]\n",
      " [0.84564382]\n",
      " [0.89645094]]\n",
      "Loss: \n",
      " 0.00020820836534768836\n",
      "\n",
      "\n",
      "Epoch: 820\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.9006117]\n",
      " [0.8456781]\n",
      " [0.8964766]]\n",
      "Loss: \n",
      " 0.00020765640967621357\n",
      "\n",
      "\n",
      "Epoch: 821\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.9006375 ]\n",
      " [0.84571227]\n",
      " [0.89650218]]\n",
      "Loss: \n",
      " 0.00020710798181411275\n",
      "\n",
      "\n",
      "Epoch: 822\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.9006632 ]\n",
      " [0.84574633]\n",
      " [0.89652767]]\n",
      "Loss: \n",
      " 0.00020656305714202833\n",
      "\n",
      "\n",
      "Epoch: 823\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90068882]\n",
      " [0.84578027]\n",
      " [0.89655306]]\n",
      "Loss: \n",
      " 0.00020602161122948884\n",
      "\n",
      "\n",
      "Epoch: 824\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90071435]\n",
      " [0.8458141 ]\n",
      " [0.89657837]]\n",
      "Loss: \n",
      " 0.0002054836198332733\n",
      "\n",
      "\n",
      "Epoch: 825\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.9007398 ]\n",
      " [0.84584781]\n",
      " [0.89660359]]\n",
      "Loss: \n",
      " 0.00020494905889584667\n",
      "\n",
      "\n",
      "Epoch: 826\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90076515]\n",
      " [0.84588141]\n",
      " [0.89662872]]\n",
      "Loss: \n",
      " 0.00020441790454374064\n",
      "\n",
      "\n",
      "Epoch: 827\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90079042]\n",
      " [0.8459149 ]\n",
      " [0.89665376]]\n",
      "Loss: \n",
      " 0.00020389013308601202\n",
      "\n",
      "\n",
      "Epoch: 828\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.9008156 ]\n",
      " [0.84594828]\n",
      " [0.89667872]]\n",
      "Loss: \n",
      " 0.00020336572101267304\n",
      "\n",
      "\n",
      "Epoch: 829\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.9008407 ]\n",
      " [0.84598155]\n",
      " [0.89670358]]\n",
      "Loss: \n",
      " 0.00020284464499316875\n",
      "\n",
      "\n",
      "Epoch: 830\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90086571]\n",
      " [0.8460147 ]\n",
      " [0.89672836]]\n",
      "Loss: \n",
      " 0.00020232688187483503\n",
      "\n",
      "\n",
      "Epoch: 831\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90089063]\n",
      " [0.84604775]\n",
      " [0.89675306]]\n",
      "Loss: \n",
      " 0.00020181240868140794\n",
      "\n",
      "\n",
      "Epoch: 832\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90091547]\n",
      " [0.84608068]\n",
      " [0.89677767]]\n",
      "Loss: \n",
      " 0.00020130120261151543\n",
      "\n",
      "\n",
      "Epoch: 833\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90094022]\n",
      " [0.8461135 ]\n",
      " [0.89680219]]\n",
      "Loss: \n",
      " 0.0002007932410371988\n",
      "\n",
      "\n",
      "Epoch: 834\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90096489]\n",
      " [0.84614622]\n",
      " [0.89682663]]\n",
      "Loss: \n",
      " 0.00020028850150244533\n",
      "\n",
      "\n",
      "Epoch: 835\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90098948]\n",
      " [0.84617882]\n",
      " [0.89685098]]\n",
      "Loss: \n",
      " 0.00019978696172174887\n",
      "\n",
      "\n",
      "Epoch: 836\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90101398]\n",
      " [0.84621132]\n",
      " [0.89687525]]\n",
      "Loss: \n",
      " 0.0001992885995786535\n",
      "\n",
      "\n",
      "Epoch: 837\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90103839]\n",
      " [0.84624371]\n",
      " [0.89689943]]\n",
      "Loss: \n",
      " 0.00019879339312433108\n",
      "\n",
      "\n",
      "Epoch: 838\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90106273]\n",
      " [0.84627599]\n",
      " [0.89692353]]\n",
      "Loss: \n",
      " 0.00019830132057617705\n",
      "\n",
      "\n",
      "Epoch: 839\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90108698]\n",
      " [0.84630817]\n",
      " [0.89694754]]\n",
      "Loss: \n",
      " 0.00019781236031640235\n",
      "\n",
      "\n",
      "Epoch: 840\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90111115]\n",
      " [0.84634023]\n",
      " [0.89697147]]\n",
      "Loss: \n",
      " 0.00019732649089066205\n",
      "\n",
      "\n",
      "Epoch: 841\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90113523]\n",
      " [0.8463722 ]\n",
      " [0.89699532]]\n",
      "Loss: \n",
      " 0.00019684369100666564\n",
      "\n",
      "\n",
      "Epoch: 842\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90115924]\n",
      " [0.84640405]\n",
      " [0.89701909]]\n",
      "Loss: \n",
      " 0.00019636393953282203\n",
      "\n",
      "\n",
      "Epoch: 843\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90118316]\n",
      " [0.8464358 ]\n",
      " [0.89704277]]\n",
      "Loss: \n",
      " 0.00019588721549690456\n",
      "\n",
      "\n",
      "Epoch: 844\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.901207  ]\n",
      " [0.84646745]\n",
      " [0.89706637]]\n",
      "Loss: \n",
      " 0.00019541349808469783\n",
      "\n",
      "\n",
      "Epoch: 845\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90123076]\n",
      " [0.84649899]\n",
      " [0.89708989]]\n",
      "Loss: \n",
      " 0.00019494276663869307\n",
      "\n",
      "\n",
      "Epoch: 846\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90125444]\n",
      " [0.84653042]\n",
      " [0.89711333]]\n",
      "Loss: \n",
      " 0.00019447500065676525\n",
      "\n",
      "\n",
      "Epoch: 847\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90127804]\n",
      " [0.84656176]\n",
      " [0.89713669]]\n",
      "Loss: \n",
      " 0.00019401017979088554\n",
      "\n",
      "\n",
      "Epoch: 848\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90130156]\n",
      " [0.84659299]\n",
      " [0.89715997]]\n",
      "Loss: \n",
      " 0.00019354828384582853\n",
      "\n",
      "\n",
      "Epoch: 849\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.901325  ]\n",
      " [0.84662411]\n",
      " [0.89718316]]\n",
      "Loss: \n",
      " 0.00019308929277790912\n",
      "\n",
      "\n",
      "Epoch: 850\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90134836]\n",
      " [0.84665513]\n",
      " [0.89720628]]\n",
      "Loss: \n",
      " 0.0001926331866937061\n",
      "\n",
      "\n",
      "Epoch: 851\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90137164]\n",
      " [0.84668606]\n",
      " [0.89722931]]\n",
      "Loss: \n",
      " 0.00019217994584882147\n",
      "\n",
      "\n",
      "Epoch: 852\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90139484]\n",
      " [0.84671688]\n",
      " [0.89725227]]\n",
      "Loss: \n",
      " 0.0001917295506466504\n",
      "\n",
      "\n",
      "Epoch: 853\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90141797]\n",
      " [0.84674759]\n",
      " [0.89727515]]\n",
      "Loss: \n",
      " 0.00019128198163713598\n",
      "\n",
      "\n",
      "Epoch: 854\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90144102]\n",
      " [0.84677821]\n",
      " [0.89729795]]\n",
      "Loss: \n",
      " 0.00019083721951557097\n",
      "\n",
      "\n",
      "Epoch: 855\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90146398]\n",
      " [0.84680873]\n",
      " [0.89732067]]\n",
      "Loss: \n",
      " 0.0001903952451213826\n",
      "\n",
      "\n",
      "Epoch: 856\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90148688]\n",
      " [0.84683914]\n",
      " [0.89734331]]\n",
      "Loss: \n",
      " 0.00018995603943694698\n",
      "\n",
      "\n",
      "Epoch: 857\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90150969]\n",
      " [0.84686946]\n",
      " [0.89736587]]\n",
      "Loss: \n",
      " 0.000189519583586403\n",
      "\n",
      "\n",
      "Epoch: 858\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90153243]\n",
      " [0.84689968]\n",
      " [0.89738836]]\n",
      "Loss: \n",
      " 0.00018908585883447977\n",
      "\n",
      "\n",
      "Epoch: 859\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90155509]\n",
      " [0.84692979]\n",
      " [0.89741077]]\n",
      "Loss: \n",
      " 0.00018865484658534673\n",
      "\n",
      "\n",
      "Epoch: 860\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90157767]\n",
      " [0.84695981]\n",
      " [0.8974331 ]]\n",
      "Loss: \n",
      " 0.00018822652838145005\n",
      "\n",
      "\n",
      "Epoch: 861\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90160018]\n",
      " [0.84698973]\n",
      " [0.89745536]]\n",
      "Loss: \n",
      " 0.00018780088590238475\n",
      "\n",
      "\n",
      "Epoch: 862\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90162262]\n",
      " [0.84701956]\n",
      " [0.89747754]]\n",
      "Loss: \n",
      " 0.000187377900963757\n",
      "\n",
      "\n",
      "Epoch: 863\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90164497]\n",
      " [0.84704928]\n",
      " [0.89749964]]\n",
      "Loss: \n",
      " 0.0001869575555160783\n",
      "\n",
      "\n",
      "Epoch: 864\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90166726]\n",
      " [0.84707891]\n",
      " [0.89752167]]\n",
      "Loss: \n",
      " 0.0001865398316436446\n",
      "\n",
      "\n",
      "Epoch: 865\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90168947]\n",
      " [0.84710844]\n",
      " [0.89754362]]\n",
      "Loss: \n",
      " 0.0001861247115634506\n",
      "\n",
      "\n",
      "Epoch: 866\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.9017116 ]\n",
      " [0.84713788]\n",
      " [0.8975655 ]]\n",
      "Loss: \n",
      " 0.00018571217762408695\n",
      "\n",
      "\n",
      "Epoch: 867\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90173366]\n",
      " [0.84716722]\n",
      " [0.8975873 ]]\n",
      "Loss: \n",
      " 0.0001853022123046795\n",
      "\n",
      "\n",
      "Epoch: 868\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90175565]\n",
      " [0.84719646]\n",
      " [0.89760903]]\n",
      "Loss: \n",
      " 0.0001848947982138109\n",
      "\n",
      "\n",
      "Epoch: 869\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90177756]\n",
      " [0.84722561]\n",
      " [0.89763068]]\n",
      "Loss: \n",
      " 0.0001844899180884704\n",
      "\n",
      "\n",
      "Epoch: 870\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.9017994 ]\n",
      " [0.84725466]\n",
      " [0.89765226]]\n",
      "Loss: \n",
      " 0.00018408755479298777\n",
      "\n",
      "\n",
      "Epoch: 871\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90182116]\n",
      " [0.84728362]\n",
      " [0.89767376]]\n",
      "Loss: \n",
      " 0.00018368769131801486\n",
      "\n",
      "\n",
      "Epoch: 872\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90184286]\n",
      " [0.84731248]\n",
      " [0.89769519]]\n",
      "Loss: \n",
      " 0.00018329031077949176\n",
      "\n",
      "\n",
      "Epoch: 873\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90186448]\n",
      " [0.84734125]\n",
      " [0.89771655]]\n",
      "Loss: \n",
      " 0.00018289539641761515\n",
      "\n",
      "\n",
      "Epoch: 874\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90188603]\n",
      " [0.84736993]\n",
      " [0.89773784]]\n",
      "Loss: \n",
      " 0.00018250293159584148\n",
      "\n",
      "\n",
      "Epoch: 875\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90190751]\n",
      " [0.84739851]\n",
      " [0.89775905]]\n",
      "Loss: \n",
      " 0.00018211289979986884\n",
      "\n",
      "\n",
      "Epoch: 876\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90192891]\n",
      " [0.84742701]\n",
      " [0.89778019]]\n",
      "Loss: \n",
      " 0.00018172528463666847\n",
      "\n",
      "\n",
      "Epoch: 877\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90195025]\n",
      " [0.8474554 ]\n",
      " [0.89780126]]\n",
      "Loss: \n",
      " 0.00018134006983347605\n",
      "\n",
      "\n",
      "Epoch: 878\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90197151]\n",
      " [0.84748371]\n",
      " [0.89782226]]\n",
      "Loss: \n",
      " 0.00018095723923683372\n",
      "\n",
      "\n",
      "Epoch: 879\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.9019927 ]\n",
      " [0.84751193]\n",
      " [0.89784319]]\n",
      "Loss: \n",
      " 0.00018057677681160693\n",
      "\n",
      "\n",
      "Epoch: 880\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90201383]\n",
      " [0.84754005]\n",
      " [0.89786404]]\n",
      "Loss: \n",
      " 0.00018019866664005656\n",
      "\n",
      "\n",
      "Epoch: 881\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90203488]\n",
      " [0.84756808]\n",
      " [0.89788483]]\n",
      "Loss: \n",
      " 0.00017982289292085862\n",
      "\n",
      "\n",
      "Epoch: 882\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90205586]\n",
      " [0.84759602]\n",
      " [0.89790554]]\n",
      "Loss: \n",
      " 0.00017944943996817976\n",
      "\n",
      "\n",
      "Epoch: 883\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90207677]\n",
      " [0.84762388]\n",
      " [0.89792618]]\n",
      "Loss: \n",
      " 0.0001790782922107434\n",
      "\n",
      "\n",
      "Epoch: 884\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90209762]\n",
      " [0.84765164]\n",
      " [0.89794675]]\n",
      "Loss: \n",
      " 0.00017870943419091067\n",
      "\n",
      "\n",
      "Epoch: 885\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90211839]\n",
      " [0.84767931]\n",
      " [0.89796726]]\n",
      "Loss: \n",
      " 0.00017834285056375155\n",
      "\n",
      "\n",
      "Epoch: 886\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.9021391 ]\n",
      " [0.84770689]\n",
      " [0.89798769]]\n",
      "Loss: \n",
      " 0.0001779785260961552\n",
      "\n",
      "\n",
      "Epoch: 887\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90215973]\n",
      " [0.84773439]\n",
      " [0.89800806]]\n",
      "Loss: \n",
      " 0.00017761644566592012\n",
      "\n",
      "\n",
      "Epoch: 888\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.9021803 ]\n",
      " [0.84776179]\n",
      " [0.89802835]]\n",
      "Loss: \n",
      " 0.00017725659426086796\n",
      "\n",
      "\n",
      "Epoch: 889\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.9022008 ]\n",
      " [0.84778911]\n",
      " [0.89804858]]\n",
      "Loss: \n",
      " 0.00017689895697795715\n",
      "\n",
      "\n",
      "Epoch: 890\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90222124]\n",
      " [0.84781634]\n",
      " [0.89806874]]\n",
      "Loss: \n",
      " 0.00017654351902241178\n",
      "\n",
      "\n",
      "Epoch: 891\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.9022416 ]\n",
      " [0.84784348]\n",
      " [0.89808883]]\n",
      "Loss: \n",
      " 0.0001761902657068537\n",
      "\n",
      "\n",
      "Epoch: 892\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.9022619 ]\n",
      " [0.84787053]\n",
      " [0.89810885]]\n",
      "Loss: \n",
      " 0.0001758391824504381\n",
      "\n",
      "\n",
      "Epoch: 893\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90228213]\n",
      " [0.8478975 ]\n",
      " [0.8981288 ]]\n",
      "Loss: \n",
      " 0.0001754902547780132\n",
      "\n",
      "\n",
      "Epoch: 894\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.9023023 ]\n",
      " [0.84792438]\n",
      " [0.89814869]]\n",
      "Loss: \n",
      " 0.00017514346831926051\n",
      "\n",
      "\n",
      "Epoch: 895\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.9023224 ]\n",
      " [0.84795117]\n",
      " [0.89816851]]\n",
      "Loss: \n",
      " 0.0001747988088078747\n",
      "\n",
      "\n",
      "Epoch: 896\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90234243]\n",
      " [0.84797788]\n",
      " [0.89818826]]\n",
      "Loss: \n",
      " 0.00017445626208072336\n",
      "\n",
      "\n",
      "Epoch: 897\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.9023624 ]\n",
      " [0.8480045 ]\n",
      " [0.89820795]]\n",
      "Loss: \n",
      " 0.00017411581407701884\n",
      "\n",
      "\n",
      "Epoch: 898\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.9023823 ]\n",
      " [0.84803104]\n",
      " [0.89822757]]\n",
      "Loss: \n",
      " 0.0001737774508375268\n",
      "\n",
      "\n",
      "Epoch: 899\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90240213]\n",
      " [0.84805749]\n",
      " [0.89824712]]\n",
      "Loss: \n",
      " 0.00017344115850373703\n",
      "\n",
      "\n",
      "Epoch: 900\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.9024219 ]\n",
      " [0.84808386]\n",
      " [0.89826661]]\n",
      "Loss: \n",
      " 0.00017310692331707592\n",
      "\n",
      "\n",
      "Epoch: 901\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90244161]\n",
      " [0.84811014]\n",
      " [0.89828603]]\n",
      "Loss: \n",
      " 0.0001727747316180999\n",
      "\n",
      "\n",
      "Epoch: 902\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90246125]\n",
      " [0.84813634]\n",
      " [0.89830539]]\n",
      "Loss: \n",
      " 0.00017244456984572627\n",
      "\n",
      "\n",
      "Epoch: 903\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90248082]\n",
      " [0.84816246]\n",
      " [0.89832468]]\n",
      "Loss: \n",
      " 0.00017211642453643546\n",
      "\n",
      "\n",
      "Epoch: 904\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90250034]\n",
      " [0.84818849]\n",
      " [0.89834391]]\n",
      "Loss: \n",
      " 0.00017179028232351985\n",
      "\n",
      "\n",
      "Epoch: 905\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90251978]\n",
      " [0.84821444]\n",
      " [0.89836307]]\n",
      "Loss: \n",
      " 0.00017146612993629553\n",
      "\n",
      "\n",
      "Epoch: 906\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90253917]\n",
      " [0.8482403 ]\n",
      " [0.89838217]]\n",
      "Loss: \n",
      " 0.00017114395419935908\n",
      "\n",
      "\n",
      "Epoch: 907\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90255849]\n",
      " [0.84826609]\n",
      " [0.8984012 ]]\n",
      "Loss: \n",
      " 0.00017082374203183405\n",
      "\n",
      "\n",
      "Epoch: 908\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90257775]\n",
      " [0.84829179]\n",
      " [0.89842017]]\n",
      "Loss: \n",
      " 0.00017050548044661166\n",
      "\n",
      "\n",
      "Epoch: 909\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90259694]\n",
      " [0.84831741]\n",
      " [0.89843908]]\n",
      "Loss: \n",
      " 0.00017018915654963226\n",
      "\n",
      "\n",
      "Epoch: 910\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90261607]\n",
      " [0.84834294]\n",
      " [0.89845792]]\n",
      "Loss: \n",
      " 0.0001698747575391338\n",
      "\n",
      "\n",
      "Epoch: 911\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90263514]\n",
      " [0.8483684 ]\n",
      " [0.8984767 ]]\n",
      "Loss: \n",
      " 0.0001695622707049354\n",
      "\n",
      "\n",
      "Epoch: 912\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90265415]\n",
      " [0.84839378]\n",
      " [0.89849542]]\n",
      "Loss: \n",
      " 0.00016925168342771965\n",
      "\n",
      "\n",
      "Epoch: 913\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90267309]\n",
      " [0.84841907]\n",
      " [0.89851407]]\n",
      "Loss: \n",
      " 0.0001689429831783126\n",
      "\n",
      "\n",
      "Epoch: 914\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90269198]\n",
      " [0.84844429]\n",
      " [0.89853266]]\n",
      "Loss: \n",
      " 0.0001686361575169797\n",
      "\n",
      "\n",
      "Epoch: 915\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.9027108 ]\n",
      " [0.84846942]\n",
      " [0.89855119]]\n",
      "Loss: \n",
      " 0.00016833119409271466\n",
      "\n",
      "\n",
      "Epoch: 916\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90272956]\n",
      " [0.84849447]\n",
      " [0.89856966]]\n",
      "Loss: \n",
      " 0.0001680280806425626\n",
      "\n",
      "\n",
      "Epoch: 917\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90274826]\n",
      " [0.84851945]\n",
      " [0.89858806]]\n",
      "Loss: \n",
      " 0.00016772680499092083\n",
      "\n",
      "\n",
      "Epoch: 918\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.9027669 ]\n",
      " [0.84854434]\n",
      " [0.89860641]]\n",
      "Loss: \n",
      " 0.00016742735504885367\n",
      "\n",
      "\n",
      "Epoch: 919\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90278548]\n",
      " [0.84856916]\n",
      " [0.89862469]]\n",
      "Loss: \n",
      " 0.0001671297188134117\n",
      "\n",
      "\n",
      "Epoch: 920\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90280399]\n",
      " [0.8485939 ]\n",
      " [0.89864291]]\n",
      "Loss: \n",
      " 0.00016683388436697477\n",
      "\n",
      "\n",
      "Epoch: 921\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90282245]\n",
      " [0.84861856]\n",
      " [0.89866107]]\n",
      "Loss: \n",
      " 0.00016653983987657557\n",
      "\n",
      "\n",
      "Epoch: 922\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90284085]\n",
      " [0.84864314]\n",
      " [0.89867917]]\n",
      "Loss: \n",
      " 0.00016624757359323767\n",
      "\n",
      "\n",
      "Epoch: 923\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90285919]\n",
      " [0.84866765]\n",
      " [0.89869721]]\n",
      "Loss: \n",
      " 0.00016595707385132837\n",
      "\n",
      "\n",
      "Epoch: 924\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90287746]\n",
      " [0.84869207]\n",
      " [0.89871519]]\n",
      "Loss: \n",
      " 0.00016566832906790826\n",
      "\n",
      "\n",
      "Epoch: 925\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90289568]\n",
      " [0.84871642]\n",
      " [0.89873311]]\n",
      "Loss: \n",
      " 0.00016538132774208394\n",
      "\n",
      "\n",
      "Epoch: 926\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90291384]\n",
      " [0.84874069]\n",
      " [0.89875097]]\n",
      "Loss: \n",
      " 0.00016509605845437753\n",
      "\n",
      "\n",
      "Epoch: 927\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90293194]\n",
      " [0.84876489]\n",
      " [0.89876877]]\n",
      "Loss: \n",
      " 0.00016481250986609321\n",
      "\n",
      "\n",
      "Epoch: 928\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90294999]\n",
      " [0.84878901]\n",
      " [0.89878651]]\n",
      "Loss: \n",
      " 0.00016453067071868317\n",
      "\n",
      "\n",
      "Epoch: 929\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90296797]\n",
      " [0.84881305]\n",
      " [0.89880419]]\n",
      "Loss: \n",
      " 0.00016425052983313552\n",
      "\n",
      "\n",
      "Epoch: 930\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.9029859 ]\n",
      " [0.84883702]\n",
      " [0.89882182]]\n",
      "Loss: \n",
      " 0.00016397207610935162\n",
      "\n",
      "\n",
      "Epoch: 931\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90300377]\n",
      " [0.84886091]\n",
      " [0.89883938]]\n",
      "Loss: \n",
      " 0.00016369529852554732\n",
      "\n",
      "\n",
      "Epoch: 932\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90302158]\n",
      " [0.84888473]\n",
      " [0.89885689]]\n",
      "Loss: \n",
      " 0.0001634201861376247\n",
      "\n",
      "\n",
      "Epoch: 933\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90303933]\n",
      " [0.84890847]\n",
      " [0.89887434]]\n",
      "Loss: \n",
      " 0.0001631467280786066\n",
      "\n",
      "\n",
      "Epoch: 934\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90305702]\n",
      " [0.84893214]\n",
      " [0.89889173]]\n",
      "Loss: \n",
      " 0.00016287491355800247\n",
      "\n",
      "\n",
      "Epoch: 935\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90307466]\n",
      " [0.84895573]\n",
      " [0.89890906]]\n",
      "Loss: \n",
      " 0.00016260473186125257\n",
      "\n",
      "\n",
      "Epoch: 936\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90309224]\n",
      " [0.84897925]\n",
      " [0.89892633]]\n",
      "Loss: \n",
      " 0.00016233617234911787\n",
      "\n",
      "\n",
      "Epoch: 937\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90310977]\n",
      " [0.8490027 ]\n",
      " [0.89894355]]\n",
      "Loss: \n",
      " 0.0001620692244571118\n",
      "\n",
      "\n",
      "Epoch: 938\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90312724]\n",
      " [0.84902607]\n",
      " [0.89896071]]\n",
      "Loss: \n",
      " 0.00016180387769493734\n",
      "\n",
      "\n",
      "Epoch: 939\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90314465]\n",
      " [0.84904937]\n",
      " [0.89897781]]\n",
      "Loss: \n",
      " 0.00016154012164588892\n",
      "\n",
      "\n",
      "Epoch: 940\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.903162  ]\n",
      " [0.84907259]\n",
      " [0.89899486]]\n",
      "Loss: \n",
      " 0.00016127794596630053\n",
      "\n",
      "\n",
      "Epoch: 941\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.9031793 ]\n",
      " [0.84909575]\n",
      " [0.89901185]]\n",
      "Loss: \n",
      " 0.00016101734038500174\n",
      "\n",
      "\n",
      "Epoch: 942\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90319655]\n",
      " [0.84911883]\n",
      " [0.89902879]]\n",
      "Loss: \n",
      " 0.00016075829470273348\n",
      "\n",
      "\n",
      "Epoch: 943\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90321374]\n",
      " [0.84914183]\n",
      " [0.89904566]]\n",
      "Loss: \n",
      " 0.00016050079879162057\n",
      "\n",
      "\n",
      "Epoch: 944\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90323087]\n",
      " [0.84916477]\n",
      " [0.89906249]]\n",
      "Loss: \n",
      " 0.00016024484259460618\n",
      "\n",
      "\n",
      "Epoch: 945\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90324795]\n",
      " [0.84918763]\n",
      " [0.89907925]]\n",
      "Loss: \n",
      " 0.00015999041612492393\n",
      "\n",
      "\n",
      "Epoch: 946\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90326497]\n",
      " [0.84921043]\n",
      " [0.89909596]]\n",
      "Loss: \n",
      " 0.00015973750946555955\n",
      "\n",
      "\n",
      "Epoch: 947\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90328194]\n",
      " [0.84923315]\n",
      " [0.89911262]]\n",
      "Loss: \n",
      " 0.00015948611276871193\n",
      "\n",
      "\n",
      "Epoch: 948\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90329886]\n",
      " [0.8492558 ]\n",
      " [0.89912922]]\n",
      "Loss: \n",
      " 0.00015923621625526767\n",
      "\n",
      "\n",
      "Epoch: 949\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90331572]\n",
      " [0.84927838]\n",
      " [0.89914577]]\n",
      "Loss: \n",
      " 0.0001589878102142825\n",
      "\n",
      "\n",
      "Epoch: 950\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90333253]\n",
      " [0.84930089]\n",
      " [0.89916226]]\n",
      "Loss: \n",
      " 0.00015874088500244968\n",
      "\n",
      "\n",
      "Epoch: 951\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90334928]\n",
      " [0.84932333]\n",
      " [0.89917869]]\n",
      "Loss: \n",
      " 0.00015849543104360446\n",
      "\n",
      "\n",
      "Epoch: 952\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90336598]\n",
      " [0.84934569]\n",
      " [0.89919508]]\n",
      "Loss: \n",
      " 0.00015825143882818867\n",
      "\n",
      "\n",
      "Epoch: 953\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90338263]\n",
      " [0.84936799]\n",
      " [0.89921141]]\n",
      "Loss: \n",
      " 0.00015800889891277024\n",
      "\n",
      "\n",
      "Epoch: 954\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90339922]\n",
      " [0.84939022]\n",
      " [0.89922768]]\n",
      "Loss: \n",
      " 0.00015776780191952537\n",
      "\n",
      "\n",
      "Epoch: 955\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90341576]\n",
      " [0.84941238]\n",
      " [0.8992439 ]]\n",
      "Loss: \n",
      " 0.0001575281385357419\n",
      "\n",
      "\n",
      "Epoch: 956\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90343225]\n",
      " [0.84943448]\n",
      " [0.89926007]]\n",
      "Loss: \n",
      " 0.00015728989951333048\n",
      "\n",
      "\n",
      "Epoch: 957\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90344868]\n",
      " [0.8494565 ]\n",
      " [0.89927618]]\n",
      "Loss: \n",
      " 0.00015705307566833362\n",
      "\n",
      "\n",
      "Epoch: 958\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90346506]\n",
      " [0.84947845]\n",
      " [0.89929225]]\n",
      "Loss: \n",
      " 0.00015681765788043694\n",
      "\n",
      "\n",
      "Epoch: 959\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90348139]\n",
      " [0.84950034]\n",
      " [0.89930825]]\n",
      "Loss: \n",
      " 0.00015658363709249114\n",
      "\n",
      "\n",
      "Epoch: 960\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90349767]\n",
      " [0.84952216]\n",
      " [0.89932421]]\n",
      "Loss: \n",
      " 0.00015635100431003952\n",
      "\n",
      "\n",
      "Epoch: 961\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90351389]\n",
      " [0.84954391]\n",
      " [0.89934011]]\n",
      "Loss: \n",
      " 0.00015611975060083222\n",
      "\n",
      "\n",
      "Epoch: 962\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90353007]\n",
      " [0.84956559]\n",
      " [0.89935596]]\n",
      "Loss: \n",
      " 0.0001558898670943644\n",
      "\n",
      "\n",
      "Epoch: 963\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90354619]\n",
      " [0.84958721]\n",
      " [0.89937176]]\n",
      "Loss: \n",
      " 0.00015566134498141445\n",
      "\n",
      "\n",
      "Epoch: 964\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90356226]\n",
      " [0.84960876]\n",
      " [0.89938751]]\n",
      "Loss: \n",
      " 0.00015543417551357248\n",
      "\n",
      "\n",
      "Epoch: 965\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90357828]\n",
      " [0.84963024]\n",
      " [0.89940321]]\n",
      "Loss: \n",
      " 0.0001552083500027981\n",
      "\n",
      "\n",
      "Epoch: 966\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90359425]\n",
      " [0.84965165]\n",
      " [0.89941885]]\n",
      "Loss: \n",
      " 0.00015498385982094524\n",
      "\n",
      "\n",
      "Epoch: 967\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90361017]\n",
      " [0.849673  ]\n",
      " [0.89943444]]\n",
      "Loss: \n",
      " 0.0001547606963993252\n",
      "\n",
      "\n",
      "Epoch: 968\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90362604]\n",
      " [0.84969429]\n",
      " [0.89944998]]\n",
      "Loss: \n",
      " 0.00015453885122826565\n",
      "\n",
      "\n",
      "Epoch: 969\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90364185]\n",
      " [0.84971551]\n",
      " [0.89946547]]\n",
      "Loss: \n",
      " 0.00015431831585665048\n",
      "\n",
      "\n",
      "Epoch: 970\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90365762]\n",
      " [0.84973666]\n",
      " [0.89948091]]\n",
      "Loss: \n",
      " 0.00015409908189149593\n",
      "\n",
      "\n",
      "Epoch: 971\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90367334]\n",
      " [0.84975774]\n",
      " [0.8994963 ]]\n",
      "Loss: \n",
      " 0.00015388114099750992\n",
      "\n",
      "\n",
      "Epoch: 972\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90368901]\n",
      " [0.84977877]\n",
      " [0.89951164]]\n",
      "Loss: \n",
      " 0.00015366448489665717\n",
      "\n",
      "\n",
      "Epoch: 973\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90370462]\n",
      " [0.84979972]\n",
      " [0.89952693]]\n",
      "Loss: \n",
      " 0.0001534491053677317\n",
      "\n",
      "\n",
      "Epoch: 974\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90372019]\n",
      " [0.84982061]\n",
      " [0.89954217]]\n",
      "Loss: \n",
      " 0.00015323499424594252\n",
      "\n",
      "\n",
      "Epoch: 975\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90373571]\n",
      " [0.84984144]\n",
      " [0.89955736]]\n",
      "Loss: \n",
      " 0.00015302214342247146\n",
      "\n",
      "\n",
      "Epoch: 976\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90375118]\n",
      " [0.84986221]\n",
      " [0.89957249]]\n",
      "Loss: \n",
      " 0.00015281054484407756\n",
      "\n",
      "\n",
      "Epoch: 977\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.9037666 ]\n",
      " [0.84988291]\n",
      " [0.89958758]]\n",
      "Loss: \n",
      " 0.00015260019051266667\n",
      "\n",
      "\n",
      "Epoch: 978\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90378197]\n",
      " [0.84990354]\n",
      " [0.89960262]]\n",
      "Loss: \n",
      " 0.0001523910724848844\n",
      "\n",
      "\n",
      "Epoch: 979\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.9037973 ]\n",
      " [0.84992411]\n",
      " [0.89961761]]\n",
      "Loss: \n",
      " 0.0001521831828717202\n",
      "\n",
      "\n",
      "Epoch: 980\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90381257]\n",
      " [0.84994462]\n",
      " [0.89963255]]\n",
      "Loss: \n",
      " 0.0001519765138380782\n",
      "\n",
      "\n",
      "Epoch: 981\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.9038278 ]\n",
      " [0.84996507]\n",
      " [0.89964745]]\n",
      "Loss: \n",
      " 0.00015177105760240134\n",
      "\n",
      "\n",
      "Epoch: 982\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90384298]\n",
      " [0.84998545]\n",
      " [0.89966229]]\n",
      "Loss: \n",
      " 0.00015156680643626792\n",
      "\n",
      "\n",
      "Epoch: 983\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90385811]\n",
      " [0.85000577]\n",
      " [0.89967709]]\n",
      "Loss: \n",
      " 0.00015136375266397746\n",
      "\n",
      "\n",
      "Epoch: 984\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90387319]\n",
      " [0.85002603]\n",
      " [0.89969183]]\n",
      "Loss: \n",
      " 0.00015116188866218155\n",
      "\n",
      "\n",
      "Epoch: 985\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90388823]\n",
      " [0.85004623]\n",
      " [0.89970653]]\n",
      "Loss: \n",
      " 0.0001509612068594966\n",
      "\n",
      "\n",
      "Epoch: 986\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90390322]\n",
      " [0.85006636]\n",
      " [0.89972118]]\n",
      "Loss: \n",
      " 0.00015076169973609512\n",
      "\n",
      "\n",
      "Epoch: 987\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90391816]\n",
      " [0.85008643]\n",
      " [0.89973579]]\n",
      "Loss: \n",
      " 0.0001505633598233596\n",
      "\n",
      "\n",
      "Epoch: 988\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90393305]\n",
      " [0.85010644]\n",
      " [0.89975034]]\n",
      "Loss: \n",
      " 0.0001503661797034661\n",
      "\n",
      "\n",
      "Epoch: 989\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.9039479 ]\n",
      " [0.85012639]\n",
      " [0.89976485]]\n",
      "Loss: \n",
      " 0.00015017015200903552\n",
      "\n",
      "\n",
      "Epoch: 990\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.9039627 ]\n",
      " [0.85014628]\n",
      " [0.89977931]]\n",
      "Loss: \n",
      " 0.00014997526942274879\n",
      "\n",
      "\n",
      "Epoch: 991\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90397745]\n",
      " [0.85016611]\n",
      " [0.89979373]]\n",
      "Loss: \n",
      " 0.00014978152467698554\n",
      "\n",
      "\n",
      "Epoch: 992\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90399216]\n",
      " [0.85018587]\n",
      " [0.89980809]]\n",
      "Loss: \n",
      " 0.00014958891055344954\n",
      "\n",
      "\n",
      "Epoch: 993\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90400682]\n",
      " [0.85020558]\n",
      " [0.89982241]]\n",
      "Loss: \n",
      " 0.00014939741988280645\n",
      "\n",
      "\n",
      "Epoch: 994\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90402144]\n",
      " [0.85022523]\n",
      " [0.89983669]]\n",
      "Loss: \n",
      " 0.00014920704554432956\n",
      "\n",
      "\n",
      "Epoch: 995\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90403601]\n",
      " [0.85024481]\n",
      " [0.89985092]]\n",
      "Loss: \n",
      " 0.00014901778046553648\n",
      "\n",
      "\n",
      "Epoch: 996\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90405053]\n",
      " [0.85026434]\n",
      " [0.8998651 ]]\n",
      "Loss: \n",
      " 0.0001488296176218333\n",
      "\n",
      "\n",
      "Epoch: 997\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90406501]\n",
      " [0.8502838 ]\n",
      " [0.89987923]]\n",
      "Loss: \n",
      " 0.00014864255003616735\n",
      "\n",
      "\n",
      "Epoch: 998\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90407944]\n",
      " [0.85030321]\n",
      " [0.89989332]]\n",
      "Loss: \n",
      " 0.00014845657077867646\n",
      "\n",
      "\n",
      "Epoch: 999\n",
      "l_rate 0.1\n",
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.90409383]\n",
      " [0.85032256]\n",
      " [0.89990736]]\n",
      "Loss: \n",
      " 0.00014827167296634005\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "X = np.array(([2, 9], [1, 5], [3, 6]), dtype=float)\n",
    "print(np.amax(X, axis=0))\n",
    "y = np.array(([92], [86], [89]), dtype=float)\n",
    "X = X/np.amax(X, axis=0)\n",
    "y = y/100\n",
    "\n",
    "class Neural_Network(object):\n",
    "    def __init__(self):\n",
    "        self.inputSize = 2\n",
    "        self.outputSize = 1\n",
    "        self.hiddenSize = 3\n",
    "        self.W1 = np.random.randn(self.inputSize, self.hiddenSize)\n",
    "        self.W2 = np.random.randn(self.hiddenSize, self.outputSize)\n",
    "\n",
    "    def forward(self, X):\n",
    "        self.z = np.dot(X, self.W1)\n",
    "        self.z2 = self.sigmoid(self.z)\n",
    "        self.z3 = np.dot(self.z2, self.W2)\n",
    "        o = self.sigmoid(self.z3) \n",
    "        return o \n",
    "\n",
    "    def sigmoid(self, s):\n",
    "        return 1/(1+np.exp(-s))\n",
    "\n",
    "    def sigmoidPrime(self, s):\n",
    "        return s * (1 - s)\n",
    "    \n",
    "    def backward(self, X, y, o):\n",
    "        self.o_error = y - o\n",
    "        self.o_delta = self.o_error*self.sigmoidPrime(o)\n",
    "        self.z2_error = self.o_delta.dot(self.W2.T)\n",
    "        self.z2_delta = self.z2_error*self.sigmoidPrime(self.z2)\n",
    "        self.W1 += l_rate*X.T.dot(self.z2_delta)\n",
    "        self.W2 += l_rate*self.z2.T.dot(self.o_delta)\n",
    "\n",
    "    def train (self, X, y):\n",
    "        o = self.forward(X)\n",
    "        self.backward(X, y, o)\n",
    "\n",
    "NN = Neural_Network()\n",
    "l_rate = 0.1 \n",
    "for i in range(1000):\n",
    "    print(\"Epoch:\",i)\n",
    "    print(\"l_rate\",l_rate)\n",
    "    print (\"Input: \\n\",str(X))\n",
    "    print (\"Actual Output: \\n\",str(y))\n",
    "    print (\"Predicted Output: \\n\",str(NN.forward(X)) )\n",
    "    print (\"Loss: \\n\",str(np.mean(np.square(y - NN.forward(X)))))\n",
    "    print(\"\\n\")\n",
    "    NN.train(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5eb8be3-179c-4a13-be73-3734502cd50a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Program 6 Source Code\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9dd9f23-7123-41ff-89ab-6e3dc5b84c9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first 5 values of data is:\n",
      "     Outlook Temperature Humidity  Windy PlayTennis\n",
      "0     Sunny         Hot     High  False         No\n",
      "1     Sunny         Hot     High   True         No\n",
      "2  Overcast         Hot     High  False        Yes\n",
      "3     Rainy        Mild     High  False        Yes\n",
      "4     Rainy        Cool   Normal  False        Yes\n",
      "\n",
      "The First 5 values of train data is\n",
      "     Outlook Temperature Humidity  Windy\n",
      "0     Sunny         Hot     High  False\n",
      "1     Sunny         Hot     High   True\n",
      "2  Overcast         Hot     High  False\n",
      "3     Rainy        Mild     High  False\n",
      "4     Rainy        Cool   Normal  False\n",
      "\n",
      "The First 5 values of train output is\n",
      " 0     No\n",
      "1     No\n",
      "2    Yes\n",
      "3    Yes\n",
      "4    Yes\n",
      "Name: PlayTennis, dtype: object\n",
      "\n",
      "Now the train data is:\n",
      "    Outlook  Temperature  Humidity  Windy\n",
      "0        2            1         0      0\n",
      "1        2            1         0      1\n",
      "2        0            1         0      0\n",
      "3        1            2         0      0\n",
      "4        1            0         1      0\n",
      "\n",
      "Now the train output is\n",
      " [0 0 1 1 1 0 1 0 1 1 1 1 1 0]\n",
      "Accuracy is: 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "pro6.csv\n",
    "Outlook,Temperature,Humidity,Windy,PlayTennis\n",
    "Sunny,Hot,High,False,No\n",
    "Sunny,Hot,High,True,No\n",
    "Overcast,Hot,High,False,Yes\n",
    "Rainy,Mild,High,False,Yes\n",
    "Rainy,Cool,Normal,False,Yes\n",
    "Rainy,Cool,Normal,True,No\n",
    "Overcast,Cool,Normal,True,Yes\n",
    "Sunny,Mild,High,False,No\n",
    "Sunny,Cool,Normal,False,Yes\n",
    "Rainy,Mild,Normal,False,Yes\n",
    "Sunny,Mild,Normal,True,Yes\n",
    "Overcast,Mild,High,True,Yes\n",
    "Overcast,Hot,Normal,False,Yes\n",
    "Rainy,Mild,High,True,No\n",
    "\n",
    "'''\n",
    "import pandas as pd\n",
    "from sklearn import tree\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "data = pd.read_csv('pro6.csv') \n",
    "print(\"The first 5 values of data is:\\n\",data.head())\n",
    "\n",
    "X = data.iloc[:,:-1]\n",
    "print(\"\\nThe First 5 values of train data is\\n\",X.head())\n",
    "y = data.iloc[:,-1]\n",
    "print(\"\\nThe First 5 values of train output is\\n\",y.head())\n",
    "\n",
    "le_outlook = LabelEncoder()\n",
    "X.Outlook = le_outlook.fit_transform(X.Outlook) \n",
    "le_Temperature = LabelEncoder() \n",
    "X.Temperature = le_Temperature.fit_transform(X.Temperature)\n",
    "le_Humidity = LabelEncoder()\n",
    "X.Humidity = le_Humidity.fit_transform(X.Humidity)\n",
    "le_Windy = LabelEncoder()\n",
    "X.Windy = le_Windy.fit_transform(X.Windy)\n",
    "\n",
    "print(\"\\nNow the train data is:\\n\", X.head())\n",
    "le_PlayTennis = LabelEncoder()\n",
    "y = le_PlayTennis.fit_transform(y)\n",
    "print(\"\\nNow the train output is\\n\",y)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.20)\n",
    "classifier=GaussianNB()\n",
    "classifier.fit(X_train,y_train)\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Accuracy is:\",accuracy_score(classifier.predict(X_test),y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Program 7 Source Code ðŸ‘‡\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\91966\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\91966\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'Petal_Length'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32md:\\StudyMaterial\\LabPrograms\\AIML-Lab\\pro1.ipynb Cell 15\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/StudyMaterial/LabPrograms/AIML-Lab/pro1.ipynb#X21sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m colormap \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([\u001b[39m'\u001b[39m\u001b[39mred\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mlime\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mblack\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/StudyMaterial/LabPrograms/AIML-Lab/pro1.ipynb#X21sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m plt\u001b[39m.\u001b[39msubplot(\u001b[39m1\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/StudyMaterial/LabPrograms/AIML-Lab/pro1.ipynb#X21sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m plt\u001b[39m.\u001b[39mscatter(X\u001b[39m.\u001b[39;49mPetal_Length,X\u001b[39m.\u001b[39mPetal_Width,c\u001b[39m=\u001b[39mcolormap[y\u001b[39m.\u001b[39mTargets], s\u001b[39m=\u001b[39m\u001b[39m40\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/StudyMaterial/LabPrograms/AIML-Lab/pro1.ipynb#X21sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m plt\u001b[39m.\u001b[39mtitle(\u001b[39m\"\u001b[39m\u001b[39mReal Clusters\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/StudyMaterial/LabPrograms/AIML-Lab/pro1.ipynb#X21sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m plt\u001b[39m.\u001b[39mxlabel(\u001b[39m\"\u001b[39m\u001b[39mPetal Length\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\91966\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:5989\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5982\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m   5983\u001b[0m     name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_internal_names_set\n\u001b[0;32m   5984\u001b[0m     \u001b[39mand\u001b[39;00m name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_metadata\n\u001b[0;32m   5985\u001b[0m     \u001b[39mand\u001b[39;00m name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_accessors\n\u001b[0;32m   5986\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_info_axis\u001b[39m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[0;32m   5987\u001b[0m ):\n\u001b[0;32m   5988\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m[name]\n\u001b[1;32m-> 5989\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mobject\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__getattribute__\u001b[39;49m(\u001b[39mself\u001b[39;49m, name)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'Petal_Length'"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.cluster import KMeans\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = pd.DataFrame(iris.data)\n",
    "X_columns = ['Sepal_Length','Sepal_Width','Petal_Length','Petal_Width']\n",
    "y = pd.DataFrame(iris.target)\n",
    "y.columns = [\"Targets\"]\n",
    "\n",
    "#Build K Means Model\n",
    "model = KMeans(n_clusters=3)\n",
    "model.fit(X)\n",
    "\n",
    "#Visualise the clustering results\n",
    "plt.figure(figsize=(14,7))\n",
    "colormap = np.array(['red','lime','black'])\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.scatter(X.Petal_Length,X.Petal_Width,c=colormap[y.Targets], s=40)\n",
    "plt.title(\"Real Clusters\")\n",
    "plt.xlabel(\"Petal Length\")\n",
    "plt.ylabel(\"Petal Width\")\n",
    "\n",
    "#plot model classifications\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.scatter(X.Petal_Length, X.Petal_Width, c=colormap[model.labels_],s=40)\n",
    "plt.title(\"K_Means Clustering\")\n",
    "plt.xlabel(\"Petal Length\")\n",
    "plt.ylabel(\"Petal Width\")\n",
    "\n",
    "\n",
    "#General EM for GMM\n",
    "from sklearn import preprocessing\n",
    "\n",
    "#transform your data\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(X)\n",
    "xsa = scaler.transform(X)\n",
    "xs = pd.DataFrame(xsa, columns=X.columns)\n",
    "\n",
    "from sklearn.mixture import GaussianMixture\n",
    "gmm = GaussianMixture(n_components=40)\n",
    "gmm.fit(xs)\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.scatter(X.Petal_Length,X.Petal_Width,c=colormap[0], s=40)\n",
    "plt.title(\"GMM Clustering\")\n",
    "plt.xlabel(\"Petal Length\")\n",
    "plt.ylabel(\"Petal Width\")\n",
    "\n",
    "\n",
    "print(\"Done !! âœ…\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Program 8 Source Code ðŸ‘‡\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iris Data set Loaded...\n",
      "Label 0 - setosa\n",
      "Label 1 - versicolor\n",
      "Label 2 - virginica\n",
      "Results of Classification using k-nn with k=1\n",
      "Sample [5.6 3.  4.5 1.5] Actual-label: 1 Predicted-label: 1\n",
      "Classification Accuracy : 1.0\n",
      "Sample [5.4 3.4 1.7 0.2] Actual-label: 0 Predicted-label: 0\n",
      "Classification Accuracy : 1.0\n",
      "Sample [6.9 3.2 5.7 2.3] Actual-label: 2 Predicted-label: 2\n",
      "Classification Accuracy : 1.0\n",
      "Sample [4.8 3.4 1.9 0.2] Actual-label: 0 Predicted-label: 0\n",
      "Classification Accuracy : 1.0\n",
      "Sample [6.8 3.2 5.9 2.3] Actual-label: 2 Predicted-label: 2\n",
      "Classification Accuracy : 1.0\n",
      "Sample [5.6 3.  4.1 1.3] Actual-label: 1 Predicted-label: 1\n",
      "Classification Accuracy : 1.0\n",
      "Sample [4.9 3.6 1.4 0.1] Actual-label: 0 Predicted-label: 0\n",
      "Classification Accuracy : 1.0\n",
      "Sample [5.  3.5 1.3 0.3] Actual-label: 0 Predicted-label: 0\n",
      "Classification Accuracy : 1.0\n",
      "Sample [5.2 2.7 3.9 1.4] Actual-label: 1 Predicted-label: 1\n",
      "Classification Accuracy : 1.0\n",
      "Sample [5.  3.2 1.2 0.2] Actual-label: 0 Predicted-label: 0\n",
      "Classification Accuracy : 1.0\n",
      "Sample [4.4 3.  1.3 0.2] Actual-label: 0 Predicted-label: 0\n",
      "Classification Accuracy : 1.0\n",
      "Sample [5.5 2.6 4.4 1.2] Actual-label: 1 Predicted-label: 1\n",
      "Classification Accuracy : 1.0\n",
      "Sample [7.2 3.6 6.1 2.5] Actual-label: 2 Predicted-label: 2\n",
      "Classification Accuracy : 1.0\n",
      "Sample [5.5 2.5 4.  1.3] Actual-label: 1 Predicted-label: 1\n",
      "Classification Accuracy : 1.0\n",
      "Sample [5.7 2.9 4.2 1.3] Actual-label: 1 Predicted-label: 1\n",
      "Classification Accuracy : 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import datasets\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "print(\"Iris Data set Loaded...\")\n",
    "\n",
    "X_train, X_test, y_train,y_test = train_test_split(iris.data,iris.target,test_size=0.1)\n",
    "\n",
    "#random_state=0\n",
    "\n",
    "for i in range(len(iris.target_names)):\n",
    "    print(\"Label\", i, \"-\",str(iris.target_names[i]))\n",
    "\n",
    "classifier = KNeighborsClassifier(n_neighbors=2)\n",
    "classifier.fit(X_train,y_train)\n",
    "y_pred=classifier.predict(X_test)\n",
    "\n",
    "print(\"Results of Classification using k-nn with k=1\")\n",
    "\n",
    "for r in range(0,len(X_test)):\n",
    "    print(\"Sample\", str(X_test[r]), \"Actual-label:\", str(y_test[r]), \"Predicted-label:\", str(y_pred[r]))\n",
    "\n",
    "    print(\"Classification Accuracy :\", classifier.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Program 9 Source Code ðŸ‘‡\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def local_regression(x0, X,Y,tau):\n",
    "    x0=[1,x0]\n",
    "    X=[[1,i] for i in X ]\n",
    "    X=np.asarray(X)\n",
    "    xw = (X.T) * np.exp(np.sum((X-x0)**2,axis=1)/(-2*tau)) \n",
    "    beta = np.linalg.pinv(xw @ X) @ xw @ Y @x0\n",
    "    return beta\n",
    "\n",
    "def draw(tau):\n",
    "    prediction=[local_regression(x0,X,Y,tau) for x0 in domain]\n",
    "    plt.plot(X,Y,'o',color=\"black\")\n",
    "    plt.plot(domain,prediction,color=\"red\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "X = np.linspace(-3,3,num=1000)\n",
    "domain = X\n",
    "Y = np.log(np.abs(X**2-1)+.5)\n",
    "\n",
    "draw(10)\n",
    "draw(0.1)\n",
    "draw(0.01)\n",
    "draw(0.001)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
